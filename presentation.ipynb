{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pprint\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, MSELoss,BCEWithLogitsLoss\n",
    "\n",
    "class ContextualBertForSequenceClassification(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, num_labels, ContextModel, SpanModel):\n",
    "    super(ContextualBertForSequenceClassification, self).__init__()\n",
    "    self.ContextModel = ContextModel\n",
    "    self.SpanModel = SpanModel\n",
    "    self.num_labels = num_labels\n",
    "\n",
    "    # self.classifier = torch.nn.Linear(768*2, num_labels)\n",
    "    # self.classifier1 = torch.nn.Linear(768, num_labels)\n",
    "    self.classifier2 = torch.nn.Linear(768+128, num_labels)\n",
    "    self.reduce_classifier = torch.nn.Linear(768, 128)\n",
    "    self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      span_input_ids,\n",
    "      span_attention_mask,\n",
    "      context_input_ids,\n",
    "      context_attention_mask,\n",
    "      labels=None\n",
    "  ):\n",
    "    context_outputs = self.ContextModel(\n",
    "        input_ids=context_input_ids,\n",
    "        attention_mask=context_attention_mask\n",
    "    )\n",
    "    context_outputs = context_outputs[1] # pooler output\n",
    "    span_outputs = self.SpanModel(\n",
    "        input_ids=span_input_ids,\n",
    "        attention_mask=span_attention_mask\n",
    "    )\n",
    "    span_outputs = span_outputs[1]\n",
    "\n",
    "    context_outputs = self.reduce_classifier(context_outputs)\n",
    "    pooled_output = torch.cat((span_outputs, context_outputs), axis=1)\n",
    "\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "    logits = self.classifier2(pooled_output)\n",
    "    outputs = (logits,)\n",
    "    if labels is not None:\n",
    "      if self.num_labels == 1:\n",
    "        loss_fct = MSELoss()\n",
    "        loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "      else:\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "      outputs = (loss,) + outputs\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model_binary = ContextualBertForSequenceClassification(1, context_model, span_model)\\nmodel_binary.cuda()\\nmodel_binary.load_state_dict(torch.load('binary.pth'))\\nmodel_binary.eval()\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#from transformers import RobertaModel\n",
    "from transformers import BertModel\n",
    "#from transformers import RobertaForSequenceClassification\n",
    "import time,sys\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "context_model = BertModel.from_pretrained(model_name)\n",
    "span_model = BertModel.from_pretrained(model_name)\n",
    "model = ContextualBertForSequenceClassification(19, context_model, span_model)\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load('19class.pth'))\n",
    "model.eval()\n",
    "\"\"\"model_binary = ContextualBertForSequenceClassification(1, context_model, span_model)\n",
    "model_binary.cuda()\n",
    "model_binary.load_state_dict(torch.load('binary.pth'))\n",
    "model_binary.eval()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from preprocess_c import *\n",
    "train_path  = 'data/data_propoganda/data/protechn_corpus_eval/train'\n",
    "test_path = 'data/data_propoganda/data/protechn_corpus_eval/test'\n",
    "dev_path = 'data/data_propoganda/data/protechn_corpus_eval/dev'\n",
    "\n",
    "def make_dset(path):\n",
    "    path_ = Path(path)\n",
    "    a = make_dataset(path_)\n",
    "    df_1 = pd.DataFrame(columns=['id','full_sent','start_sent','end_sent','start_prop','end_prop','prop','??','???'])\n",
    "    for dm in a:\n",
    "        df_t = pd.DataFrame(dm,columns =['id','full_sent','start_sent','end_sent','start_prop','end_prop','prop','??','???'] )\n",
    "        df_1 = df_1.append(df_t,ignore_index= True)\n",
    "    return df_1.iloc[:,:-2]\n",
    "\n",
    "df_train = make_dset(train_path)\n",
    "df_test = make_dset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_tagging = [0 if i == 'O' else 1 for i in df_train.prop.values ]\n",
    "df_train['binary'] = binary_tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_sent</th>\n",
       "      <th>start_sent</th>\n",
       "      <th>end_sent</th>\n",
       "      <th>start_prop</th>\n",
       "      <th>end_prop</th>\n",
       "      <th>prop</th>\n",
       "      <th>binary</th>\n",
       "      <th>prop_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111112</td>\n",
       "      <td>Pamela Geller and Robert Spencer co-founded anti-Muslim group Stop Islamization of America.</td>\n",
       "      <td>129</td>\n",
       "      <td>220</td>\n",
       "      <td>191</td>\n",
       "      <td>220</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111112</td>\n",
       "      <td>He added: \"We condemn all those whose behaviours and views run counter to our shared values and will not stand for extremism in any form.\"</td>\n",
       "      <td>465</td>\n",
       "      <td>603</td>\n",
       "      <td>476</td>\n",
       "      <td>556</td>\n",
       "      <td>Black-and-White_Fallacy</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111112</td>\n",
       "      <td>Ms Geller, of the Atlas Shrugs blog, and Mr Spencer, of Jihad Watch, are also co-founders of the American Freedom Defense Initiative, best known f...</td>\n",
       "      <td>622</td>\n",
       "      <td>838</td>\n",
       "      <td>785</td>\n",
       "      <td>798</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111112</td>\n",
       "      <td>On both of their blogs the pair called their bans from entering the UK \"a striking blow against freedom\" and said the \"the nation that gave the wo...</td>\n",
       "      <td>839</td>\n",
       "      <td>1014</td>\n",
       "      <td>911</td>\n",
       "      <td>942</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111112</td>\n",
       "      <td>On both of their blogs the pair called their bans from entering the UK \"a striking blow against freedom\" and said the \"the nation that gave the wo...</td>\n",
       "      <td>839</td>\n",
       "      <td>1014</td>\n",
       "      <td>958</td>\n",
       "      <td>1014</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15745</th>\n",
       "      <td>999001621</td>\n",
       "      <td>This is a Moon of Alabama fundraiser week.</td>\n",
       "      <td>12271</td>\n",
       "      <td>12313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15746</th>\n",
       "      <td>999001621</td>\n",
       "      <td>No one pays me to write these blog posts.</td>\n",
       "      <td>12314</td>\n",
       "      <td>12355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15747</th>\n",
       "      <td>999001621</td>\n",
       "      <td>If you appreciated this one, or any of the 7,000+ others, please consider a donation.</td>\n",
       "      <td>12356</td>\n",
       "      <td>12441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15748</th>\n",
       "      <td>999001621</td>\n",
       "      <td>Posted by b on November 29, 2018 at 10:23 AM | Permalink</td>\n",
       "      <td>12442</td>\n",
       "      <td>12498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15749</th>\n",
       "      <td>999001621</td>\n",
       "      <td>Comments</td>\n",
       "      <td>12499</td>\n",
       "      <td>12507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15750 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  \\\n",
       "0      111111112   \n",
       "1      111111112   \n",
       "2      111111112   \n",
       "3      111111112   \n",
       "4      111111112   \n",
       "...          ...   \n",
       "15745  999001621   \n",
       "15746  999001621   \n",
       "15747  999001621   \n",
       "15748  999001621   \n",
       "15749  999001621   \n",
       "\n",
       "                                                                                                                                                   full_sent  \\\n",
       "0                                                                Pamela Geller and Robert Spencer co-founded anti-Muslim group Stop Islamization of America.   \n",
       "1                 He added: \"We condemn all those whose behaviours and views run counter to our shared values and will not stand for extremism in any form.\"   \n",
       "2      Ms Geller, of the Atlas Shrugs blog, and Mr Spencer, of Jihad Watch, are also co-founders of the American Freedom Defense Initiative, best known f...   \n",
       "3      On both of their blogs the pair called their bans from entering the UK \"a striking blow against freedom\" and said the \"the nation that gave the wo...   \n",
       "4      On both of their blogs the pair called their bans from entering the UK \"a striking blow against freedom\" and said the \"the nation that gave the wo...   \n",
       "...                                                                                                                                                      ...   \n",
       "15745                                                                                                             This is a Moon of Alabama fundraiser week.   \n",
       "15746                                                                                                              No one pays me to write these blog posts.   \n",
       "15747                                                                  If you appreciated this one, or any of the 7,000+ others, please consider a donation.   \n",
       "15748                                                                                               Posted by b on November 29, 2018 at 10:23 AM | Permalink   \n",
       "15749                                                                                                                                               Comments   \n",
       "\n",
       "      start_sent end_sent start_prop end_prop                     prop  \\\n",
       "0            129      220        191      220                  Slogans   \n",
       "1            465      603        476      556  Black-and-White_Fallacy   \n",
       "2            622      838        785      798                  Slogans   \n",
       "3            839     1014        911      942          Loaded_Language   \n",
       "4            839     1014        958     1014          Loaded_Language   \n",
       "...          ...      ...        ...      ...                      ...   \n",
       "15745      12271    12313          0        0                        O   \n",
       "15746      12314    12355          0        0                        O   \n",
       "15747      12356    12441          0        0                        O   \n",
       "15748      12442    12498          0        0                        O   \n",
       "15749      12499    12507          0        0                        O   \n",
       "\n",
       "       binary  prop_1  \n",
       "0           1       9  \n",
       "1           1      11  \n",
       "2           1       9  \n",
       "3           1       1  \n",
       "4           1       1  \n",
       "...       ...     ...  \n",
       "15745       0       0  \n",
       "15746       0       0  \n",
       "15747       0       0  \n",
       "15748       0       0  \n",
       "15749       0       0  \n",
       "\n",
       "[15750 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'O':0,'Loaded_Language':1,'Name_Calling,Labeling':2,'Repetition':3,\n",
    "           'Exaggeration,Minimisation':4,'Doubt':5,'Appeal_to_fear-prejudice':6,'Flag-Waving':7,'Causal_Oversimplification':8,\n",
    "           'Slogans':9,'Appeal_to_Authority':10,'Black-and-White_Fallacy':11,'Thought-terminating_Cliches':12,'Whataboutism':13,\n",
    "           'Reductio_ad_hitlerum':14,'Red_Herring':15,'Bandwagon':16,'Obfuscation,Intentional_Vagueness,Confusion':17,'Straw_Men':18}\n",
    "#df_train = df_train[df_train.binary !=0]\n",
    "rev_mapping = {v:k for k,v in mapping.items()}\n",
    "\n",
    "\n",
    "df_train['prop_1'] = df_train.prop.apply(lambda x: mapping[x])\n",
    "df_test['prop_1'] = df_test.prop.apply(lambda x: mapping[x])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "train_direct = glob.glob('data/data_propoganda/data/protechn_corpus_eval/train/*.txt')\n",
    "test_direct = glob.glob('data/data_propoganda/data/protechn_corpus_eval/test/*.txt')\n",
    "\n",
    "def read_articles(dire,mode = 'train'):\n",
    "  articles = []\n",
    "  \n",
    "  for filename in dire:\n",
    "      myfile = open(filename,encoding='utf8')\n",
    "      article = myfile.read()\n",
    "      articles.append(article)\n",
    "      myfile.close()\n",
    "  article_ids = []\n",
    "  \n",
    "  for filename in dire:\n",
    "    if mode =='train':\n",
    "      article_ids.append(filename[60:-4])\n",
    "    else:\n",
    "      article_ids.append(filename[59:-4])\n",
    "  \n",
    "  return articles, article_ids\n",
    "articles,art_ids = read_articles(train_direct)\n",
    "\n",
    "articles_t,art_ids_t = read_articles(test_direct,'test')\n",
    "id2art ={i:a for a,i in zip(articles,art_ids)}\n",
    "id2art_t = {i:a for a,i in zip(articles_t,art_ids_t)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(article, span, mode='sentence',set = 'train'):\n",
    "  article = id2art[article] if set =='train' else id2art_t[article]\n",
    "  def get_num_words(sentence):\n",
    "    return len(sentence.split(' '))\n",
    "  if mode == \"title\":\n",
    "    return article.split('\\n')[0]\n",
    "  if mode == \"sentence\":\n",
    "    WORD_LEN_LIMIT = 120\n",
    "    li = span[0]\n",
    "    ri = span[1]\n",
    "    span_text = article[li: ri]\n",
    "    num_words = get_num_words(span_text)\n",
    "    if num_words >= WORD_LEN_LIMIT:\n",
    "      return span_text\n",
    "    remaining_len = WORD_LEN_LIMIT - num_words\n",
    "    lhs_words = remaining_len // 2\n",
    "    rhs_words = remaining_len - lhs_words\n",
    "    li -= 1\n",
    "    lcount = 0\n",
    "    while li >= 0 and article[li-1] != '\\n' and lcount < lhs_words:\n",
    "      if article[li] == ' ':\n",
    "        lcount += 1\n",
    "      li -= 1\n",
    "    ri += 1\n",
    "    rcount = 0\n",
    "    while ri < len(article) and article[ri] != '\\n' and rcount < rhs_words:\n",
    "      if article[ri] == ' ':\n",
    "        rcount += 1\n",
    "      ri += 1\n",
    "    return article[li+1: ri - 1] \n",
    "\n",
    "  return \"\"\n",
    "spans_1 = [(i,k,j) for i,k,j in zip(df_train.id,df_train.start_sent,df_train.end_sent)]\n",
    "spans_2 = [(i,k,j) for i,k,j in zip(df_test.id,df_test.start_sent,df_test.end_sent)]\n",
    "df_train['context'] = [get_context(i,(s,e)) for i,s,e in spans_1]\n",
    "df_test['context'] = [get_context(i,(s,e),set='test') for i,s,e in spans_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.full_sent[index])\n",
    "        title = \" \".join(title.split())\n",
    "        context = str(self.data.context[index])\n",
    "        context = \" \".join(context.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        tokenized_context = self.tokenizer.encode_plus(context,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,truncation = True)\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        c_ids = tokenized_context['input_ids']\n",
    "        c_mask = tokenized_context['attention_mask']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.prop_1[index], dtype=torch.long),\n",
    "            'c_ids':torch.tensor(c_ids, dtype=torch.long),\n",
    "            'c_mask': torch.tensor(c_mask,dtype= torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage_binary(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.full_sent[index])\n",
    "        title = \" \".join(title.split())\n",
    "        context = str(self.data.context[index])\n",
    "        context = \" \".join(context.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        tokenized_context = self.tokenizer.encode_plus(context,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,truncation = True)\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        c_ids = tokenized_context['input_ids']\n",
    "        c_mask = tokenized_context['attention_mask']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.binary[index], dtype=torch.long),\n",
    "            'c_ids':torch.tensor(c_ids, dtype=torch.long),\n",
    "            'c_mask': torch.tensor(c_mask,dtype= torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(seed=126):\n",
    "    test_set = df_train.sample(32,random_state = seed).reset_index()\n",
    "    print(\"TEST Dataset: {}\".format(test_set.shape))\n",
    "    \n",
    "    testing_set = Triage(test_set, tokenizer, MAX_LEN)\n",
    "    #testing_set_binary = Triage_binary(test_set,tokenizer,MAX_LEN)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    testing_loader = DataLoader(testing_set, **test_params)\n",
    "    #testing_loader_bin  =DataLoader(testing_set_binary, **test_params)\n",
    "    return test_set,testing_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Dataset: (32, 11)\n"
     ]
    }
   ],
   "source": [
    "test_set,testing_loader = make_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def get_model_predictions(model, dataloader,mode = 'multi'):\n",
    "  model.eval()\n",
    "  predictions , true_labels = [], []\n",
    "  nb_eval_steps = 0\n",
    "  for batch in dataloader:\n",
    "    b_input_ids = batch['ids'].to(device)\n",
    "    b_labels = batch['targets'].to(device)\n",
    "    b_input_mask = batch['mask'].to(device)\n",
    "    b_c_input_ids = batch['c_ids'].to(device)\n",
    "    b_c_input_mask = batch['c_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "      logits = model(b_input_ids, \n",
    "                     b_input_mask,\n",
    "                     b_c_input_ids, \n",
    "                     b_c_input_mask)\n",
    "    logits = logits[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    pred_label = np.argmax(logits, axis=1) if mode =='multi' else [1 if a >0.5 else 0 for a in logits]\n",
    "    predictions.extend(pred_label)\n",
    "    true_labels.extend(label_ids)\n",
    "  return predictions, true_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def show_results(df,model,loader):\n",
    "    pred,true = get_model_predictions(model, loader)\n",
    "    \n",
    "    accuracy = sum([a==b for a,b in zip(pred,true)])/len(pred)\n",
    "    print('Accuracy on validation set:',accuracy)\n",
    "    predvstrue = {'full_sentence':df.full_sent,'pred':pred,'true':true}\n",
    "    predvstrue = pd.DataFrame(predvstrue)\n",
    "    display(predvstrue)\n",
    "    predvstrue['pred_lab'] = predvstrue.pred.apply(lambda x: rev_mapping[x])\n",
    "    predvstrue['true_lab'] = predvstrue.true.apply(lambda x: rev_mapping[x])\n",
    "    \n",
    "    \n",
    "    print(classification_report(predvstrue.true_lab,predvstrue.pred_lab\n",
    "                                \n",
    "                               \n",
    "                                \n",
    "                               ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.90625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sentence</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, that’s Satan.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How in the world can we trust them even as they express bias while investigating malfeasance?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And again in 1066, rioting Muslims, enraged by the humiliation of a Jew who had been appointed to rule over Muslims, murdered four thousand Jews i...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The unnamed US citizen assigned to the consulate in Guangzhou had reported a variety of \"physical symptoms\" dating from late 2017 to April this ye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The immigrant employment index, set to 100.0 in January 2009, fell to 124.7 from 129.6 in April.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Habib-Powell had attended the Iftar dinner with members of Muslim Brotherhood front groups.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who should replace Nikki Haley as our ambassador to the U.N.?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>More than 100 Russian individuals and companies have been sanctioned for a variety of reasons.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This doltish and dimwitted document wreaks of psycho babble, insults the intelligence of young people, and will destroy the future of the Church.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>His findings, he wrote, do “not substantiate the notion that the vote was motivated by anti-Semitism,” which he defined as hostility toward or dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It emerged that during a Vatican training course for new bishops in September 2015 a French priest informed bishops they had no obligation to repo...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In his Twitter post, Trump also blasted the 17 angry Democrats that are doing a conflicted Mueller’s dirty work.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Don’t forget: According to Trump’s own tweets, he had already ostensibly decided to deny the CIA’s request for secrecy before the Thursday deadline:</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Spygate Coverup?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Catholic Church's new-found \"climate of tolerance\" is exactly what McCarrick and company are counting on!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hungarian Prime Minister Viktor Orban who has been at the forefront in Europe in standing against illegal immigration and the invasion of Muslims ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Article posted with permission from The Free Thought Project</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Likewise, when he claims that the Qur’an has “not a thing” to say about Sharia, he appears unaware that the Qur’an is one of the sources of Sharia.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>• Email: ghamilton@nationalpost.com | Twitter: grayhamilton</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I haven’t looked it up.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"I have grown accustomed to feeling unwelcome in Jewish spaces,\" Dan Fishback whines.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>In doing so, he put other seminarians at risk.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>In fact, the Gulf of Tonkin incident, as it became known, turned out to be a fictitious creation courtesy of the government to escalate war in Vie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cardinal Angelo Sodano was Secretary of State until September 2006: all information was communicated to him.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I first reported that 3-D guns were for real back in July of 2012, when an internet gunsmith by the name of \"Have Blue\" produced an AR style pisto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>“You voted NOT GUILTY on both counts at Bill Clinton’s impeachment,” she tweeted.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>“Those cases are going to be haunting this papacy and really causing a rift in the major protection of children that Pope Benedict had worked very...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Patel pleaded guilty Thursday in U.S. District Court to two counts of making false statements.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Las Vegas mass shooting victim Rocky Palermo was shot in the pelvis during the horrific attack and is now speaking out about what he saw and belie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>To call them nativists and parade their moral superiority.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            full_sentence  \\\n",
       "0                                                                                                                                       No, that’s Satan.   \n",
       "1                                                           How in the world can we trust them even as they express bias while investigating malfeasance?   \n",
       "2   And again in 1066, rioting Muslims, enraged by the humiliation of a Jew who had been appointed to rule over Muslims, murdered four thousand Jews i...   \n",
       "3   The unnamed US citizen assigned to the consulate in Guangzhou had reported a variety of \"physical symptoms\" dating from late 2017 to April this ye...   \n",
       "4                                                        The immigrant employment index, set to 100.0 in January 2009, fell to 124.7 from 129.6 in April.   \n",
       "5                                                             Habib-Powell had attended the Iftar dinner with members of Muslim Brotherhood front groups.   \n",
       "6                                                                                           Who should replace Nikki Haley as our ambassador to the U.N.?   \n",
       "7                                                          More than 100 Russian individuals and companies have been sanctioned for a variety of reasons.   \n",
       "8       This doltish and dimwitted document wreaks of psycho babble, insults the intelligence of young people, and will destroy the future of the Church.   \n",
       "9   His findings, he wrote, do “not substantiate the notion that the vote was motivated by anti-Semitism,” which he defined as hostility toward or dis...   \n",
       "10  It emerged that during a Vatican training course for new bishops in September 2015 a French priest informed bishops they had no obligation to repo...   \n",
       "11                                       In his Twitter post, Trump also blasted the 17 angry Democrats that are doing a conflicted Mueller’s dirty work.   \n",
       "12   Don’t forget: According to Trump’s own tweets, he had already ostensibly decided to deny the CIA’s request for secrecy before the Thursday deadline:   \n",
       "13                                                                                                                                       Spygate Coverup?   \n",
       "14                                          The Catholic Church's new-found \"climate of tolerance\" is exactly what McCarrick and company are counting on!   \n",
       "15  Hungarian Prime Minister Viktor Orban who has been at the forefront in Europe in standing against illegal immigration and the invasion of Muslims ...   \n",
       "16                                                                                           Article posted with permission from The Free Thought Project   \n",
       "17                                                                                                                                                      .   \n",
       "18    Likewise, when he claims that the Qur’an has “not a thing” to say about Sharia, he appears unaware that the Qur’an is one of the sources of Sharia.   \n",
       "19                                                                                            • Email: ghamilton@nationalpost.com | Twitter: grayhamilton   \n",
       "20                                                                                                                                               Delaware   \n",
       "21                                                                                                                                I haven’t looked it up.   \n",
       "22                                                                  \"I have grown accustomed to feeling unwelcome in Jewish spaces,\" Dan Fishback whines.   \n",
       "23                                                                                                         In doing so, he put other seminarians at risk.   \n",
       "24  In fact, the Gulf of Tonkin incident, as it became known, turned out to be a fictitious creation courtesy of the government to escalate war in Vie...   \n",
       "25                                           Cardinal Angelo Sodano was Secretary of State until September 2006: all information was communicated to him.   \n",
       "26  I first reported that 3-D guns were for real back in July of 2012, when an internet gunsmith by the name of \"Have Blue\" produced an AR style pisto...   \n",
       "27                                                                      “You voted NOT GUILTY on both counts at Bill Clinton’s impeachment,” she tweeted.   \n",
       "28  “Those cases are going to be haunting this papacy and really causing a rift in the major protection of children that Pope Benedict had worked very...   \n",
       "29                                                         Patel pleaded guilty Thursday in U.S. District Court to two counts of making false statements.   \n",
       "30  Las Vegas mass shooting victim Rocky Palermo was shot in the pelvis during the horrific attack and is now speaking out about what he saw and belie...   \n",
       "31                                                                                             To call them nativists and parade their moral superiority.   \n",
       "\n",
       "    pred  true  \n",
       "0      0     0  \n",
       "1      3     2  \n",
       "2      5     5  \n",
       "3      0     0  \n",
       "4      1     1  \n",
       "5      0     0  \n",
       "6      0     0  \n",
       "7      0     0  \n",
       "8      0     0  \n",
       "9      0     0  \n",
       "10     5     5  \n",
       "11     0     0  \n",
       "12     1     1  \n",
       "13     0     0  \n",
       "14     0     0  \n",
       "15     0     0  \n",
       "16     2     4  \n",
       "17     0     0  \n",
       "18     2     1  \n",
       "19     5     5  \n",
       "20     0     0  \n",
       "21     3     3  \n",
       "22     0     0  \n",
       "23     0     0  \n",
       "24     0     0  \n",
       "25     0     0  \n",
       "26     0     0  \n",
       "27     1     1  \n",
       "28     0     0  \n",
       "29     0     0  \n",
       "30     0     0  \n",
       "31     0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                    Doubt       1.00      1.00      1.00         3\n",
      "Exaggeration,Minimisation       0.00      0.00      0.00         1\n",
      "          Loaded_Language       1.00      0.75      0.86         4\n",
      "    Name_Calling,Labeling       0.00      0.00      0.00         1\n",
      "                        O       1.00      1.00      1.00        22\n",
      "               Repetition       0.50      1.00      0.67         1\n",
      "\n",
      "                 accuracy                           0.91        32\n",
      "                macro avg       0.58      0.62      0.59        32\n",
      "             weighted avg       0.92      0.91      0.91        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results(test_set,model,testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set,testing_loader = make_loader(seed=1236)\n",
    "show_results(test_set,model,testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(sent,label=-1):\n",
    "    \n",
    "    datf = pd.DataFrame(np.array([[sent,label,sent]])\n",
    "                   ,columns = ['full_sent','prop_1','context'])\n",
    "    \n",
    "    datf.prop_1 = datf.prop_1.astype('int')\n",
    "    present = Triage(datf,tokenizer,MAX_LEN)\n",
    "    pre_loader = DataLoader(present,**test_params)\n",
    "    pred,true = get_model_predictions(model, pre_loader,'multi')\n",
    "    \n",
    "    classify = rev_mapping[pred[0]]\n",
    "    \n",
    "    if label ==-1:\n",
    "        return str(classify)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trump_tweets = [\"An 'extremely credible' source has called my office and told me that @BarackObama's birth certificate is a fraud.\",\n",
    "                \"Sadly, because president Obama has done such a poor job as a president, you won't see another black president for generations!\",\n",
    "                'RIGGED ELECTION!',\n",
    "                \"On behalf of the entire Trump Family, I want to wish everyone a healthy and happy thanksgiving. \",\n",
    "               'The concept of global warming was created by and for the Chinese in order to make U.S. manufacturing non-competitive.',\n",
    "               'I have never seen a thin person drinking Diet Coke.'\n",
    "                \n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: An 'extremely credible' source has called my office and told me that @BarackObama's birth certificate is a fraud. \n",
      " Classification: Exaggeration,Minimisation \n",
      "\n",
      "Sentence: Sadly, because president Obama has done such a poor job as a president, you won't see another black president for generations! \n",
      " Classification: Exaggeration,Minimisation \n",
      "\n",
      "Sentence: RIGGED ELECTION! \n",
      " Classification: Loaded_Language \n",
      "\n",
      "Sentence: On behalf of the entire Trump Family, I want to wish everyone a healthy and happy thanksgiving.  \n",
      " Classification: O \n",
      "\n",
      "Sentence: The concept of global warming was created by and for the Chinese in order to make U.S. manufacturing non-competitive. \n",
      " Classification: O \n",
      "\n",
      "Sentence: I have never seen a thin person drinking Diet Coke. \n",
      " Classification: O \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweets in Trump_tweets:\n",
    "    print('Sentence:',tweets,'\\n','Classification:',demo(tweets),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sent = [('Until forced to act by a worldwide storm of outrage','Loaded_Language'), \n",
    "               ('Can the same be said for the Obama Administration?','Doubt'),\n",
    "               ('\"BUILD THE WALL!” Trump tweeted','Slogans'),\n",
    "               ('Heal the situation of extremely grave immoral behavior','Exaggeration, minimization'),\n",
    "               ('Dismissing the protesters as “lefties” and hugging Barros publicly','Name_Calling, Labeling')\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,l in random_sent:\n",
    "    print('Sentence:',s,'\\n','Classification:',demo(s),'\\n','True label:',l,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
