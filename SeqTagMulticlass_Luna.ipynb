{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqTagMulticlass_Luna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNy43ZSS9PayLN0f+9A7n3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhnguyen222/DPS-Silo/blob/master/SeqTagMulticlass_Luna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhCLMONDlKuI"
      },
      "source": [
        "Multi-class Sequence Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUWlk0prGfb-",
        "outputId": "12d5c1af-e7d1-4711-9508-800bf67a0610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81nDPb7ZGiZ_",
        "outputId": "5fefae44-d85a-4d45-89fd-87b9d1061e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov  8 23:04:06 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    38W / 300W |  14763MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2I7zW1qJ57m",
        "outputId": "f2badb03-678c-49e1-80ab-637b5c76f1a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip -q install trax==1.3.1\n",
        "\n",
        "import trax \n",
        "from trax import layers as tl\n",
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "#from pytorch_pretrained_bert import BertTokenizer\n",
        "import torch\n",
        "from pandas import DataFrame\n",
        "import random as rnd\n",
        "\n",
        "# set random seeds to make this notebook easier to replicate\n",
        "trax.supervised.trainer_lib.init_random_number_generators(33)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ 0, 33], dtype=uint32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD7i2z5wGnq2",
        "outputId": "9faaf2ed-ae65-4175-ecc0-e7c6fb2dab2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "traindirectory = '/content/drive/My Drive/DSP/data/protechn_corpus_eval/train'\n",
        "testDirectory = '/content/drive/My Drive/DSP/data/protechn_corpus_eval/test'\n",
        "devDirectory = '/content/drive/My Drive/DSP/data/protechn_corpus_eval/dev'"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJojhYR3GvpL"
      },
      "source": [
        "def read_data(directory):\n",
        "    ids = []\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for f in directory.glob('*.txt'):\n",
        "        id = f.name.replace('article', '').replace('.txt','')\n",
        "        ids.append(id)\n",
        "        texts.append(f.read_text())\n",
        "        labels.append(parse_label(f.as_posix().replace('.txt', '.labels.tsv')))\n",
        "    # labels can be empty \n",
        "    return ids, texts, labels\n",
        "\n",
        "def clean_text(articles, ids):\n",
        "    texts = []\n",
        "    for article, id in zip(articles, ids):\n",
        "        sentences = article.split('\\n')\n",
        "        start = 0\n",
        "        end = -1\n",
        "        res = []\n",
        "        for sentence in sentences:\n",
        "           start = end + 1\n",
        "           end = start + len(sentence)  # length of sequence \n",
        "           if sentence != \"\": # if not empty line\n",
        "               res.append([id, sentence, start, end])\n",
        "        texts.append(res)\n",
        "    return texts\n",
        "\n",
        "\n",
        "def make_dataset(directory):\n",
        "    ids, texts, labels = read_data(directory)\n",
        "    texts = clean_text(texts, ids)\n",
        "    res = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        # making positive examples\n",
        "        tmp = [] \n",
        "        pos_ind = [0] * len(text)\n",
        "        for l in label:\n",
        "            for i, sen in enumerate(text):\n",
        "                if l[0] >= sen[2] and l[0] < sen[3] and l[1] > sen[3]:\n",
        "                    l[4] = 1\n",
        "                    tmp.append(sen + [l[0], sen[3], l[2], l[3], l[4]])\n",
        "                    pos_ind[i] = 1\n",
        "                    l[0] = sen[3] + 1\n",
        "                elif l[0] != l[1] and l[0] >= sen[2] and l[0] < sen[3] and l[1] <= sen[3]: \n",
        "                    tmp.append(sen + l)\n",
        "                    pos_ind[i] = 1\n",
        "        # making negative examples\n",
        "        dummy = [0, 0, 'O', 0, 0]\n",
        "        for k, sen in enumerate(text):\n",
        "            if pos_ind[k] != 1:\n",
        "                tmp.append(sen+dummy)\n",
        "        res.append(tmp)     \n",
        "    return res"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJUHkt2YG6hf"
      },
      "source": [
        "def parse_label(label_path):\n",
        "    labels = []\n",
        "    f= Path(label_path)\n",
        "    \n",
        "    if not f.exists():\n",
        "        return labels\n",
        "\n",
        "    for line in open(label_path):\n",
        "        parts = line.strip().split('\\t')\n",
        "        labels.append([int(parts[2]), int(parts[3]), parts[1], 0, 0])\n",
        "    labels = sorted(labels) \n",
        "\n",
        "    if labels:\n",
        "        length = max([label[1] for label in labels]) \n",
        "        visit = np.zeros(length)\n",
        "        res = []\n",
        "        for label in labels:\n",
        "            if sum(visit[label[0]:label[1]]):\n",
        "                label[3] = 1\n",
        "            else:\n",
        "               visit[label[0]:label[1]] = 1\n",
        "            res.append(label)\n",
        "        return res \n",
        "    else:\n",
        "        return labels"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQuzpVmVHGFL"
      },
      "source": [
        "dataset=make_dataset(Path('/content/drive/My Drive/DSP/data/protechn_corpus_eval/train'))\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyBwoiuOHOvL"
      },
      "source": [
        "empty=[]\n",
        "for i in dataset:\n",
        "    \n",
        "    temp=DataFrame(i, columns=['id', 'full_sent', 'start_sent', 'end_sent', 'start_prop', 'end_prop','prop', 'ex1', 'ex2' ])\n",
        "    empty.append(temp)\n",
        "\n",
        "df=pd.concat(empty)  \n",
        "df = df.drop(['ex1'],axis =1).drop(['ex2'],axis =1)\n",
        "df.head()\n",
        "df.prop.value_counts()\n",
        "possible_labels=df.prop.unique()\n",
        "\"\"\"\n",
        "label_dict={}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label]=index\n",
        "print(label_dict)\n",
        "\"\"\"\n",
        "label_dict={'0': 0, 'Black-and-White_Fallacy': 1, 'Loaded_Language': 2, 'Flag-Waving': 3, \n",
        " 'Name_Calling,Labeling': 4, 'Slogans': 0, 'Causal_Oversimplification': 6, 'Whataboutism': 7,\n",
        " 'Exaggeration,Minimisation': 8, 'Doubt': 9, 'Appeal_to_Authority': 10, 'Repetition': 11, 'Appeal_to_fear-prejudice': 12,\n",
        " 'Thought-terminating_Cliches': 13, 'Bandwagon': 14, 'Red_Herring': 15, 'Reductio_ad_hitlerum': 16,\n",
        " 'Obfuscation,Intentional_Vagueness,Confusion': 17, 'Straw_Men': 18}\n",
        "df=df.reset_index()\n",
        "df.drop(['index'], axis=1)\n",
        "\n",
        "label_dict\n",
        "df['label']=df.prop.replace(label_dict)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYz3y6qNI2Te",
        "outputId": "cf137b46-fe7d-4f7a-dcf2-56ad9daae0f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df.shape[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_aacIuAI0Ny"
      },
      "source": [
        "df['binary']=10\n",
        "#df.at[1,'binary']=10\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hgbyp4vJlDn",
        "outputId": "2b028734-7f8b-4330-a372-477fa59be679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range (0, 15752):\n",
        "    if df.iloc[i]['label']==0 :\n",
        "        df.iloc[i]['binary']=0\n",
        "    else:\n",
        "        df.iloc[i]['binary']=1"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BvEBggl6FrQ",
        "outputId": "3e747c6a-31a3-4be3-85e1-227115404e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "df=pd.read_csv(Path(\"/content/export-train-seq\"))\n",
        "df.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "      <th>label</th>\n",
              "      <th>binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>111111112</td>\n",
              "      <td>Pamela Geller and Robert Spencer co-founded an...</td>\n",
              "      <td>129</td>\n",
              "      <td>220</td>\n",
              "      <td>191</td>\n",
              "      <td>220</td>\n",
              "      <td>Slogans</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>111111112</td>\n",
              "      <td>He added: \"We condemn all those whose behaviou...</td>\n",
              "      <td>465</td>\n",
              "      <td>603</td>\n",
              "      <td>476</td>\n",
              "      <td>556</td>\n",
              "      <td>Black-and-White_Fallacy</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>111111112</td>\n",
              "      <td>Ms Geller, of the Atlas Shrugs blog, and Mr Sp...</td>\n",
              "      <td>622</td>\n",
              "      <td>838</td>\n",
              "      <td>785</td>\n",
              "      <td>798</td>\n",
              "      <td>Slogans</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>111111112</td>\n",
              "      <td>On both of their blogs the pair called their b...</td>\n",
              "      <td>839</td>\n",
              "      <td>1014</td>\n",
              "      <td>911</td>\n",
              "      <td>942</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111111112</td>\n",
              "      <td>On both of their blogs the pair called their b...</td>\n",
              "      <td>839</td>\n",
              "      <td>1014</td>\n",
              "      <td>958</td>\n",
              "      <td>1014</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         id  ... label  binary\n",
              "0      0  111111112  ...     5     1.0\n",
              "1      1  111111112  ...     1     1.0\n",
              "2      2  111111112  ...     5     1.0\n",
              "3      3  111111112  ...     2     1.0\n",
              "4      4  111111112  ...     2     1.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7cXsbW4Xwgg"
      },
      "source": [
        "For the purpose of sequence tagging a subset dataframe is formed from those sentences which hold a propaganda technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qTDK5EO8RjT",
        "outputId": "fa26c37e-36c5-4c0c-f8a7-5b1e45cda83d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "only_prop_df=df[(df[\"binary\"] == 1)]\n",
        "print(only_prop_df.shape[0])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7IF55GX8bUj"
      },
      "source": [
        "    \n",
        "      \n",
        "def clean(test):\n",
        "    \n",
        "     return re.sub(r'''\n",
        "               [,.;“”*:`/\"@#-?!&_$()]+  # Accept one or more copies of punctuation\n",
        "               \\ *           # plus zero or more copies of a space,\n",
        "               ''',\n",
        "               \" \",          # and replace it with a single space\n",
        "               test, flags=re.VERBOSE).replace('[','').replace(']','')  \n",
        "\n",
        "           \n",
        "            "
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hBziaZ58ffP"
      },
      "source": [
        "import re"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFdoyAo9beaL"
      },
      "source": [
        "In this part each sentence is tagged such that words that signal a string of propaganda technique  are tagged as that technique and the rest of words in that sentence are tagged as none. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaHXW5c8Mv3"
      },
      "source": [
        "all_tagged=[]\n",
        "\"\"\"Pad token is 21\"\"\"\n",
        "\n",
        "for i in range (0, 5415):\n",
        "    #number of training example in one tsv file-length of each tsv dataframe\n",
        "    #length= list_data[i].shape[0]\n",
        "    #temp= nltk.sent_tokenize(s1[i])\n",
        "        \n",
        "    sentstart= only_prop_df.iloc[i][3]\n",
        "    sentend= only_prop_df.iloc[i][4]\n",
        "    propstart= only_prop_df.iloc[i][5]\n",
        "    propend= only_prop_df.iloc[i][6]\n",
        "    #label\n",
        "    propclass=only_prop_df.iloc[i][8]\n",
        "    count=0\n",
        "    if propstart !=sentstart:\n",
        "        #begin=df.iloc[i][4]\n",
        "        #end=df.iloc[i][5]\n",
        "        if propend !=sentend:\n",
        "            begin= propstart-sentstart\n",
        "            #proplength=propend_propstart   this is the length of the propaganda token\n",
        "            end=propend-propstart+begin\n",
        "            #beginstring.append(only_prop_df.iloc[i][2][:begin])\n",
        "            length1=len(clean(only_prop_df.iloc[i][2][:begin]).split())\n",
        "            begintag=[0]*length1\n",
        "            \n",
        "            #this is the substring that should be tagged\n",
        "            length2=len(clean(only_prop_df.iloc[i][2][begin:end]).split())\n",
        "            #midstring.append(clean(only_prop_df.iloc[i][2][begin:end]).split()\n",
        "            midtag=[propclass]*length2\n",
        "\n",
        "            \n",
        "            length3=len(clean(only_prop_df.iloc[i][2][end:]).split())\n",
        "            endtag=[0]*length3\n",
        "            \n",
        "            all_tagged.append(begintag+midtag+endtag)\n",
        "                  \n",
        "        else:\n",
        "            \n",
        "            begin= propstart-sentstart\n",
        "            #proplength=propend_propstart   this is the length of the propaganda token\n",
        "            #end=propend-propstart+begin\n",
        "            length1=len(clean(only_prop_df.iloc[i][2][:begin]).split())\n",
        "            begintag=[0]*length1\n",
        "            # this is what should be tagged\n",
        "            midstring=[]  \n",
        "            length2=len(clean(only_prop_df.iloc[i][2][begin:]).split())\n",
        "            midtag=[propclass]*length2\n",
        "            \n",
        "            all_tagged.append(begintag+midtag)\n",
        "\n",
        "            \n",
        "    else:\n",
        "        \n",
        "        if  propend !=sentend:\n",
        "            \n",
        "                    \n",
        "            #begin= propstart-sentstart\n",
        "            begin=0\n",
        "            #proplength=propend_propstart   this is the length of the propaganda token\n",
        "            end=propend-propstart\n",
        "            #this is the substring that should be tagged\n",
        "            length1=len(clean(only_prop_df.iloc[i][2][:end]).split())\n",
        "            begintag=[propclass]*length1\n",
        "            \n",
        "            length2=len(clean(only_prop_df.iloc[i][2][end:]).split())\n",
        "            endtag=[0]*length2\n",
        "            all_tagged.append(begintag+endtag)\n",
        "\n",
        "        else:  \n",
        "                       \n",
        "            length= len(clean(only_prop_df.iloc[i][2]).split())\n",
        "            tag=[propclass]*length\n",
        "            all_tagged.append(tag)\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHrblMQA8jIz",
        "outputId": "f418a111-2ac4-444d-8972-46409effed86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(all_tagged[0])\n",
        "print(\"size of all taged sentences from training set is:\", len(all_tagged))\n",
        "assert len(all_tagged)==(len(only_prop_df))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5]\n",
            "size of all taged sentences from training set is: 5415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeXwStxcLaK"
      },
      "source": [
        "The tag_map corresponds to one of the possible tags a word can have. The cell below highlights the  classes that will be predicting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB0oi01f86L-",
        "outputId": "5ee4f091-2b10-493f-bcc1-618b133d4387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tag_map= {'0': 0, 'Black-and-White_Fallacy': 1, 'Loaded_Language': 2, 'Flag-Waving': 3,\n",
        "  'Name_Calling,Labeling': 4, 'Slogans': 5, 'Causal_Oversimplification': 6, 'Whataboutism': 7, 'Exaggeration,Minimisation': 8,\n",
        "  'Doubt': 9, 'Appeal_to_Authority': 10, 'Repetition': 11, 'Appeal_to_fear-prejudice': 12, 'Thought-terminating_Cliches': 13,\n",
        "  'Bandwagon': 14, 'Red_Herring': 15, 'Reductio_ad_hitlerum': 16, 'Obfuscation,Intentional_Vagueness,Confusion': 17, 'Straw_Men': 18}\n",
        " \n",
        " \n",
        "full_sent= only_prop_df['full_sent'].tolist()\n",
        "print(tag_map)\n",
        " "
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0': 0, 'Black-and-White_Fallacy': 1, 'Loaded_Language': 2, 'Flag-Waving': 3, 'Name_Calling,Labeling': 4, 'Slogans': 5, 'Causal_Oversimplification': 6, 'Whataboutism': 7, 'Exaggeration,Minimisation': 8, 'Doubt': 9, 'Appeal_to_Authority': 10, 'Repetition': 11, 'Appeal_to_fear-prejudice': 12, 'Thought-terminating_Cliches': 13, 'Bandwagon': 14, 'Red_Herring': 15, 'Reductio_ad_hitlerum': 16, 'Obfuscation,Intentional_Vagueness,Confusion': 17, 'Straw_Men': 18}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awG4JEp_9Fkt"
      },
      "source": [
        "from string import punctuation\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilU8hgtbcm9h"
      },
      "source": [
        "vocab_to_int is a dictionary that translates a word string to a unique number. Given a sentence,then it is possible to  represent it as an array of numbers translating with this dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22SknMsvfR-g"
      },
      "source": [
        "We will create an index mapping dictionary in such a way that the frequently occurring words are assigned lower indexes.  Counter method from Collections library is used for this purpose. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO8FW5oZ8-Ti",
        "outputId": "e88ffaae-b03c-418b-bc6a-f76d6359f9f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(0,5415):\n",
        "    \n",
        "    \n",
        "    full_sent[i]=full_sent[i].lower()\n",
        "    full_sent[i]=clean(full_sent[i])\n",
        "    \n",
        "    \n",
        "#with space\n",
        "all_text2 = ' '.join([c for c in full_sent if c not in punctuation])\n",
        "#without space\n",
        "all_text2 = ''.join([c for c in all_text2 if c not in punctuation])    \n",
        " \n",
        "all_text2 = all_text2.split('\\n')\n",
        "all_text2 = ' '.join(all_text2)\n",
        "words2=all_text2.split()\n",
        "from collections import Counter\n",
        "\n",
        "counts = Counter(words2)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "\n",
        "#print(vocab)\n",
        "vocab_to_int = {word2: ii for ii, word2 in enumerate(vocab, 1)}\n",
        "#print(vocab_to_int)\n",
        "print('vocab[\"at\"]:', vocab_to_int[\"at\"])\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab[\"at\"]: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfEpXWWLB8cY"
      },
      "source": [
        "full_sent_split=[]\n",
        "for i in range(0, 5415):\n",
        "    full_sent_split.append(full_sent[i].split())\n",
        "    \n",
        "full_sent_ints = [] \n",
        "\n",
        "for i in range(5415):     \n",
        "    full_sent_ints.append([vocab_to_int[word] for word in full_sent_split[i]])\n",
        "    "
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU9-PceYJkzb",
        "outputId": "0a8dfde3-dadf-49b0-85cb-71dbe57bf3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(full_sent_ints))\n",
        "print(len(all_tagged))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5415\n",
            "5415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdEKKCShJHiL"
      },
      "source": [
        "vocab=vocab_to_int\n",
        "tag_map=tag_map\n",
        "t_sentences=full_sent_ints[:4500]\n",
        "t_labels=all_tagged[:4500]\n",
        "t_size=len(t_labels)\n",
        "v_sentences=full_sent_ints[4500:5000]\n",
        "v_labels=all_tagged[4500:5000]\n",
        "v_size=len(v_labels)\n",
        "test_sentences=full_sent_ints[5000:]\n",
        "test_labels=all_tagged[5000:]\n",
        "test_size=len(test_labels)\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFWlbplxXMD4",
        "outputId": "4f594a02-2fe2-40d4-d50e-5e51395d8a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(t_sentences[1])\n",
        "print(t_labels[1])\n",
        "print(t_size)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15, 620, 36, 2308, 37, 88, 244, 7996, 4, 962, 963, 3325, 3, 48, 4703, 1162, 4, 40, 23, 642, 9, 4704, 6, 74, 964]\n",
            "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "4500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36xarsLOMlgw",
        "outputId": "81b13202-2f6d-4e36-a902-ea19b32e76c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Exploring information about the data\n",
        "print('The number of outputs in tag_map is: ', len(tag_map))\n",
        "# The number of vocabulary tokens (including <PAD>)\n",
        "g_vocab_size = len(vocab)\n",
        "print(f\"Num of vocabulary words: {g_vocab_size}\")\n",
        "print('The vocab size is:', len(vocab))\n",
        "print('The training size is: ', t_size)\n",
        "print('The validation size is: ', v_size)\n",
        "print('An example of the first sentence is: ', t_sentences[0])\n",
        "print('An example of its corresponding label is: ', t_labels[0])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of outputs in tag_map is:  19\n",
            "Num of vocabulary words: 11665\n",
            "The vocab size is: 11665\n",
            "The training size is:  4500\n",
            "The validation size is:  500\n",
            "An example of the first sentence is:  [3323, 1907, 4, 808, 3324, 1380, 3899, 158, 114, 303, 232, 1908, 2, 168]\n",
            "An example of its corresponding label is:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuhonyDbIbkL"
      },
      "source": [
        "# data_generator behaves like an iterator; it will return the next item \n",
        "def data_generator(batch_size, x, y, pad, shuffle=False, verbose=False):\n",
        "    '''\n",
        "      Output:\n",
        "        a tuple containing 2 elements:\n",
        "        X - np.ndarray of dim (batch_size, max_len) of padded sentences\n",
        "        Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X\n",
        "    '''\n",
        "    \n",
        "    # count the number of lines in data_lines\n",
        "    num_lines = len(x)\n",
        "    \n",
        "    # create an array with the indexes of data_lines that can be shuffled\n",
        "    lines_index = [*range(num_lines)]\n",
        "    \n",
        "    # shuffle the indexes if shuffle is set to True\n",
        "    if shuffle:\n",
        "        rnd.shuffle(lines_index)\n",
        "    \n",
        "    index = 0 # tracks current location in x, y\n",
        "    while True:\n",
        "        buffer_x = [0] * batch_size # Temporal array to store the raw x data for this batch\n",
        "        buffer_y = [0] * batch_size \n",
        "                \n",
        "        \n",
        "        \n",
        "        # Find maximum length of sentences in x[index : index + batch_size] for this batch. \n",
        "        max_len = 0\n",
        "        for i in range(batch_size):\n",
        "            if index >= num_lines:\n",
        "                index = 0\n",
        "                if shuffle:\n",
        "                    rnd.shuffle(lines_index)\n",
        "            \n",
        "            # The current position is obtained using `lines_index[index]`\n",
        "            buffer_x[i] = x[lines_index[index]]\n",
        "            \n",
        "            # Store the y value at the current position into the buffer_y\n",
        "            buffer_y[i] = y[lines_index[index]]\n",
        "            \n",
        "            lenx = len(x[lines_index[index]])     #length of current x[]\n",
        "            if lenx > max_len:\n",
        "                max_len = lenx                   #max_len tracks longest x[]\n",
        "            \n",
        "            # increment index by one\n",
        "            index += 1\n",
        "\n",
        "\n",
        "        # create X,Y, NumPy arrays of size (batch_size, max_len)\n",
        "        X = np.full((batch_size, max_len), pad)\n",
        "        Y = np.full((batch_size, max_len), pad)\n",
        "\n",
        "        # copy values from lists to NumPy arrays. \n",
        "        for i in range(batch_size):\n",
        "            # get the example (sentence as a tensor)\n",
        "            x_i = buffer_x[i]\n",
        "            \n",
        "            # similarly, get the example's labels\n",
        "            # in `buffer_y` at the `i` index\n",
        "            y_i = buffer_y[i]\n",
        "            \n",
        "            # Walk through each word in x_i\n",
        "            for j in range(len(x_i)):\n",
        "                # store the word in x_i at position j into X\n",
        "                X[i, j] = x_i[j]\n",
        "                \n",
        "                # store the label in y_i at position j into Y\n",
        "                Y[i, j] = y_i[j]\n",
        "\n",
        "        if verbose: print(\"index=\", index)\n",
        "        yield((X,Y))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2SDsuy4Jeu9",
        "outputId": "bc9ef7fd-8d3a-4af6-acae-47f7aa7f31a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 5\n",
        "mini_sentences = t_sentences[0: 8]\n",
        "mini_labels = t_labels[0: 8]\n",
        "dg = data_generator(batch_size, mini_sentences, mini_labels, 12121, shuffle=False, verbose=True)\n",
        "X1, Y1 = next(dg)\n",
        "X2, Y2 = next(dg)\n",
        "print(Y1.shape, X1.shape, Y2.shape, X2.shape)\n",
        "print(X1[0][:], \"\\n\", Y1[0][:])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index= 5\n",
            "index= 2\n",
            "(5, 38) (5, 38) (5, 25) (5, 25)\n",
            "[ 3323  1907     4   808  3324  1380  3899   158   114   303   232  1908\n",
            "     2   168 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121\n",
            " 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121\n",
            " 12121 12121] \n",
            " [    0     0     0     0     0     0     0     0     0     0     5     5\n",
            "     5     5 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121\n",
            " 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121 12121\n",
            " 12121 12121]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZb4dxnjN2VJ"
      },
      "source": [
        "\n",
        "def NER(vocab_size=35181, d_model=50, tags=tag_map):\n",
        "    '''\n",
        "      Input: \n",
        "        vocab_size - integer containing the size of the vocabulary\n",
        "        d_model - integer describing the embedding size\n",
        "      Output:\n",
        "        model - a serial model\n",
        "    '''\n",
        "    model = tl.Serial(\n",
        "        tl.Embedding(vocab_size, d_model), # Embedding layer\n",
        "     tl.LSTM(d_model), # LSTM layer\n",
        "      tl.Dense(len(tags)), # Dense layer with len(tags) units\n",
        "      tl.LogSoftmax()# LogSoftmax layer\n",
        "      )\n",
        "    return model"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mtqivyzN3Ux",
        "outputId": "3f713e69-2821-41a4-b3d1-1f57a467ee63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# initializing the model\n",
        "model = NER()\n",
        "# display the model\n",
        "print(model)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Embedding_35181_50\n",
            "  LSTM_50\n",
            "  Dense_19\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-u1zzJN7ft"
      },
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "rnd.seed(33)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create training data, mask pad id=12121 for training\n",
        "train_generator = trax.supervised.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, t_sentences, t_labels, 12121, True),\n",
        "    id_to_mask=12121)\n",
        "\n",
        "# Create validation data, mask pad id=12121 for training\n",
        "eval_generator = trax.supervised.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, v_sentences, v_labels, 12121, True),\n",
        "    id_to_mask=12121)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqbRofSaOGFd"
      },
      "source": [
        "# train_model\n",
        "def train_model(NER, train_generator, eval_generator, train_steps=1, output_dir='model'):\n",
        "    '''\n",
        "    Input: \n",
        "        NER - the model you are building\n",
        "        train_generator - The data generator for training examples\n",
        "        eval_generator - The data generator for validation examples,\n",
        "        train_steps - number of training steps\n",
        "        output_dir - folder to save your model\n",
        "    Output:\n",
        "        training_loop - a trax supervised training Loop\n",
        "    '''\n",
        "    train_task = training.TrainTask(\n",
        "      train_generator, # A train data generator\n",
        "      loss_layer = tl.CrossEntropyLoss(), # A cross-entropy loss function\n",
        "      optimizer = trax.optimizers.Adam(0.01),  # The adam optimizer\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "      labeled_data = eval_generator, # A labeled data generator\n",
        "      metrics = [tl.CrossEntropyLoss(), tl.Accuracy()], # Evaluate with cross-entropy loss and accuracy\n",
        "      n_eval_batches = 10 # Number of batches to use on each evaluation\n",
        "    )\n",
        "\n",
        "    training_loop = training.Loop(\n",
        "        NER, # A model to train\n",
        "        train_task, # A train task\n",
        "        eval_task = eval_task, # The evaluation task\n",
        "        output_dir = output_dir) # The output directory\n",
        "\n",
        "    # Train with train_steps\n",
        "    training_loop.run(n_steps = train_steps)\n",
        "    return training_loop"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d4yGVRhTqRa",
        "outputId": "80af3825-39ef-4659-b25d-afa2c40e6085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_steps = 100            \n",
        "!rm -f 'model/model.pkl.gz'  # Remove old model.pkl if it exists\n",
        "\n",
        "# Train the model\n",
        "training_loop = train_model(NER(), train_generator, eval_generator, train_steps)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step      1: train CrossEntropyLoss |  2.83612227\n",
            "Step      1: eval  CrossEntropyLoss |  2.07690383\n",
            "Step      1: eval          Accuracy |  0.68264646\n",
            "Step    100: train CrossEntropyLoss |  1.22409749\n",
            "Step    100: eval  CrossEntropyLoss |  1.35256333\n",
            "Step    100: eval          Accuracy |  0.69497184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP4sf6Lphtxr"
      },
      "source": [
        "# loading in a pretrained model..\n",
        "model = NER()\n",
        "model.init(trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
        "\n",
        "# Load the pretrained model\n",
        "model.init_from_file('/content/model/model.pkl.gz', weights_only=True)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhpfOubkTwzo",
        "outputId": "36729778-e602-48f2-bf6d-48eddc6ebe14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Example of a comparision on a matrix \n",
        "a = np.array([1, 2, 3, 4])\n",
        "a == 2"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFdVTASKU81i",
        "outputId": "40b2bda0-b866-44d7-bcf8-3329bba3d8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create the evaluation inputs\n",
        "x, y = next(data_generator(len(test_sentences), test_sentences, test_labels, 12121))\n",
        "print(\"input shapes\", x.shape, y.shape)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shapes (415, 98) (415, 98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyjHMNQniB-k",
        "outputId": "e5161dd6-52b1-429b-b419-1df669db9139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# sample prediction\n",
        "tmp_pred = model(x)\n",
        "print(type(tmp_pred))\n",
        "print(f\"tmp_pred has shape: {tmp_pred.shape}\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'jax.interpreters.xla.DeviceArray'>\n",
            "tmp_pred has shape: (415, 98, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jblsKCq2VfnG"
      },
      "source": [
        "#  evaluate_prediction\n",
        "def evaluate_prediction(pred, labels, pad):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        pred: prediction array with shape \n",
        "            (num examples, max sentence length in batch, num of classes)\n",
        "        labels: array of size (batch_size, seq_len)\n",
        "        pad: integer representing pad character\n",
        "    Outputs:\n",
        "        accuracy: float\n",
        "    \"\"\"\n",
        "    outputs = np.argmax(pred, axis=2)\n",
        "    print(\"outputs shape:\", outputs.shape)\n",
        "\n",
        "    mask = labels !=pad\n",
        "    print(\"mask shape:\", mask.shape, \"mask[0][20:30]:\", mask[0][20:30])\n",
        "    accuracy = np.sum(outputs == labels) / float(np.sum(mask))\n",
        "    return accuracy"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNQ2c0nsVgZ0",
        "outputId": "909327fa-7d1a-4d14-8a76-d42eed46339f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy = evaluate_prediction(model(x), y, 12121)\n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outputs shape: (415, 98)\n",
            "mask shape: (415, 98) mask[0][20:30]: [ True  True  True  True  True  True  True  True  True  True]\n",
            "accuracy:  0.5767786914551305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8rhvgKolmkN"
      },
      "source": [
        "# Try the output for the introduction example\n",
        "#sentence_for_Appeal_to_authority = \"Only police and law knows about this\"\n",
        "#sentence_for_Doubt = \"We are unsure as this is unclear how to be done\"\n",
        "\n",
        "sentence_for_exageration = \"This policy is terribly very wrong\"\n",
        "#s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWVNqVco1bi",
        "outputId": "1a1e4df1-08b4-4cc9-a617-77531d8e6258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_sentence(test_sen):\n",
        "    test_sen = test_sen.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_sen if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_sent = tokenize_sentence(sentence_for_exageration)\n",
        "print(test_sent)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14, 622, 8, 7517, 103, 778]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}