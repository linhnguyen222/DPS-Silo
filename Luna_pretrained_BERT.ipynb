{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Luna_pretrained_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPY5qaMda3E7W8kyBNzpzTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ff8b043bbfd4971bea6bcfa5c89d296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f47d35ac58a45f490a1436a996c8377",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1eaeef3904d41e9ab201c2ba475d537",
              "IPY_MODEL_05f32fc533bf41589684e621c83f7ca4"
            ]
          }
        },
        "9f47d35ac58a45f490a1436a996c8377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1eaeef3904d41e9ab201c2ba475d537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fb570096d214644afa8e515ee9146b7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a101d6a440dd4227ac3581373598b57f"
          }
        },
        "05f32fc533bf41589684e621c83f7ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a7812e58c171481c91bfd058bef05ffb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 825kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c05c83152ca400b9c043c3f0d1a1d77"
          }
        },
        "2fb570096d214644afa8e515ee9146b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a101d6a440dd4227ac3581373598b57f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7812e58c171481c91bfd058bef05ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c05c83152ca400b9c043c3f0d1a1d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63e6aae062744e68bd2d7a14cb00f5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30d600025c374d7bb44b77d6d3b5e6ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd461ca49cde4b4fae97ef55bb523f1d",
              "IPY_MODEL_5effd48efa8243dc9a248a6610db8a4d"
            ]
          }
        },
        "30d600025c374d7bb44b77d6d3b5e6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd461ca49cde4b4fae97ef55bb523f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67588845db3d47099569472740f6eed4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e679578a8ff42f3be4a8e6a96ad94e3"
          }
        },
        "5effd48efa8243dc9a248a6610db8a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_066c859b65174bd592acf10e8a35941c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 996B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12c5930904e6402abe6c63e8cc008cc6"
          }
        },
        "67588845db3d47099569472740f6eed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e679578a8ff42f3be4a8e6a96ad94e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "066c859b65174bd592acf10e8a35941c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12c5930904e6402abe6c63e8cc008cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a2b03408df244748ac7f6c6e3fa1013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76bfe71cf31240c19760f21f101745ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_367666947a7643cdaf9949b8737c0c7b",
              "IPY_MODEL_b42d50b1f8c74549bdca9e569de542b3"
            ]
          }
        },
        "76bfe71cf31240c19760f21f101745ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "367666947a7643cdaf9949b8737c0c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c36d1b07ef64137956607ff290775b3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3ef932e53e46aba01405cc9b738877"
          }
        },
        "b42d50b1f8c74549bdca9e569de542b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d6c11b64d6846bf8a089067c11fd20b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 75.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2037e064bad4e8d8361e6efead3f24b"
          }
        },
        "6c36d1b07ef64137956607ff290775b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3ef932e53e46aba01405cc9b738877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d6c11b64d6846bf8a089067c11fd20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2037e064bad4e8d8361e6efead3f24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhnguyen222/DPS-Silo/blob/master/Luna_pretrained_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUwT_vy3GA1O"
      },
      "source": [
        "###Pre trained BERT model for full sentence multiclass classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb_bqfFBV-gU",
        "outputId": "7a056a47-b193-4746-bb7a-39257a58239e"
      },
      "source": [
        "from platform import python_version\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "#from pytorch_pretrained_bert import BertTokenizer\n",
        "import torch\n",
        "from pandas import DataFrame\n",
        "\n",
        "\n",
        "print(python_version())\n",
        "print (tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gwLfAfnZElz",
        "outputId": "b8a0a707-08c7-4a55-e77a-406f7369ca51"
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOB13ua3bYtQ"
      },
      "source": [
        "####Helper functions to read in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPJhRSocZPaf"
      },
      "source": [
        "def read_data(directory):\n",
        "    ids = []\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for f in directory.glob('*.txt'):\n",
        "        id = f.name.replace('article', '').replace('.txt','')\n",
        "        ids.append(id)\n",
        "        texts.append(f.read_text())\n",
        "        labels.append(parse_label(f.as_posix().replace('.txt', '.labels.tsv')))\n",
        "    # labels can be empty \n",
        "    return ids, texts, labels\n",
        "\n",
        "def clean_text(articles, ids):\n",
        "    texts = []\n",
        "    for article, id in zip(articles, ids):\n",
        "        sentences = article.split('\\n')\n",
        "        start = 0\n",
        "        end = -1\n",
        "        res = []\n",
        "        for sentence in sentences:\n",
        "           start = end + 1\n",
        "           end = start + len(sentence)  # length of sequence \n",
        "           if sentence != \"\": # if not empty line\n",
        "               res.append([id, sentence, start, end])\n",
        "        texts.append(res)\n",
        "    return texts\n",
        "\n",
        "\n",
        "def make_dataset(directory):\n",
        "    ids, texts, labels = read_data(directory)\n",
        "    texts = clean_text(texts, ids)\n",
        "    res = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        # making positive examples\n",
        "        tmp = [] \n",
        "        pos_ind = [0] * len(text)\n",
        "        for l in label:\n",
        "            for i, sen in enumerate(text):\n",
        "                if l[0] >= sen[2] and l[0] < sen[3] and l[1] > sen[3]:\n",
        "                    l[4] = 1\n",
        "                    tmp.append(sen + [l[0], sen[3], l[2], l[3], l[4]])\n",
        "                    pos_ind[i] = 1\n",
        "                    l[0] = sen[3] + 1\n",
        "                elif l[0] != l[1] and l[0] >= sen[2] and l[0] < sen[3] and l[1] <= sen[3]: \n",
        "                    tmp.append(sen + l)\n",
        "                    pos_ind[i] = 1\n",
        "        # making negative examples\n",
        "        dummy = [0, 0, 'O', 0, 0]\n",
        "        for k, sen in enumerate(text):\n",
        "            if pos_ind[k] != 1:\n",
        "                tmp.append(sen+dummy)\n",
        "        res.append(tmp)     \n",
        "    return res\n",
        "  \n",
        "def parse_label(label_path):\n",
        "    labels = []\n",
        "    f= Path(label_path)\n",
        "    \n",
        "    if not f.exists():\n",
        "        return labels\n",
        "\n",
        "    for line in open(label_path):\n",
        "        parts = line.strip().split('\\t')\n",
        "        labels.append([int(parts[2]), int(parts[3]), parts[1], 0, 0])\n",
        "    labels = sorted(labels) \n",
        "\n",
        "    if labels:\n",
        "        length = max([label[1] for label in labels]) \n",
        "        visit = np.zeros(length)\n",
        "        res = []\n",
        "        for label in labels:\n",
        "            if sum(visit[label[0]:label[1]]):\n",
        "                label[3] = 1\n",
        "            else:\n",
        "               visit[label[0]:label[1]] = 1\n",
        "            res.append(label)\n",
        "        return res \n",
        "    else:\n",
        "        return labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnUTW4QmRX4t"
      },
      "source": [
        "####Importing train and test set and reading them in as dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIMmocTPZWvh"
      },
      "source": [
        "#train set\n",
        "dataset_train=make_dataset(Path('/content/drive/My Drive/DSP/data/protechn_corpus_eval/train'))\n",
        "#test set\n",
        "dataset_test=make_dataset(Path('/content/drive/My Drive/DSP/data/protechn_corpus_eval/test'))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "EjK83ZbabDvD",
        "outputId": "b3b6ebb4-b3d7-42ba-bc75-53d9111cbee6"
      },
      "source": [
        "#train dataframe\n",
        "empty=[]\n",
        "for i in dataset_train:\n",
        "    \n",
        "    temp=DataFrame(i, columns=['id', 'full_sent', 'start_sent', 'end_sent', 'start_prop', 'end_prop','prop', 'ex1', 'ex2' ])\n",
        "    empty.append(temp)\n",
        "\n",
        "df_train=pd.concat(empty)  \n",
        "df_train = df_train.drop(['ex1'],axis =1).drop(['ex2'],axis =1)\n",
        "df_train.prop.value_counts()\n",
        "df_train=df_train.reset_index()\n",
        "#del df['index']\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They interpreted the law in my case to say it...</td>\n",
              "      <td>1695</td>\n",
              "      <td>1873</td>\n",
              "      <td>1831</td>\n",
              "      <td>1872</td>\n",
              "      <td>Whataboutism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Two guys on my ship did the same thing and wer...</td>\n",
              "      <td>1905</td>\n",
              "      <td>1977</td>\n",
              "      <td>1925</td>\n",
              "      <td>1976</td>\n",
              "      <td>Whataboutism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They used me as an example because of [the ba...</td>\n",
              "      <td>2312</td>\n",
              "      <td>2454</td>\n",
              "      <td>2312</td>\n",
              "      <td>2388</td>\n",
              "      <td>Causal_Oversimplification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>The government actively destroyed his life an ...</td>\n",
              "      <td>2710</td>\n",
              "      <td>2819</td>\n",
              "      <td>2725</td>\n",
              "      <td>2782</td>\n",
              "      <td>Exaggeration,Minimisation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Ex-Sailor Pardoned By Trump Says He’s SUING Ob...</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index          id  ... end_prop                       prop\n",
              "0      0  7618745059  ...     1872               Whataboutism\n",
              "1      1  7618745059  ...     1976               Whataboutism\n",
              "2      2  7618745059  ...     2388  Causal_Oversimplification\n",
              "3      3  7618745059  ...     2782  Exaggeration,Minimisation\n",
              "4      4  7618745059  ...        0                          O\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDzgaXAOQ7R5"
      },
      "source": [
        "#### We define a new column (called 'label') to turn string labels into integer labels by using a defined label dictionary that maps each propaganda technique to an integer representing that class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrERNLRMb3Tc"
      },
      "source": [
        "\"\"\"\n",
        "label_dict={}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label]=index\n",
        "print(label_dict)\n",
        "\"\"\"\n",
        "label_dict={'O': 0, 'Black-and-White_Fallacy': 1, 'Loaded_Language': 2, 'Flag-Waving': 3, \n",
        " 'Name_Calling,Labeling': 4, 'Slogans': 5, 'Causal_Oversimplification': 6, 'Whataboutism': 7,\n",
        " 'Exaggeration,Minimisation': 8, 'Doubt': 9, 'Appeal_to_Authority': 10, 'Repetition': 11, 'Appeal_to_fear-prejudice': 12,\n",
        " 'Thought-terminating_Cliches': 13, 'Bandwagon': 14, 'Red_Herring': 15, 'Reductio_ad_hitlerum': 16,\n",
        " 'Obfuscation,Intentional_Vagueness,Confusion': 17, 'Straw_Men': 18}\n",
        "\n",
        "df_train['label']=df_train.prop.replace(label_dict)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "SkyD-qGlb59V",
        "outputId": "22c8c19c-61db-4900-9e1c-2cff7df3eb6a"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They interpreted the law in my case to say it...</td>\n",
              "      <td>1695</td>\n",
              "      <td>1873</td>\n",
              "      <td>1831</td>\n",
              "      <td>1872</td>\n",
              "      <td>Whataboutism</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Two guys on my ship did the same thing and wer...</td>\n",
              "      <td>1905</td>\n",
              "      <td>1977</td>\n",
              "      <td>1925</td>\n",
              "      <td>1976</td>\n",
              "      <td>Whataboutism</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They used me as an example because of [the ba...</td>\n",
              "      <td>2312</td>\n",
              "      <td>2454</td>\n",
              "      <td>2312</td>\n",
              "      <td>2388</td>\n",
              "      <td>Causal_Oversimplification</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>The government actively destroyed his life an ...</td>\n",
              "      <td>2710</td>\n",
              "      <td>2819</td>\n",
              "      <td>2725</td>\n",
              "      <td>2782</td>\n",
              "      <td>Exaggeration,Minimisation</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Ex-Sailor Pardoned By Trump Says He’s SUING Ob...</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index          id  ...                       prop  label\n",
              "0      0  7618745059  ...               Whataboutism      7\n",
              "1      1  7618745059  ...               Whataboutism      7\n",
              "2      2  7618745059  ...  Causal_Oversimplification      6\n",
              "3      3  7618745059  ...  Exaggeration,Minimisation      8\n",
              "4      4  7618745059  ...                          O      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPz-S-Vp6vG_",
        "outputId": "1759d3e9-14b6-4ac9-b5f2-80f5313dfa12"
      },
      "source": [
        "df_train.dtypes\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index          int64\n",
              "id            object\n",
              "full_sent     object\n",
              "start_sent     int64\n",
              "end_sent       int64\n",
              "start_prop     int64\n",
              "end_prop       int64\n",
              "prop          object\n",
              "label          int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGrTE7Cf66YB",
        "outputId": "276f134a-ff81-4190-f622-9795c0466d6d"
      },
      "source": [
        "type(df_train['full_sent'][0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAZbK5ZnbgPU"
      },
      "source": [
        "####Dataset is imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdv3sqYKS00j",
        "outputId": "7fdbc9e1-df5d-4516-f638-7ab127c6b713"
      },
      "source": [
        "#data is not unitedly distributed in different classes i.e., we have a class imbalance\n",
        "df_train.prop.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O                                              10337\n",
              "Loaded_Language                                 1832\n",
              "Name_Calling,Labeling                            934\n",
              "Doubt                                            527\n",
              "Repetition                                       465\n",
              "Exaggeration,Minimisation                        401\n",
              "Appeal_to_fear-prejudice                         225\n",
              "Flag-Waving                                      216\n",
              "Causal_Oversimplification                        199\n",
              "Appeal_to_Authority                              129\n",
              "Black-and-White_Fallacy                          123\n",
              "Slogans                                          123\n",
              "Thought-terminating_Cliches                       72\n",
              "Whataboutism                                      59\n",
              "Reductio_ad_hitlerum                              48\n",
              "Red_Herring                                       26\n",
              "Bandwagon                                         13\n",
              "Straw_Men                                         12\n",
              "Obfuscation,Intentional_Vagueness,Confusion       11\n",
              "Name: prop, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo1uiBxcTA4F",
        "outputId": "ad63b234-f1b1-4079-9b54-6b54a4ed810e"
      },
      "source": [
        "df_train.label.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     10337\n",
              "2      1832\n",
              "4       934\n",
              "9       527\n",
              "11      465\n",
              "8       401\n",
              "12      225\n",
              "3       216\n",
              "6       199\n",
              "10      129\n",
              "5       123\n",
              "1       123\n",
              "13       72\n",
              "7        59\n",
              "16       48\n",
              "15       26\n",
              "14       13\n",
              "18       12\n",
              "17       11\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "HhN7qfWkcEAh",
        "outputId": "8ffc6b01-42bf-44ef-ab53-39f4d123dc73"
      },
      "source": [
        "#test dataframe\n",
        "empty=[]\n",
        "for i in dataset_test:\n",
        "    \n",
        "    temp=DataFrame(i, columns=['id', 'full_sent', 'start_sent', 'end_sent', 'start_prop', 'end_prop','prop', 'ex1', 'ex2' ])\n",
        "    empty.append(temp)\n",
        "\n",
        "df_test=pd.concat(empty)  \n",
        "df_test = df_test.drop(['ex1'],axis =1).drop(['ex2'],axis =1)\n",
        "df_test.prop.value_counts()\n",
        "df_test=df_test.reset_index()\n",
        "#del df['index']\n",
        "\n",
        "df_test.head()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>111111133</td>\n",
              "      <td>CNN in turn dropped its lawsuit on the matter,...</td>\n",
              "      <td>301</td>\n",
              "      <td>415</td>\n",
              "      <td>358</td>\n",
              "      <td>367</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>460</td>\n",
              "      <td>465</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>504</td>\n",
              "      <td>507</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>111111133</td>\n",
              "      <td>The White House sought to blame Mr. Acosta for...</td>\n",
              "      <td>967</td>\n",
              "      <td>1167</td>\n",
              "      <td>1070</td>\n",
              "      <td>1077</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111111133</td>\n",
              "      <td>Codifying the behavior of journalists struck s...</td>\n",
              "      <td>1168</td>\n",
              "      <td>1391</td>\n",
              "      <td>1224</td>\n",
              "      <td>1244</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         id  ... end_prop             prop\n",
              "0      0  111111133  ...      367  Loaded_Language\n",
              "1      1  111111133  ...      465  Loaded_Language\n",
              "2      2  111111133  ...      507  Loaded_Language\n",
              "3      3  111111133  ...     1077  Loaded_Language\n",
              "4      4  111111133  ...     1244  Loaded_Language\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXNRjmwtcH71"
      },
      "source": [
        "\n",
        "df_test['label']=df_test.prop.replace(label_dict)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "kiR8kpuWYwqa",
        "outputId": "89dc3fbf-8e06-4d99-b65c-34bbf643a742"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>111111133</td>\n",
              "      <td>CNN in turn dropped its lawsuit on the matter,...</td>\n",
              "      <td>301</td>\n",
              "      <td>415</td>\n",
              "      <td>358</td>\n",
              "      <td>367</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>460</td>\n",
              "      <td>465</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>504</td>\n",
              "      <td>507</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>111111133</td>\n",
              "      <td>The White House sought to blame Mr. Acosta for...</td>\n",
              "      <td>967</td>\n",
              "      <td>1167</td>\n",
              "      <td>1070</td>\n",
              "      <td>1077</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111111133</td>\n",
              "      <td>Codifying the behavior of journalists struck s...</td>\n",
              "      <td>1168</td>\n",
              "      <td>1391</td>\n",
              "      <td>1224</td>\n",
              "      <td>1244</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         id  ...             prop  label\n",
              "0      0  111111133  ...  Loaded_Language      2\n",
              "1      1  111111133  ...  Loaded_Language      2\n",
              "2      2  111111133  ...  Loaded_Language      2\n",
              "3      3  111111133  ...  Loaded_Language      2\n",
              "4      4  111111133  ...  Loaded_Language      2\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgGXF7vDqGNx"
      },
      "source": [
        "\n",
        "\n",
        "####If we wanted to test this model with Augmented Data then we would be running these lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbK7IG3YoJmE",
        "outputId": "0df4ba29-0396-4d2e-b409-d6a62923348f"
      },
      "source": [
        "print(\"size of train set is: \", df_train.shape[0])\n",
        "print(\"size of test set is: \", df_test.shape[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of train set is:  15752\n",
            "size of test set is:  4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i-9fKeEqNKc"
      },
      "source": [
        "#df_new=pd.read_csv(Path(\"/content/ADD_Context.csv\"))\n",
        "#df_new.head()\n",
        "#df_new['Sentence'].isnull()\n",
        "#df_new.isnull().values.any()\n",
        "#df_new = df_new.dropna()\n",
        "#df_new.isnull().values.any()\n",
        "#df_new['label']=df_new.Label.replace(label_dict)\n",
        "#df_new = df_new.rename(columns = {'Sentence':'full_sent'})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8bvAc9BzEJZ"
      },
      "source": [
        "#df_train=df_new.iloc[0:20000, 0:5]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtpmVCyO0dE1"
      },
      "source": [
        "#df_train=df_train.reset_index()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAnxPUqc3UPi"
      },
      "source": [
        "#df_test=df_new.iloc[20000:, 0:5]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dikQ16z0clPO",
        "outputId": "f6823182-700d-4981-a99b-74c5553e6a7c"
      },
      "source": [
        "!pip install transformers\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6e591a954a80a3e3c565ed01a96898c810c8e113a2e08c60cfd6cfdf916e13a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dHao83SbkVw"
      },
      "source": [
        "###The tokenizer takes in raw text and splits it into tokens. A token in this case is a numerical number that represents a certain word. Tensordataset makes it possible to use the data set in a pytorch environment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIsohV5WcR8t"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQOOtbjbtVD"
      },
      "source": [
        "###We use a pretrained BERT to encode our dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKIsKhCcSZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2ff8b043bbfd4971bea6bcfa5c89d296",
            "9f47d35ac58a45f490a1436a996c8377",
            "b1eaeef3904d41e9ab201c2ba475d537",
            "05f32fc533bf41589684e621c83f7ca4",
            "2fb570096d214644afa8e515ee9146b7",
            "a101d6a440dd4227ac3581373598b57f",
            "a7812e58c171481c91bfd058bef05ffb",
            "8c05c83152ca400b9c043c3f0d1a1d77"
          ]
        },
        "outputId": "39b2c6fd-1474-4671-a2a3-e7ad1a414dcf"
      },
      "source": [
        "#we will be using all lower case data\n",
        "#do_lower_case converts every string to lower case as an uncased version of BERT will be used\n",
        "tokenizer= BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ff8b043bbfd4971bea6bcfa5c89d296",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJxs6_F6h5Po"
      },
      "source": [
        "####Now we need to convert all our sentences from language into encoded form. Batch encode class can perform this as it can take multiple strings and convert them into tokens as is needed. This is done separately for train and test data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejywm5LKcxjy",
        "outputId": "bb267c34-6909-4d34-86df-560e138617b6"
      },
      "source": [
        "\"\"\" As parameters it takes actual sentences, add special tokens will highlight when a sentences ends and when a new one begins, \n",
        "an attention mask tells the model where the relevant information in a sentence lies - as sentences do not originaly have the same length \"\"\"\n",
        "\n",
        "encoded_data_train=tokenizer.batch_encode_plus(df_train.full_sent.values, add_special_tokens=True, \n",
        "                                               return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "encoded_data_test=tokenizer.batch_encode_plus(df_test.full_sent.values, add_special_tokens=True, \n",
        "                                               return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD896K-Ic0V0"
      },
      "source": [
        "\"\"\" access the data train dictionary and pull out the input ids which essetntailly represents each word as a number\"\"\"\n",
        "input_ids_train=encoded_data_train['input_ids']\n",
        "attention_masks_train=encoded_data_train['attention_mask']\n",
        "#make a tensor out of the original data labels\n",
        "labels_train=torch.tensor(df_train.label.values, dtype=torch.long)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5wtrfG4mZi_"
      },
      "source": [
        "####We create the train data set by TensorDataset which used in pytorch library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-nlyxkgdRNn"
      },
      "source": [
        "#iterates over each three element at one time for each data set\n",
        "dataset_train=TensorDataset(input_ids_train,\n",
        "                            attention_masks_train,labels_train)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQOu2ecadVL6"
      },
      "source": [
        "#repeat for test set\n",
        "input_ids_test=encoded_data_test['input_ids']\n",
        "attention_masks_test=encoded_data_test['attention_mask']\n",
        "labels_test=torch.tensor(df_test.label.values, dtype=torch.long)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9V1wTK7dYCC"
      },
      "source": [
        "dataset_test=TensorDataset(input_ids_test,\n",
        "                            attention_masks_test,labels_test)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejx6K5hFn97p",
        "outputId": "fbf1b910-35fb-4147-a45f-b0d050845f2b"
      },
      "source": [
        "print(len(dataset_train))\n",
        "print(len(dataset_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15752\n",
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1mk-HhsofCU"
      },
      "source": [
        "####We import the pretrained BERT model from module Huggingface's transformer library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQBOM9WHda26"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrEnu414sdbI"
      },
      "source": [
        "####In this part we can as well fine tune the pretrained BERT by outlining number of labels the final layer of BERT should have. We add a layer on top of that of size 19 as a classifier. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "63e6aae062744e68bd2d7a14cb00f5c0",
            "30d600025c374d7bb44b77d6d3b5e6ff",
            "dd461ca49cde4b4fae97ef55bb523f1d",
            "5effd48efa8243dc9a248a6610db8a4d",
            "67588845db3d47099569472740f6eed4",
            "8e679578a8ff42f3be4a8e6a96ad94e3",
            "066c859b65174bd592acf10e8a35941c",
            "12c5930904e6402abe6c63e8cc008cc6",
            "4a2b03408df244748ac7f6c6e3fa1013",
            "76bfe71cf31240c19760f21f101745ba",
            "367666947a7643cdaf9949b8737c0c7b",
            "b42d50b1f8c74549bdca9e569de542b3",
            "6c36d1b07ef64137956607ff290775b3",
            "6c3ef932e53e46aba01405cc9b738877",
            "5d6c11b64d6846bf8a089067c11fd20b",
            "c2037e064bad4e8d8361e6efead3f24b"
          ]
        },
        "id": "pKA9wnDnddEW",
        "outputId": "23708eef-e41b-4d46-ada6-e5978f9f3699"
      },
      "source": [
        "model= BertForSequenceClassification.from_pretrained(\n",
        "                'bert-base-uncased',\n",
        "                #length of the label dictionary is 19\n",
        "                 num_labels=19, \n",
        "                  output_attentions=False, \n",
        "                  #the state before the output state which won't be needed to return\n",
        "                 output_hidden_states=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e6aae062744e68bd2d7a14cb00f5c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a2b03408df244748ac7f6c6e3fa1013",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXqFU2Xstqst"
      },
      "source": [
        "####Dataloaders make it possible to iterate over the dataset in batches. Randomsampler samples the data randomly per batch. This will help randomize what data the model is exposed to. Sequential sampler can be used for test set, as for test set randomly sorting the data set is not as important as the gradients are fixed already in that stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p_M9aKhdfUy"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N7u64Fidhfu"
      },
      "source": [
        "batch_size=32 \n",
        "dataloader_train=DataLoader(dataset_train, \n",
        "                            sampler=RandomSampler(dataset_train), \n",
        "                            batch_size=batch_size)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqol30ukdjjC"
      },
      "source": [
        "dataloader_test=DataLoader(dataset_test, \n",
        "                            sampler=RandomSampler(dataset_test), \n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeszC9P8v3jf"
      },
      "source": [
        "####Setting the optimizer to Adam as a stochastic optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XBiF2rdocV"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQtjjM3dqzz"
      },
      "source": [
        "optimizer=AdamW(\n",
        "    model.parameters(), \n",
        "    lr=1e-5, #2e-5 >5e-5\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esc_4HcMds2b"
      },
      "source": [
        "epochs=10\n",
        "scheduler=get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=0, \n",
        "    #how many times learning rate is set to change\n",
        "    num_training_steps=len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uDkbJ0hdu8P"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQh0LyhdxMR"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usMGxk0nzOfB"
      },
      "source": [
        "####Predictions will come in the foramt of probabilities turned into 0s and 1s. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhqUXHK0dy12"
      },
      "source": [
        "#preds=[0.9, 0.07, 0.05]--> #preds=[1, 0, 0]\n",
        "def f1_score_func(preds, labels):\n",
        "  preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "  return f1_score(labels_flat, preds_flat, average='weighted')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4gKrCIKd0nH"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "  label_dict_inverse={v: k for k, v in label_dict.items()}\n",
        "\n",
        "  preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "\n",
        "  for label in np.unique(labels_flat):\n",
        "    y_preds=preds_flat[labels_flat==label]\n",
        "    y_true=labels_flat[labels_flat==label]\n",
        "    print(f'Class:{label_dict_inverse[label]}')\n",
        "    print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX68pajEd2ZG"
      },
      "source": [
        "import random\n",
        "seed_val=17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4lBWC5Jd4eL",
        "outputId": "e4f75d7c-ebba-4b72-aba0-13479fc0feda"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#send the model to the available device\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qB2Ldvd6fT"
      },
      "source": [
        "def evaluate(dataloader_test):\n",
        "  model.eval()\n",
        "\n",
        "  loss_test_total=0\n",
        "  predictions, true_vals=[],[]\n",
        "  \n",
        "  for batch in dataloader_test:\n",
        "      batch=tuple(b.to(device) for b in batch)\n",
        "\n",
        "      inputs={\n",
        "          'input_ids': batch[0],\n",
        "\n",
        "          'attention_mask': batch[1],\n",
        "          'labels': batch[2]\n",
        "\n",
        "      }\n",
        "      with torch.no_grad():\n",
        "        outputs=model(**inputs)\n",
        "\n",
        "      loss=outputs[0]\n",
        "      logits= outputs[1]\n",
        "      loss_test_total +=loss.item()\n",
        "      #loss.backward()\n",
        "\n",
        "      logits=logits.detach().cpu().numpy()\n",
        "      label_ids=inputs['labels'].cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "      true_vals.append(label_ids)\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "  loss_test_avg=loss_test_total/len(dataloader_test)\n",
        "\n",
        "  predictions=np.concatenate(predictions, axis=0)\n",
        "  true_vals=np.concatenate(true_vals, axis=0)\n",
        "\n",
        "\n",
        "  return loss_test_avg, predictions, true_vals\n",
        "  \n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfwkycH4d9P3",
        "outputId": "a57eca5a-9711-4c9a-df39-54059f6f33b9"
      },
      "source": [
        "pip install tqdm\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--8cz-od_xE"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKfc0E9aeB0D",
        "outputId": "db6a6091-378e-4073-8910-9264f5d536dd"
      },
      "source": [
        "for  epoch in tqdm(range(1, epochs+1)):  \n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  loss_train_total=0\n",
        "\n",
        "  progress_bar=tqdm(dataloader_train, \n",
        "                    desc='Epoch {:1d}'.format(epoch), \n",
        "                    leave=False, \n",
        "                    disable=False)\n",
        "                    \n",
        "  for batch in progress_bar:\n",
        "      model.zero_grad()\n",
        "      batch=tuple(b.to(device) for b in batch)\n",
        "      inputs={\n",
        "          'input_ids': batch[0],\n",
        "\n",
        "          'attention_mask': batch[1],\n",
        "          'labels': batch[2]\n",
        "\n",
        "      }\n",
        "      #with torch.no_grad():\n",
        "      outputs=model(**inputs)\n",
        "\n",
        "      loss=outputs[0]\n",
        "      loss_train_total +=loss.item()\n",
        "      loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch) )})\n",
        "  torch.save(model.state_dict(), f'/content/BERT_ft_epoch{epoch}.model')\n",
        "  tqdm.write('\\nEpoch {epoch}')\n",
        "  loss_train_avg=loss_train_total/len(dataloader_train)\n",
        "  tqdm.write(f'Training loss:{loss_train_avg}')\n",
        "  val_loss, predictions, true_vals=evaluate(dataloader_test)\n",
        "\n",
        "  val_f1=f1_score_func(predictions, true_vals)\n",
        "  tqdm.write(f'Validation loss: {val_loss}')\n",
        "  tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/493 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/493 [00:00<?, ?it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:   0%|          | 1/493 [00:00<06:31,  1.26it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:   0%|          | 1/493 [00:01<06:31,  1.26it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:   0%|          | 2/493 [00:01<06:28,  1.27it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:   0%|          | 2/493 [00:02<06:28,  1.27it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:   1%|          | 3/493 [00:02<06:27,  1.27it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:   1%|          | 3/493 [00:03<06:27,  1.27it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:   1%|          | 4/493 [00:03<06:24,  1.27it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:   1%|          | 4/493 [00:03<06:24,  1.27it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   1%|          | 5/493 [00:03<06:23,  1.27it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   1%|          | 5/493 [00:04<06:23,  1.27it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   1%|          | 6/493 [00:04<06:21,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   1%|          | 6/493 [00:05<06:21,  1.28it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/493 [00:05<06:20,  1.28it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/493 [00:06<06:20,  1.28it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/493 [00:06<06:18,  1.28it/s, training_loss=0.374]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/493 [00:07<06:18,  1.28it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/493 [00:07<06:17,  1.28it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/493 [00:07<06:17,  1.28it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/493 [00:07<06:17,  1.28it/s, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/493 [00:08<06:17,  1.28it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/493 [00:08<06:16,  1.28it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/493 [00:09<06:16,  1.28it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/493 [00:09<06:15,  1.28it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/493 [00:10<06:15,  1.28it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/493 [00:10<06:14,  1.28it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/493 [00:10<06:14,  1.28it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/493 [00:10<06:13,  1.28it/s, training_loss=0.258]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/493 [00:11<06:13,  1.28it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/493 [00:11<06:13,  1.28it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/493 [00:12<06:13,  1.28it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/493 [00:12<06:12,  1.28it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/493 [00:13<06:12,  1.28it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/493 [00:13<06:10,  1.28it/s, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   3%|▎         | 17/493 [00:14<06:10,  1.28it/s, training_loss=0.517]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/493 [00:14<06:10,  1.28it/s, training_loss=0.517]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/493 [00:14<06:10,  1.28it/s, training_loss=0.395]\u001b[A\n",
            "Epoch 1:   4%|▍         | 19/493 [00:14<06:09,  1.28it/s, training_loss=0.395]\u001b[A\n",
            "Epoch 1:   4%|▍         | 19/493 [00:15<06:09,  1.28it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/493 [00:15<06:08,  1.28it/s, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/493 [00:16<06:08,  1.28it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/493 [00:16<06:08,  1.28it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/493 [00:17<06:08,  1.28it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/493 [00:17<06:07,  1.28it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   4%|▍         | 22/493 [00:17<06:07,  1.28it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/493 [00:17<06:06,  1.28it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/493 [00:18<06:06,  1.28it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:   5%|▍         | 24/493 [00:18<06:05,  1.28it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:   5%|▍         | 24/493 [00:19<06:05,  1.28it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/493 [00:19<06:05,  1.28it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/493 [00:20<06:05,  1.28it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:   5%|▌         | 26/493 [00:20<06:03,  1.29it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:   5%|▌         | 26/493 [00:21<06:03,  1.29it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:   5%|▌         | 27/493 [00:21<06:03,  1.28it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:   5%|▌         | 27/493 [00:21<06:03,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/493 [00:21<06:01,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/493 [00:22<06:01,  1.28it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/493 [00:22<06:01,  1.29it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/493 [00:23<06:01,  1.29it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:   6%|▌         | 30/493 [00:23<06:00,  1.29it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:   6%|▌         | 30/493 [00:24<06:00,  1.29it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:   6%|▋         | 31/493 [00:24<05:59,  1.28it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:   6%|▋         | 31/493 [00:24<05:59,  1.28it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:   6%|▋         | 32/493 [00:24<05:58,  1.29it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:   6%|▋         | 32/493 [00:25<05:58,  1.29it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 1:   7%|▋         | 33/493 [00:25<05:57,  1.29it/s, training_loss=0.321]\u001b[A\n",
            "Epoch 1:   7%|▋         | 33/493 [00:26<05:57,  1.29it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/493 [00:26<05:57,  1.29it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/493 [00:27<05:57,  1.29it/s, training_loss=0.334]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/493 [00:27<05:56,  1.29it/s, training_loss=0.334]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/493 [00:28<05:56,  1.29it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/493 [00:28<05:55,  1.29it/s, training_loss=0.314]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/493 [00:28<05:55,  1.29it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/493 [00:28<05:53,  1.29it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/493 [00:29<05:53,  1.29it/s, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   8%|▊         | 38/493 [00:29<05:53,  1.29it/s, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   8%|▊         | 38/493 [00:30<05:53,  1.29it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:   8%|▊         | 39/493 [00:30<05:53,  1.29it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:   8%|▊         | 39/493 [00:31<05:53,  1.29it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/493 [00:31<05:52,  1.28it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/493 [00:31<05:52,  1.28it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   8%|▊         | 41/493 [00:31<05:53,  1.28it/s, training_loss=0.344]\u001b[A\n",
            "Epoch 1:   8%|▊         | 41/493 [00:32<05:53,  1.28it/s, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/493 [00:32<05:51,  1.28it/s, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/493 [00:33<05:51,  1.28it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:   9%|▊         | 43/493 [00:33<05:51,  1.28it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:   9%|▊         | 43/493 [00:34<05:51,  1.28it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/493 [00:34<05:50,  1.28it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/493 [00:35<05:50,  1.28it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/493 [00:35<05:49,  1.28it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/493 [00:35<05:49,  1.28it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:   9%|▉         | 46/493 [00:35<05:48,  1.28it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:   9%|▉         | 46/493 [00:36<05:48,  1.28it/s, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/493 [00:36<05:47,  1.28it/s, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/493 [00:37<05:47,  1.28it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/493 [00:37<05:47,  1.28it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/493 [00:38<05:47,  1.28it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  10%|▉         | 49/493 [00:38<05:46,  1.28it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  10%|▉         | 49/493 [00:38<05:46,  1.28it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  10%|█         | 50/493 [00:38<05:45,  1.28it/s, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  10%|█         | 50/493 [00:39<05:45,  1.28it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  10%|█         | 51/493 [00:39<05:44,  1.28it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  10%|█         | 51/493 [00:40<05:44,  1.28it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  11%|█         | 52/493 [00:40<05:44,  1.28it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  11%|█         | 52/493 [00:41<05:44,  1.28it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/493 [00:41<05:43,  1.28it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/493 [00:42<05:43,  1.28it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/493 [00:42<05:42,  1.28it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/493 [00:42<05:42,  1.28it/s, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  11%|█         | 55/493 [00:42<05:41,  1.28it/s, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  11%|█         | 55/493 [00:43<05:41,  1.28it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 56/493 [00:43<05:40,  1.28it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 56/493 [00:44<05:40,  1.28it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/493 [00:44<05:39,  1.28it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/493 [00:45<05:39,  1.28it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/493 [00:45<05:38,  1.28it/s, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/493 [00:46<05:38,  1.28it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/493 [00:46<05:38,  1.28it/s, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/493 [00:46<05:38,  1.28it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/493 [00:46<05:37,  1.28it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/493 [00:47<05:37,  1.28it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 61/493 [00:47<05:36,  1.28it/s, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 61/493 [00:48<05:36,  1.28it/s, training_loss=0.439]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/493 [00:48<05:35,  1.28it/s, training_loss=0.439]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/493 [00:49<05:35,  1.28it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/493 [00:49<05:35,  1.28it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/493 [00:49<05:35,  1.28it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/493 [00:49<05:34,  1.28it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/493 [00:50<05:34,  1.28it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/493 [00:50<05:33,  1.28it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/493 [00:51<05:33,  1.28it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 66/493 [00:51<05:32,  1.28it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 66/493 [00:52<05:32,  1.28it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 67/493 [00:52<05:31,  1.28it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 67/493 [00:53<05:31,  1.28it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/493 [00:53<05:30,  1.28it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/493 [00:53<05:30,  1.28it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/493 [00:53<05:29,  1.29it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/493 [00:54<05:29,  1.29it/s, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/493 [00:54<05:28,  1.29it/s, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/493 [00:55<05:28,  1.29it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 71/493 [00:55<05:27,  1.29it/s, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 71/493 [00:56<05:27,  1.29it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/493 [00:56<05:27,  1.29it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/493 [00:56<05:27,  1.29it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 73/493 [00:56<05:26,  1.29it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 73/493 [00:57<05:26,  1.29it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/493 [00:57<05:25,  1.29it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/493 [00:58<05:25,  1.29it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/493 [00:58<05:25,  1.28it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/493 [00:59<05:25,  1.28it/s, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 76/493 [00:59<05:24,  1.29it/s, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 76/493 [01:00<05:24,  1.29it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/493 [01:00<05:23,  1.29it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/493 [01:00<05:23,  1.29it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/493 [01:00<05:22,  1.29it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/493 [01:01<05:22,  1.29it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 79/493 [01:01<05:22,  1.28it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 79/493 [01:02<05:22,  1.28it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 80/493 [01:02<05:22,  1.28it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 80/493 [01:03<05:22,  1.28it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 81/493 [01:03<05:21,  1.28it/s, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 81/493 [01:03<05:21,  1.28it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/493 [01:03<05:20,  1.28it/s, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/493 [01:04<05:20,  1.28it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/493 [01:04<05:20,  1.28it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/493 [01:05<05:20,  1.28it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/493 [01:05<05:19,  1.28it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/493 [01:06<05:19,  1.28it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 85/493 [01:06<05:18,  1.28it/s, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 85/493 [01:07<05:18,  1.28it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 86/493 [01:07<05:17,  1.28it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 86/493 [01:07<05:17,  1.28it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/493 [01:07<05:16,  1.28it/s, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/493 [01:08<05:16,  1.28it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/493 [01:08<05:15,  1.28it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/493 [01:09<05:15,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/493 [01:09<05:14,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/493 [01:10<05:14,  1.28it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 90/493 [01:10<05:13,  1.29it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 90/493 [01:10<05:13,  1.29it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 91/493 [01:10<05:12,  1.28it/s, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 91/493 [01:11<05:12,  1.28it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 92/493 [01:11<05:12,  1.28it/s, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 92/493 [01:12<05:12,  1.28it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/493 [01:12<05:12,  1.28it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/493 [01:13<05:12,  1.28it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/493 [01:13<05:11,  1.28it/s, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/493 [01:14<05:11,  1.28it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 95/493 [01:14<05:10,  1.28it/s, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 95/493 [01:14<05:10,  1.28it/s, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 96/493 [01:14<05:09,  1.28it/s, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 96/493 [01:15<05:09,  1.28it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 97/493 [01:15<05:09,  1.28it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 97/493 [01:16<05:09,  1.28it/s, training_loss=0.421]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 98/493 [01:16<05:07,  1.28it/s, training_loss=0.421]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 98/493 [01:17<05:07,  1.28it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/493 [01:17<05:06,  1.28it/s, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/493 [01:17<05:06,  1.28it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  20%|██        | 100/493 [01:17<05:05,  1.29it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  20%|██        | 100/493 [01:18<05:05,  1.29it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  20%|██        | 101/493 [01:18<05:05,  1.29it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  20%|██        | 101/493 [01:19<05:05,  1.29it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/493 [01:19<05:04,  1.28it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/493 [01:20<05:04,  1.28it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  21%|██        | 103/493 [01:20<05:03,  1.29it/s, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  21%|██        | 103/493 [01:21<05:03,  1.29it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  21%|██        | 104/493 [01:21<05:02,  1.29it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  21%|██        | 104/493 [01:21<05:02,  1.29it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 105/493 [01:21<05:01,  1.29it/s, training_loss=0.263]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 105/493 [01:22<05:01,  1.29it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/493 [01:22<05:00,  1.29it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/493 [01:23<05:00,  1.29it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/493 [01:23<05:00,  1.29it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/493 [01:24<05:00,  1.29it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/493 [01:24<04:59,  1.29it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/493 [01:24<04:59,  1.29it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 109/493 [01:24<04:58,  1.29it/s, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 109/493 [01:25<04:58,  1.29it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 110/493 [01:25<04:58,  1.28it/s, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 110/493 [01:26<04:58,  1.28it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/493 [01:26<04:57,  1.28it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/493 [01:27<04:57,  1.28it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/493 [01:27<04:56,  1.29it/s, training_loss=0.348]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/493 [01:28<04:56,  1.29it/s, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/493 [01:28<04:55,  1.28it/s, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/493 [01:28<04:55,  1.28it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 114/493 [01:28<04:54,  1.29it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 114/493 [01:29<04:54,  1.29it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 115/493 [01:29<04:54,  1.28it/s, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 115/493 [01:30<04:54,  1.28it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 116/493 [01:30<04:53,  1.28it/s, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 116/493 [01:31<04:53,  1.28it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 117/493 [01:31<04:53,  1.28it/s, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 117/493 [01:31<04:53,  1.28it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/493 [01:31<04:52,  1.28it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/493 [01:32<04:52,  1.28it/s, training_loss=0.591]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 119/493 [01:32<04:51,  1.28it/s, training_loss=0.591]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 119/493 [01:33<04:51,  1.28it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 120/493 [01:33<04:50,  1.29it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 120/493 [01:34<04:50,  1.29it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 121/493 [01:34<04:49,  1.29it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 121/493 [01:35<04:49,  1.29it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 122/493 [01:35<04:48,  1.29it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 122/493 [01:35<04:48,  1.29it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 123/493 [01:35<04:48,  1.28it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 123/493 [01:36<04:48,  1.28it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 124/493 [01:36<04:47,  1.28it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 124/493 [01:37<04:47,  1.28it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 125/493 [01:37<04:45,  1.29it/s, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 125/493 [01:38<04:45,  1.29it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/493 [01:38<04:45,  1.28it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/493 [01:38<04:45,  1.28it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/493 [01:38<04:45,  1.28it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/493 [01:39<04:45,  1.28it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 128/493 [01:39<04:44,  1.28it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 128/493 [01:40<04:44,  1.28it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 129/493 [01:40<04:43,  1.29it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 129/493 [01:41<04:43,  1.29it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 130/493 [01:41<04:42,  1.28it/s, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 130/493 [01:42<04:42,  1.28it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/493 [01:42<04:42,  1.28it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/493 [01:42<04:42,  1.28it/s, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/493 [01:42<04:41,  1.28it/s, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/493 [01:43<04:41,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/493 [01:43<04:40,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/493 [01:44<04:40,  1.28it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 134/493 [01:44<04:39,  1.28it/s, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 134/493 [01:45<04:39,  1.28it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 135/493 [01:45<04:39,  1.28it/s, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 135/493 [01:45<04:39,  1.28it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/493 [01:45<04:38,  1.28it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/493 [01:46<04:38,  1.28it/s, training_loss=0.472]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/493 [01:46<04:37,  1.28it/s, training_loss=0.472]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/493 [01:47<04:37,  1.28it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 138/493 [01:47<04:36,  1.28it/s, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 138/493 [01:48<04:36,  1.28it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 139/493 [01:48<04:35,  1.28it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 139/493 [01:49<04:35,  1.28it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 140/493 [01:49<04:35,  1.28it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 140/493 [01:49<04:35,  1.28it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 141/493 [01:49<04:34,  1.28it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 141/493 [01:50<04:34,  1.28it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/493 [01:50<04:33,  1.28it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/493 [01:51<04:33,  1.28it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 143/493 [01:51<04:32,  1.28it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 143/493 [01:52<04:32,  1.28it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 144/493 [01:52<04:31,  1.29it/s, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 144/493 [01:52<04:31,  1.29it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 145/493 [01:52<04:30,  1.29it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 145/493 [01:53<04:30,  1.29it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 146/493 [01:53<04:29,  1.29it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 146/493 [01:54<04:29,  1.29it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 147/493 [01:54<04:28,  1.29it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 147/493 [01:55<04:28,  1.29it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  30%|███       | 148/493 [01:55<04:28,  1.29it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  30%|███       | 148/493 [01:56<04:28,  1.29it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  30%|███       | 149/493 [01:56<04:27,  1.28it/s, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  30%|███       | 149/493 [01:56<04:27,  1.28it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  30%|███       | 150/493 [01:56<04:26,  1.29it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  30%|███       | 150/493 [01:57<04:26,  1.29it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/493 [01:57<04:26,  1.28it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/493 [01:58<04:26,  1.28it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  31%|███       | 152/493 [01:58<04:26,  1.28it/s, training_loss=0.203]\u001b[A\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYfEBY0kHla",
        "outputId": "0540f8c9-776d-4ea2-851a-399e8ba9b92a"
      },
      "source": [
        "model=BertForSequenceClassification.from_pretrained(\n",
        "                'bert-base-uncased',\n",
        "                 num_labels=19, \n",
        "                  output_attentions=False, \n",
        "                 output_hidden_states=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUUm-quRI-Z8"
      },
      "source": [
        "####We choose the model from the last epoch, here the 8th epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTOm43XIkO51",
        "outputId": "01996b9a-bad3-4892-ddad-922f2132d192"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/BERT_ft_epoch5.model', map_location=torch.device('cuda')))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChkyrFghkdBO",
        "outputId": "29d5de9f-cde8-45c3-d9a9-766190bc5217"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HCzzIW9kr1x"
      },
      "source": [
        "_, prediction, true_vals= evaluate(dataloader_test)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwlOPdROHn8o"
      },
      "source": [
        "####F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCX_pfXdI3IU",
        "outputId": "ae01c948-1a67-498b-82ba-190d19a831bf"
      },
      "source": [
        "f1_score_func(prediction, true_vals)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6351770948862572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmZBkB1MIxR9",
        "outputId": "e6ad5bae-815d-4102-ce13-ed4039d8f837"
      },
      "source": [
        "accuracy_per_class(prediction, true_vals)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class:O\n",
            "Accuracy:2821/3000\n",
            "\n",
            "Class:Black-and-White_Fallacy\n",
            "Accuracy:0/26\n",
            "\n",
            "Class:Loaded_Language\n",
            "Accuracy:236/436\n",
            "\n",
            "Class:Flag-Waving\n",
            "Accuracy:12/96\n",
            "\n",
            "Class:Name_Calling,Labeling\n",
            "Accuracy:38/209\n",
            "\n",
            "Class:Slogans\n",
            "Accuracy:0/36\n",
            "\n",
            "Class:Causal_Oversimplification\n",
            "Accuracy:0/33\n",
            "\n",
            "Class:Whataboutism\n",
            "Accuracy:0/25\n",
            "\n",
            "Class:Exaggeration,Minimisation\n",
            "Accuracy:7/99\n",
            "\n",
            "Class:Doubt\n",
            "Accuracy:2/89\n",
            "\n",
            "Class:Appeal_to_Authority\n",
            "Accuracy:0/56\n",
            "\n",
            "Class:Repetition\n",
            "Accuracy:1/195\n",
            "\n",
            "Class:Appeal_to_fear-prejudice\n",
            "Accuracy:3/130\n",
            "\n",
            "Class:Thought-terminating_Cliches\n",
            "Accuracy:0/22\n",
            "\n",
            "Class:Bandwagon\n",
            "Accuracy:0/4\n",
            "\n",
            "Class:Red_Herring\n",
            "Accuracy:0/15\n",
            "\n",
            "Class:Reductio_ad_hitlerum\n",
            "Accuracy:0/11\n",
            "\n",
            "Class:Obfuscation,Intentional_Vagueness,Confusion\n",
            "Accuracy:0/6\n",
            "\n",
            "Class:Straw_Men\n",
            "Accuracy:0/2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSB4P1mbs4Hb",
        "outputId": "368d46f2-5f9f-4c32-da6f-c2fb570dc79d"
      },
      "source": [
        "print(len(prediction))\n",
        "assert(len(predictions)==len(df_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM3yxtEmtA3G",
        "outputId": "459f9d50-7451-46e9-992a-2dfb60ec9d22"
      },
      "source": [
        "a=prediction[4000]\n",
        "print(\"an example of the predicted vectors is: \", a)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an example of the predicted vectors is:  [ 6.3453336  -1.077924    0.657036   -0.857547    0.21784805 -0.58260053\n",
            " -0.5905076  -1.0472031  -0.32378218  0.6990846   0.1088158   0.63251996\n",
            " -0.60680425 -0.88674796 -1.3269558  -1.2315438  -1.1710534  -1.3416458\n",
            " -1.3956172 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJdU6LJGt8h1"
      },
      "source": [
        "pred=[]\n",
        "for i in range (len(prediction)):\n",
        "  pred.append(np.argmax(prediction[i]).flatten())\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1XJMsPhveeq",
        "outputId": "078260ef-d554-4ab8-fd38-9b7e8f273b09"
      },
      "source": [
        "print(pred[9])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rab8IUd9s7XZ",
        "outputId": "8ea0cf07-0b89-486f-a0cc-7e1bd2d27292"
      },
      "source": [
        "print(len(true_vals))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pZoy_6Rs9vZ",
        "outputId": "939aaee6-36cc-429c-8d5e-b260ba5af8d9"
      },
      "source": [
        "print(true_vals[1000])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKs79LOiqIJU",
        "outputId": "9f206e30-1392-4d66-b066-d75ccc67df21"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "#predicted = [1,2,3,4,5,1,2,1,1,4,5] \n",
        "#y_test = [1,2,3,4,5,1,2,1,1,4,1]\n",
        "\n",
        "precision, recall, fscore, support = score(true_vals, pred)\n",
        "\n",
        "#print('precision: {}'.format(precision))\n",
        "#print('recall: {}'.format(recall))\n",
        "#print('fscore: {}'.format(fscore))\n",
        "#print('support: {}'.format(support))\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJO3g3huxhzu"
      },
      "source": [
        "df1 = pd.DataFrame({ 'precision': precision, 'recall':recall, 'Fscore':fscore, 'support':support })\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8ifEK--xnip",
        "outputId": "6dfa2243-e130-46b4-a5b5-95532a2ffe24"
      },
      "source": [
        "df1.head\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of     precision    recall    Fscore  support\n",
              "0    0.795544  0.940333  0.861900     3000\n",
              "1    0.000000  0.000000  0.000000       26\n",
              "2    0.342029  0.541284  0.419183      436\n",
              "3    0.363636  0.125000  0.186047       96\n",
              "4    0.248366  0.181818  0.209945      209\n",
              "5    0.000000  0.000000  0.000000       36\n",
              "6    0.000000  0.000000  0.000000       33\n",
              "7    0.000000  0.000000  0.000000       25\n",
              "8    0.269231  0.070707  0.112000       99\n",
              "9    0.105263  0.022472  0.037037       89\n",
              "10   0.000000  0.000000  0.000000       56\n",
              "11   0.100000  0.005128  0.009756      195\n",
              "12   0.230769  0.023077  0.041958      130\n",
              "13   0.000000  0.000000  0.000000       22\n",
              "14   0.000000  0.000000  0.000000        4\n",
              "15   0.000000  0.000000  0.000000       15\n",
              "16   0.000000  0.000000  0.000000       11\n",
              "17   0.000000  0.000000  0.000000        6\n",
              "18   0.000000  0.000000  0.000000        2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VjLhfEybxS",
        "outputId": "802645c7-d4b4-46b4-f091-2bb12368cb13"
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "print(tabulate(df1, headers='keys', tablefmt='psql'))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-------------+------------+-----------+-----------+\n",
            "|    |   precision |     recall |    Fscore |   support |\n",
            "|----+-------------+------------+-----------+-----------|\n",
            "|  0 |    0.795544 | 0.940333   | 0.8619    |      3000 |\n",
            "|  1 |    0        | 0          | 0         |        26 |\n",
            "|  2 |    0.342029 | 0.541284   | 0.419183  |       436 |\n",
            "|  3 |    0.363636 | 0.125      | 0.186047  |        96 |\n",
            "|  4 |    0.248366 | 0.181818   | 0.209945  |       209 |\n",
            "|  5 |    0        | 0          | 0         |        36 |\n",
            "|  6 |    0        | 0          | 0         |        33 |\n",
            "|  7 |    0        | 0          | 0         |        25 |\n",
            "|  8 |    0.269231 | 0.0707071  | 0.112     |        99 |\n",
            "|  9 |    0.105263 | 0.0224719  | 0.037037  |        89 |\n",
            "| 10 |    0        | 0          | 0         |        56 |\n",
            "| 11 |    0.1      | 0.00512821 | 0.0097561 |       195 |\n",
            "| 12 |    0.230769 | 0.0230769  | 0.041958  |       130 |\n",
            "| 13 |    0        | 0          | 0         |        22 |\n",
            "| 14 |    0        | 0          | 0         |         4 |\n",
            "| 15 |    0        | 0          | 0         |        15 |\n",
            "| 16 |    0        | 0          | 0         |        11 |\n",
            "| 17 |    0        | 0          | 0         |         6 |\n",
            "| 18 |    0        | 0          | 0         |         2 |\n",
            "+----+-------------+------------+-----------+-----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}