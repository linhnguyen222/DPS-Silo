{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anselmi/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.datasets import UD_ENGLISH\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from flair.data import Dictionary\n",
    "from flair import Seque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-05 10:17:16,721 Reading data from /home/anselmi/Desktop/Courses/Data Science Project\n",
      "2020-11-05 10:17:16,724 Train: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n",
      "2020-11-05 10:17:16,725 Dev: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n",
      "2020-11-05 10:17:16,727 Test: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n"
     ]
    }
   ],
   "source": [
    "# 1. create the corpus\n",
    "\n",
    "columns = {0: 'text', 1: 'tag'}\n",
    "data_folder = '/home/anselmi/Desktop/Courses/Data Science Project'\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='tag_test.txt',\n",
    "                              test_file='tag_test.txt',\n",
    "                              dev_file='tag_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 1 tags: <unk>\n",
      "Help on class Dictionary in module flair.data:\n",
      "\n",
      "class Dictionary(builtins.object)\n",
      " |  Dictionary(add_unk=True)\n",
      " |  \n",
      " |  This class holds a dictionary that maps strings to IDs, used to generate one-hot encodings of strings.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, add_unk=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_item(self, item: str) -> int\n",
      " |      add string - if already in dictionary returns its ID. if not in dictionary, it will get a new ID.\n",
      " |      :param item: a string for which to assign an id.\n",
      " |      :return: ID of string\n",
      " |  \n",
      " |  get_idx_for_item(self, item: str) -> int\n",
      " |      returns the ID of the string, otherwise 0\n",
      " |      :param item: string for which ID is requested\n",
      " |      :return: ID of string, otherwise 0\n",
      " |  \n",
      " |  get_idx_for_items(self, items: List[str]) -> List[int]\n",
      " |      returns the IDs for each item of the list of string, otherwise 0 if not found\n",
      " |      :param items: List of string for which IDs are requested\n",
      " |      :return: List of ID of strings\n",
      " |  \n",
      " |  get_item_for_index(self, idx)\n",
      " |  \n",
      " |  get_items(self) -> List[str]\n",
      " |  \n",
      " |  save(self, savefile)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(name: str) from builtins.type\n",
      " |  \n",
      " |  load_from_file(filename: str) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. make the tag dictionary from the corpus\n",
    "\n",
    "# tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "# print(tag_dictionary)\n",
    "\n",
    "tag_dictionary = Dictionary()\n",
    "print(tag_dictionary)\n",
    "\n",
    "help(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Corpus in module flair.data:\n",
      "\n",
      "class Corpus(builtins.object)\n",
      " |  Corpus(train: flair.data.FlairDataset, dev: flair.data.FlairDataset = None, test: flair.data.FlairDataset = None, name: str = 'corpus')\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, train: flair.data.FlairDataset, dev: flair.data.FlairDataset = None, test: flair.data.FlairDataset = None, name: str = 'corpus')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  downsample(self, percentage: float = 0.1, downsample_train=True, downsample_dev=True, downsample_test=True)\n",
      " |  \n",
      " |  filter_empty_sentences(self)\n",
      " |  \n",
      " |  filter_long_sentences(self, max_charlength: int)\n",
      " |  \n",
      " |  get_all_sentences(self) -> torch.utils.data.dataset.Dataset\n",
      " |  \n",
      " |  get_label_distribution(self)\n",
      " |  \n",
      " |  make_label_dictionary(self, label_type: str = None) -> flair.data.Dictionary\n",
      " |      Creates a dictionary of all labels assigned to the sentences in the corpus.\n",
      " |      :return: dictionary of labels\n",
      " |  \n",
      " |  make_tag_dictionary(self, tag_type: str) -> flair.data.Dictionary\n",
      " |  \n",
      " |  make_vocab_dictionary(self, max_tokens=-1, min_freq=1) -> flair.data.Dictionary\n",
      " |      Creates a dictionary of all tokens contained in the corpus.\n",
      " |      By defining `max_tokens` you can set the maximum number of tokens that should be contained in the dictionary.\n",
      " |      If there are more than `max_tokens` tokens in the corpus, the most frequent tokens are added first.\n",
      " |      If `min_freq` is set the a value greater than 1 only tokens occurring more than `min_freq` times are considered\n",
      " |      to be added to the dictionary.\n",
      " |      :param max_tokens: the maximum number of tokens that should be added to the dictionary (-1 = take all tokens)\n",
      " |      :param min_freq: a token needs to occur at least `min_freq` times to be added to the dictionary (-1 = there is no limitation)\n",
      " |      :return: dictionary of tokens\n",
      " |  \n",
      " |  obtain_statistics(self, label_type: str = None, pretty_print: bool = True) -> dict\n",
      " |      Print statistics about the class distribution (only labels of sentences are taken into account) and sentence\n",
      " |      sizes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  dev\n",
      " |  \n",
      " |  test\n",
      " |  \n",
      " |  train\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Dictionary\n",
    "help(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:54:48,091 Reading data from /home/anselmi/Desktop/Courses/Data Science Project\n",
      "2020-11-05 09:54:48,093 Train: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n",
      "2020-11-05 09:54:48,095 Dev: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n",
      "2020-11-05 09:54:48,098 Test: /home/anselmi/Desktop/Courses/Data Science Project/tag_test.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = corpus.make_tag_dictionary('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 5 tags: <unk>, O, , <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"This sentence has propaganda tags for all but the first and last two words\"   [− Tokens: 14  − Token-Labels: \"This <0> sentence <1> has <1> propaganda <1> tags <1> for <1> all <1> but <1> the <1> first <1> and <1> last <1> two <0> words <0>\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an example <B-STRAWMAN> sentence'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0].to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 20:47:03,883 Reading data from data\n",
      "2020-11-11 20:47:03,884 Train: data/train.txt\n",
      "2020-11-11 20:47:03,885 Dev: data/dev.txt\n",
      "2020-11-11 20:47:03,886 Test: None\n",
      "2020-11-11 20:47:09,982 Filtering empty sentences\n",
      "2020-11-11 20:47:10,016 Corpus: 12830 train + 2033 dev + 1426 test sentences\n"
     ]
    }
   ],
   "source": [
    "# Dataset columns\n",
    "columns = {0 : 'text', 1 : 'ner'}\n",
    "\n",
    "# Data path\n",
    "data_path = './data/'\n",
    "\n",
    "# Create corpus\n",
    "corpus = ColumnCorpus(data_path, columns,\n",
    "                              train_file = 'train.txt',\n",
    "                              #test_file = 'test.txt',\n",
    "                              dev_file = 'dev.txt')\n",
    "\n",
    "# remove empty sentences\n",
    "corpus.filter_empty_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_type = 'ner'\n",
    "\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089b370a708048a184e25ec4da5acd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e50b57012f842048155b76e0cdc696c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a8303565440ba94d201c25900c796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_types = [\n",
    "    #WordEmbeddings('glove'),\n",
    "    TransformerWordEmbeddings('bert-base-uncased')\n",
    "    # More stuff maybe\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=tag_dictionary,\n",
    "                        tag_type=tag_type,\n",
    "                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 21:02:46,146 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,149 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): TransformerWordEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)\n",
      "  (rnn): LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=22, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 21:02:46,151 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,152 Corpus: \"Corpus: 12830 train + 2033 dev + 1426 test sentences\"\n",
      "2020-11-11 21:02:46,153 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,155 Parameters:\n",
      "2020-11-11 21:02:46,156  - learning_rate: \"0.1\"\n",
      "2020-11-11 21:02:46,158  - mini_batch_size: \"32\"\n",
      "2020-11-11 21:02:46,159  - patience: \"3\"\n",
      "2020-11-11 21:02:46,160  - anneal_factor: \"0.5\"\n",
      "2020-11-11 21:02:46,161  - max_epochs: \"150\"\n",
      "2020-11-11 21:02:46,162  - shuffle: \"True\"\n",
      "2020-11-11 21:02:46,163  - train_with_dev: \"False\"\n",
      "2020-11-11 21:02:46,164  - batch_growth_annealing: \"False\"\n",
      "2020-11-11 21:02:46,165 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,166 Model training base path: \"resources/taggers/example-ner\"\n",
      "2020-11-11 21:02:46,167 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,168 Device: cpu\n",
      "2020-11-11 21:02:46,168 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:02:46,169 Embeddings storage mode: cpu\n",
      "2020-11-11 21:02:46,174 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:04:32,186 epoch 1 - iter 40/401 - loss 20.01969196 - samples/sec: 12.07 - lr: 0.100000\n",
      "2020-11-11 21:06:20,466 epoch 1 - iter 80/401 - loss 17.19978634 - samples/sec: 11.82 - lr: 0.100000\n",
      "2020-11-11 21:08:08,302 epoch 1 - iter 120/401 - loss 15.63664059 - samples/sec: 11.87 - lr: 0.100000\n",
      "2020-11-11 21:09:56,122 epoch 1 - iter 160/401 - loss 14.80864528 - samples/sec: 11.87 - lr: 0.100000\n",
      "2020-11-11 21:11:48,367 epoch 1 - iter 200/401 - loss 14.07164420 - samples/sec: 11.40 - lr: 0.100000\n",
      "2020-11-11 21:13:55,489 epoch 1 - iter 240/401 - loss 13.34544686 - samples/sec: 10.07 - lr: 0.100000\n",
      "2020-11-11 21:16:03,459 epoch 1 - iter 280/401 - loss 12.57281118 - samples/sec: 10.00 - lr: 0.100000\n",
      "2020-11-11 21:18:10,656 epoch 1 - iter 320/401 - loss 12.14174125 - samples/sec: 10.06 - lr: 0.100000\n",
      "2020-11-11 21:20:18,829 epoch 1 - iter 360/401 - loss 11.64274804 - samples/sec: 9.99 - lr: 0.100000\n",
      "2020-11-11 21:22:27,183 epoch 1 - iter 400/401 - loss 11.26779633 - samples/sec: 9.97 - lr: 0.100000\n",
      "2020-11-11 21:22:30,024 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:22:30,025 EPOCH 1 done: loss 11.2534 - lr 0.1000000\n",
      "2020-11-11 21:24:58,220 DEV : loss 8.192145347595215 - score 0.8526\n",
      "2020-11-11 21:24:58,371 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-11-11 21:24:58,999 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:25:41,452 epoch 2 - iter 40/401 - loss 7.91925855 - samples/sec: 30.16 - lr: 0.100000\n",
      "2020-11-11 21:26:21,764 epoch 2 - iter 80/401 - loss 7.09664063 - samples/sec: 31.76 - lr: 0.100000\n",
      "2020-11-11 21:27:02,324 epoch 2 - iter 120/401 - loss 6.90384671 - samples/sec: 31.56 - lr: 0.100000\n",
      "2020-11-11 21:27:43,398 epoch 2 - iter 160/401 - loss 6.61458215 - samples/sec: 31.17 - lr: 0.100000\n",
      "2020-11-11 21:28:21,717 epoch 2 - iter 200/401 - loss 6.39989829 - samples/sec: 33.41 - lr: 0.100000\n",
      "2020-11-11 21:28:59,815 epoch 2 - iter 240/401 - loss 6.13268818 - samples/sec: 33.60 - lr: 0.100000\n",
      "2020-11-11 21:29:42,535 epoch 2 - iter 280/401 - loss 6.12418241 - samples/sec: 29.97 - lr: 0.100000\n",
      "2020-11-11 21:30:23,555 epoch 2 - iter 320/401 - loss 6.06621785 - samples/sec: 31.21 - lr: 0.100000\n",
      "2020-11-11 21:31:03,008 epoch 2 - iter 360/401 - loss 6.00832753 - samples/sec: 32.45 - lr: 0.100000\n",
      "2020-11-11 21:31:43,066 epoch 2 - iter 400/401 - loss 5.92403892 - samples/sec: 31.96 - lr: 0.100000\n",
      "2020-11-11 21:31:43,994 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:31:43,995 EPOCH 2 done: loss 5.9166 - lr 0.1000000\n",
      "2020-11-11 21:32:06,289 DEV : loss 4.875819683074951 - score 0.8522\n",
      "2020-11-11 21:32:06,455 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 21:32:06,466 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:32:45,357 epoch 3 - iter 40/401 - loss 4.78066871 - samples/sec: 32.92 - lr: 0.100000\n",
      "2020-11-11 21:33:25,915 epoch 3 - iter 80/401 - loss 5.00611266 - samples/sec: 31.56 - lr: 0.100000\n",
      "2020-11-11 21:34:07,488 epoch 3 - iter 120/401 - loss 4.89530941 - samples/sec: 30.79 - lr: 0.100000\n",
      "2020-11-11 21:34:45,878 epoch 3 - iter 160/401 - loss 4.85955099 - samples/sec: 33.35 - lr: 0.100000\n",
      "2020-11-11 21:35:26,416 epoch 3 - iter 200/401 - loss 4.83469426 - samples/sec: 31.58 - lr: 0.100000\n",
      "2020-11-11 21:36:07,755 epoch 3 - iter 240/401 - loss 4.85290405 - samples/sec: 30.97 - lr: 0.100000\n",
      "2020-11-11 21:36:49,379 epoch 3 - iter 280/401 - loss 4.84189686 - samples/sec: 30.76 - lr: 0.100000\n",
      "2020-11-11 21:37:27,822 epoch 3 - iter 320/401 - loss 4.82260306 - samples/sec: 33.30 - lr: 0.100000\n",
      "2020-11-11 21:38:08,336 epoch 3 - iter 360/401 - loss 4.83573537 - samples/sec: 31.60 - lr: 0.100000\n",
      "2020-11-11 21:38:46,909 epoch 3 - iter 400/401 - loss 4.83428581 - samples/sec: 33.19 - lr: 0.100000\n",
      "2020-11-11 21:38:47,942 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:38:47,954 EPOCH 3 done: loss 4.8377 - lr 0.1000000\n",
      "2020-11-11 21:39:10,151 DEV : loss 4.275538921356201 - score 0.8426\n",
      "2020-11-11 21:39:10,314 BAD EPOCHS (no improvement): 2\n",
      "2020-11-11 21:39:10,314 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:39:48,981 epoch 4 - iter 40/401 - loss 4.32799146 - samples/sec: 33.11 - lr: 0.100000\n",
      "2020-11-11 21:40:28,780 epoch 4 - iter 80/401 - loss 4.54779968 - samples/sec: 32.17 - lr: 0.100000\n",
      "2020-11-11 21:41:09,752 epoch 4 - iter 120/401 - loss 4.43653010 - samples/sec: 31.24 - lr: 0.100000\n",
      "2020-11-11 21:41:54,009 epoch 4 - iter 160/401 - loss 4.49867411 - samples/sec: 28.93 - lr: 0.100000\n",
      "2020-11-11 21:42:31,207 epoch 4 - iter 200/401 - loss 4.46180849 - samples/sec: 34.42 - lr: 0.100000\n",
      "2020-11-11 21:43:10,762 epoch 4 - iter 240/401 - loss 4.46861867 - samples/sec: 32.36 - lr: 0.100000\n",
      "2020-11-11 21:43:51,698 epoch 4 - iter 280/401 - loss 4.49740031 - samples/sec: 31.27 - lr: 0.100000\n",
      "2020-11-11 21:44:32,141 epoch 4 - iter 320/401 - loss 4.49680897 - samples/sec: 31.65 - lr: 0.100000\n",
      "2020-11-11 21:45:12,413 epoch 4 - iter 360/401 - loss 4.43600451 - samples/sec: 31.79 - lr: 0.100000\n",
      "2020-11-11 21:45:51,487 epoch 4 - iter 400/401 - loss 4.41206494 - samples/sec: 32.76 - lr: 0.100000\n",
      "2020-11-11 21:45:52,951 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:45:52,954 EPOCH 4 done: loss 4.4147 - lr 0.1000000\n",
      "2020-11-11 21:46:15,881 DEV : loss 4.098170280456543 - score 0.7658\n",
      "2020-11-11 21:46:16,055 BAD EPOCHS (no improvement): 3\n",
      "2020-11-11 21:46:16,056 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:46:50,878 epoch 5 - iter 40/401 - loss 3.95384923 - samples/sec: 36.76 - lr: 0.100000\n",
      "2020-11-11 21:47:23,748 epoch 5 - iter 80/401 - loss 4.02123229 - samples/sec: 38.95 - lr: 0.100000\n",
      "2020-11-11 21:47:56,357 epoch 5 - iter 120/401 - loss 3.93566781 - samples/sec: 39.26 - lr: 0.100000\n",
      "2020-11-11 21:48:29,063 epoch 5 - iter 160/401 - loss 3.96039208 - samples/sec: 39.14 - lr: 0.100000\n",
      "2020-11-11 21:49:02,657 epoch 5 - iter 200/401 - loss 4.07613820 - samples/sec: 38.11 - lr: 0.100000\n",
      "2020-11-11 21:49:37,296 epoch 5 - iter 240/401 - loss 4.08407648 - samples/sec: 36.96 - lr: 0.100000\n",
      "2020-11-11 21:50:09,680 epoch 5 - iter 280/401 - loss 4.12799672 - samples/sec: 39.53 - lr: 0.100000\n",
      "2020-11-11 21:50:43,041 epoch 5 - iter 320/401 - loss 4.10539090 - samples/sec: 38.37 - lr: 0.100000\n",
      "2020-11-11 21:51:19,491 epoch 5 - iter 360/401 - loss 4.08847165 - samples/sec: 35.12 - lr: 0.100000\n",
      "2020-11-11 21:52:02,439 epoch 5 - iter 400/401 - loss 4.08029209 - samples/sec: 29.81 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 21:52:03,490 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:52:03,491 EPOCH 5 done: loss 4.0863 - lr 0.1000000\n",
      "2020-11-11 21:52:25,742 DEV : loss 6.209514617919922 - score 0.3687\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-11-11 21:52:25,905 BAD EPOCHS (no improvement): 4\n",
      "2020-11-11 21:52:25,906 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:53:04,462 epoch 6 - iter 40/401 - loss 2.99350680 - samples/sec: 33.20 - lr: 0.050000\n",
      "2020-11-11 21:53:45,949 epoch 6 - iter 80/401 - loss 3.16134791 - samples/sec: 30.86 - lr: 0.050000\n",
      "2020-11-11 21:54:25,988 epoch 6 - iter 120/401 - loss 3.31509494 - samples/sec: 31.97 - lr: 0.050000\n",
      "2020-11-11 21:55:07,062 epoch 6 - iter 160/401 - loss 3.25413935 - samples/sec: 31.17 - lr: 0.050000\n",
      "2020-11-11 21:55:45,646 epoch 6 - iter 200/401 - loss 3.35865395 - samples/sec: 33.18 - lr: 0.050000\n",
      "2020-11-11 21:56:24,005 epoch 6 - iter 240/401 - loss 3.30583986 - samples/sec: 33.37 - lr: 0.050000\n",
      "2020-11-11 21:57:05,374 epoch 6 - iter 280/401 - loss 3.28633512 - samples/sec: 30.95 - lr: 0.050000\n",
      "2020-11-11 21:57:44,409 epoch 6 - iter 320/401 - loss 3.25700698 - samples/sec: 32.80 - lr: 0.050000\n",
      "2020-11-11 21:58:23,981 epoch 6 - iter 360/401 - loss 3.22866401 - samples/sec: 32.35 - lr: 0.050000\n",
      "2020-11-11 21:59:06,606 epoch 6 - iter 400/401 - loss 3.27448063 - samples/sec: 30.03 - lr: 0.050000\n",
      "2020-11-11 21:59:07,622 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 21:59:07,624 EPOCH 6 done: loss 3.2711 - lr 0.0500000\n",
      "2020-11-11 21:59:30,079 DEV : loss 3.70194935798645 - score 0.8528\n",
      "2020-11-11 21:59:30,279 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-11-11 21:59:30,863 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:00:10,930 epoch 7 - iter 40/401 - loss 2.96294083 - samples/sec: 31.97 - lr: 0.050000\n",
      "2020-11-11 22:00:52,304 epoch 7 - iter 80/401 - loss 3.01207168 - samples/sec: 30.94 - lr: 0.050000\n",
      "2020-11-11 22:01:32,254 epoch 7 - iter 120/401 - loss 3.01261870 - samples/sec: 32.04 - lr: 0.050000\n",
      "2020-11-11 22:02:13,822 epoch 7 - iter 160/401 - loss 3.07722613 - samples/sec: 30.80 - lr: 0.050000\n",
      "2020-11-11 22:02:52,338 epoch 7 - iter 200/401 - loss 3.10694222 - samples/sec: 33.24 - lr: 0.050000\n",
      "2020-11-11 22:03:31,395 epoch 7 - iter 240/401 - loss 3.17220510 - samples/sec: 32.78 - lr: 0.050000\n",
      "2020-11-11 22:04:11,039 epoch 7 - iter 280/401 - loss 3.18070809 - samples/sec: 32.29 - lr: 0.050000\n",
      "2020-11-11 22:04:51,954 epoch 7 - iter 320/401 - loss 3.12136976 - samples/sec: 31.29 - lr: 0.050000\n",
      "2020-11-11 22:05:32,066 epoch 7 - iter 360/401 - loss 3.14166894 - samples/sec: 31.91 - lr: 0.050000\n",
      "2020-11-11 22:06:11,438 epoch 7 - iter 400/401 - loss 3.14187611 - samples/sec: 32.52 - lr: 0.050000\n",
      "2020-11-11 22:06:12,609 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:06:12,610 EPOCH 7 done: loss 3.1399 - lr 0.0500000\n",
      "2020-11-11 22:06:34,813 DEV : loss 3.7865734100341797 - score 0.8528\n",
      "2020-11-11 22:06:35,036 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 22:06:35,038 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:07:17,220 epoch 8 - iter 40/401 - loss 2.91742548 - samples/sec: 30.35 - lr: 0.050000\n",
      "2020-11-11 22:07:54,751 epoch 8 - iter 80/401 - loss 2.94246869 - samples/sec: 34.11 - lr: 0.050000\n",
      "2020-11-11 22:08:37,959 epoch 8 - iter 120/401 - loss 3.07012722 - samples/sec: 29.63 - lr: 0.050000\n",
      "2020-11-11 22:09:19,792 epoch 8 - iter 160/401 - loss 3.12505421 - samples/sec: 30.60 - lr: 0.050000\n",
      "2020-11-11 22:09:57,667 epoch 8 - iter 200/401 - loss 3.10034290 - samples/sec: 33.80 - lr: 0.050000\n",
      "2020-11-11 22:10:36,257 epoch 8 - iter 240/401 - loss 3.08594217 - samples/sec: 33.17 - lr: 0.050000\n",
      "2020-11-11 22:11:16,231 epoch 8 - iter 280/401 - loss 3.03371123 - samples/sec: 32.02 - lr: 0.050000\n",
      "2020-11-11 22:11:54,149 epoch 8 - iter 320/401 - loss 3.06406128 - samples/sec: 33.76 - lr: 0.050000\n",
      "2020-11-11 22:12:30,884 epoch 8 - iter 360/401 - loss 3.03540796 - samples/sec: 34.85 - lr: 0.050000\n",
      "2020-11-11 22:13:12,642 epoch 8 - iter 400/401 - loss 3.03697714 - samples/sec: 30.66 - lr: 0.050000\n",
      "2020-11-11 22:13:13,520 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:13:13,521 EPOCH 8 done: loss 3.0369 - lr 0.0500000\n",
      "2020-11-11 22:13:35,686 DEV : loss 3.3864734172821045 - score 0.847\n",
      "2020-11-11 22:13:35,849 BAD EPOCHS (no improvement): 2\n",
      "2020-11-11 22:13:35,850 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:14:16,020 epoch 9 - iter 40/401 - loss 3.07046998 - samples/sec: 31.87 - lr: 0.050000\n",
      "2020-11-11 22:14:58,555 epoch 9 - iter 80/401 - loss 3.09502719 - samples/sec: 30.10 - lr: 0.050000\n",
      "2020-11-11 22:15:40,723 epoch 9 - iter 120/401 - loss 3.03541554 - samples/sec: 30.36 - lr: 0.050000\n",
      "2020-11-11 22:16:19,831 epoch 9 - iter 160/401 - loss 3.00622529 - samples/sec: 32.73 - lr: 0.050000\n",
      "2020-11-11 22:16:59,946 epoch 9 - iter 200/401 - loss 3.00677802 - samples/sec: 31.91 - lr: 0.050000\n",
      "2020-11-11 22:17:37,326 epoch 9 - iter 240/401 - loss 2.97542241 - samples/sec: 34.25 - lr: 0.050000\n",
      "2020-11-11 22:18:16,393 epoch 9 - iter 280/401 - loss 2.93243160 - samples/sec: 32.77 - lr: 0.050000\n",
      "2020-11-11 22:18:58,783 epoch 9 - iter 320/401 - loss 2.95793909 - samples/sec: 30.20 - lr: 0.050000\n",
      "2020-11-11 22:19:37,739 epoch 9 - iter 360/401 - loss 2.93214434 - samples/sec: 32.86 - lr: 0.050000\n",
      "2020-11-11 22:20:18,224 epoch 9 - iter 400/401 - loss 2.92297644 - samples/sec: 31.62 - lr: 0.050000\n",
      "2020-11-11 22:20:19,023 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:20:19,024 EPOCH 9 done: loss 2.9224 - lr 0.0500000\n",
      "2020-11-11 22:20:41,204 DEV : loss 3.336512327194214 - score 0.8297\n",
      "2020-11-11 22:20:41,371 BAD EPOCHS (no improvement): 3\n",
      "2020-11-11 22:20:41,371 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:21:23,950 epoch 10 - iter 40/401 - loss 3.20677345 - samples/sec: 30.07 - lr: 0.050000\n",
      "2020-11-11 22:22:05,535 epoch 10 - iter 80/401 - loss 3.04494910 - samples/sec: 30.78 - lr: 0.050000\n",
      "2020-11-11 22:22:45,384 epoch 10 - iter 120/401 - loss 3.13981967 - samples/sec: 32.13 - lr: 0.050000\n",
      "2020-11-11 22:23:25,385 epoch 10 - iter 160/401 - loss 3.03271060 - samples/sec: 32.00 - lr: 0.050000\n",
      "2020-11-11 22:24:04,955 epoch 10 - iter 200/401 - loss 2.99620464 - samples/sec: 32.35 - lr: 0.050000\n",
      "2020-11-11 22:24:41,829 epoch 10 - iter 240/401 - loss 2.95409455 - samples/sec: 34.72 - lr: 0.050000\n",
      "2020-11-11 22:25:21,738 epoch 10 - iter 280/401 - loss 2.90342986 - samples/sec: 32.08 - lr: 0.050000\n",
      "2020-11-11 22:25:59,064 epoch 10 - iter 320/401 - loss 2.86470024 - samples/sec: 34.30 - lr: 0.050000\n",
      "2020-11-11 22:26:41,254 epoch 10 - iter 360/401 - loss 2.85561428 - samples/sec: 30.34 - lr: 0.050000\n",
      "2020-11-11 22:27:21,752 epoch 10 - iter 400/401 - loss 2.83362508 - samples/sec: 31.61 - lr: 0.050000\n",
      "2020-11-11 22:27:22,661 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:27:22,662 EPOCH 10 done: loss 2.8362 - lr 0.0500000\n",
      "2020-11-11 22:27:44,864 DEV : loss 3.291630506515503 - score 0.851\n",
      "Epoch    10: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-11-11 22:27:45,027 BAD EPOCHS (no improvement): 4\n",
      "2020-11-11 22:27:45,028 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:28:24,908 epoch 11 - iter 40/401 - loss 2.57081310 - samples/sec: 32.10 - lr: 0.025000\n",
      "2020-11-11 22:29:06,020 epoch 11 - iter 80/401 - loss 2.62309870 - samples/sec: 31.14 - lr: 0.025000\n",
      "2020-11-11 22:29:47,031 epoch 11 - iter 120/401 - loss 2.61970816 - samples/sec: 31.22 - lr: 0.025000\n",
      "2020-11-11 22:30:28,554 epoch 11 - iter 160/401 - loss 2.61690002 - samples/sec: 30.83 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 22:31:08,152 epoch 11 - iter 200/401 - loss 2.63263380 - samples/sec: 32.33 - lr: 0.025000\n",
      "2020-11-11 22:31:50,230 epoch 11 - iter 240/401 - loss 2.62952410 - samples/sec: 30.42 - lr: 0.025000\n",
      "2020-11-11 22:32:27,941 epoch 11 - iter 280/401 - loss 2.61703288 - samples/sec: 33.95 - lr: 0.025000\n",
      "2020-11-11 22:33:08,291 epoch 11 - iter 320/401 - loss 2.61018592 - samples/sec: 31.73 - lr: 0.025000\n",
      "2020-11-11 22:33:47,382 epoch 11 - iter 360/401 - loss 2.60474727 - samples/sec: 32.75 - lr: 0.025000\n",
      "2020-11-11 22:34:25,745 epoch 11 - iter 400/401 - loss 2.60846058 - samples/sec: 33.37 - lr: 0.025000\n",
      "2020-11-11 22:34:26,613 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:34:26,614 EPOCH 11 done: loss 2.6059 - lr 0.0250000\n",
      "2020-11-11 22:34:48,811 DEV : loss 3.172679901123047 - score 0.8487\n",
      "2020-11-11 22:34:48,976 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 22:34:48,977 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:35:27,578 epoch 12 - iter 40/401 - loss 2.40277822 - samples/sec: 33.16 - lr: 0.025000\n",
      "2020-11-11 22:36:06,550 epoch 12 - iter 80/401 - loss 2.34263294 - samples/sec: 32.85 - lr: 0.025000\n",
      "2020-11-11 22:36:44,647 epoch 12 - iter 120/401 - loss 2.43434119 - samples/sec: 33.60 - lr: 0.025000\n",
      "2020-11-11 22:37:27,912 epoch 12 - iter 160/401 - loss 2.46074069 - samples/sec: 29.59 - lr: 0.025000\n",
      "2020-11-11 22:38:10,588 epoch 12 - iter 200/401 - loss 2.49729898 - samples/sec: 30.00 - lr: 0.025000\n",
      "2020-11-11 22:38:49,211 epoch 12 - iter 240/401 - loss 2.51075005 - samples/sec: 33.15 - lr: 0.025000\n",
      "2020-11-11 22:39:30,231 epoch 12 - iter 280/401 - loss 2.53858044 - samples/sec: 31.21 - lr: 0.025000\n",
      "2020-11-11 22:40:13,080 epoch 12 - iter 320/401 - loss 2.55641822 - samples/sec: 29.88 - lr: 0.025000\n",
      "2020-11-11 22:40:51,086 epoch 12 - iter 360/401 - loss 2.53228291 - samples/sec: 33.68 - lr: 0.025000\n",
      "2020-11-11 22:41:28,437 epoch 12 - iter 400/401 - loss 2.55313756 - samples/sec: 34.27 - lr: 0.025000\n",
      "2020-11-11 22:41:29,368 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:41:29,369 EPOCH 12 done: loss 2.5539 - lr 0.0250000\n",
      "2020-11-11 22:41:53,267 DEV : loss 3.165822982788086 - score 0.847\n",
      "2020-11-11 22:41:53,431 BAD EPOCHS (no improvement): 2\n",
      "2020-11-11 22:41:53,432 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:42:31,513 epoch 13 - iter 40/401 - loss 2.37961337 - samples/sec: 33.62 - lr: 0.025000\n",
      "2020-11-11 22:43:11,933 epoch 13 - iter 80/401 - loss 2.59136242 - samples/sec: 31.67 - lr: 0.025000\n",
      "2020-11-11 22:43:53,019 epoch 13 - iter 120/401 - loss 2.56670394 - samples/sec: 31.16 - lr: 0.025000\n",
      "2020-11-11 22:44:33,065 epoch 13 - iter 160/401 - loss 2.51299855 - samples/sec: 31.97 - lr: 0.025000\n",
      "2020-11-11 22:45:13,735 epoch 13 - iter 200/401 - loss 2.48754866 - samples/sec: 31.48 - lr: 0.025000\n",
      "2020-11-11 22:45:53,989 epoch 13 - iter 240/401 - loss 2.50108228 - samples/sec: 31.80 - lr: 0.025000\n",
      "2020-11-11 22:46:32,731 epoch 13 - iter 280/401 - loss 2.48280149 - samples/sec: 33.04 - lr: 0.025000\n",
      "2020-11-11 22:47:13,314 epoch 13 - iter 320/401 - loss 2.49313144 - samples/sec: 31.54 - lr: 0.025000\n",
      "2020-11-11 22:47:51,665 epoch 13 - iter 360/401 - loss 2.48958665 - samples/sec: 33.38 - lr: 0.025000\n",
      "2020-11-11 22:48:32,824 epoch 13 - iter 400/401 - loss 2.49923173 - samples/sec: 31.10 - lr: 0.025000\n",
      "2020-11-11 22:48:33,998 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:48:33,999 EPOCH 13 done: loss 2.4986 - lr 0.0250000\n",
      "2020-11-11 22:48:56,188 DEV : loss 3.1069228649139404 - score 0.8443\n",
      "2020-11-11 22:48:56,351 BAD EPOCHS (no improvement): 3\n",
      "2020-11-11 22:48:56,352 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:49:37,502 epoch 14 - iter 40/401 - loss 2.63795214 - samples/sec: 31.11 - lr: 0.025000\n",
      "2020-11-11 22:50:17,226 epoch 14 - iter 80/401 - loss 2.43656550 - samples/sec: 32.23 - lr: 0.025000\n",
      "2020-11-11 22:50:55,464 epoch 14 - iter 120/401 - loss 2.39014114 - samples/sec: 33.48 - lr: 0.025000\n",
      "2020-11-11 22:51:36,496 epoch 14 - iter 160/401 - loss 2.40642161 - samples/sec: 31.20 - lr: 0.025000\n",
      "2020-11-11 22:52:16,494 epoch 14 - iter 200/401 - loss 2.40574263 - samples/sec: 32.01 - lr: 0.025000\n",
      "2020-11-11 22:52:57,619 epoch 14 - iter 240/401 - loss 2.42209626 - samples/sec: 31.13 - lr: 0.025000\n",
      "2020-11-11 22:53:39,282 epoch 14 - iter 280/401 - loss 2.45518156 - samples/sec: 30.73 - lr: 0.025000\n",
      "2020-11-11 22:54:20,751 epoch 14 - iter 320/401 - loss 2.45731958 - samples/sec: 30.87 - lr: 0.025000\n",
      "2020-11-11 22:54:57,763 epoch 14 - iter 360/401 - loss 2.44793498 - samples/sec: 34.59 - lr: 0.025000\n",
      "2020-11-11 22:55:38,163 epoch 14 - iter 400/401 - loss 2.46008875 - samples/sec: 31.69 - lr: 0.025000\n",
      "2020-11-11 22:55:39,106 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:55:39,107 EPOCH 14 done: loss 2.4599 - lr 0.0250000\n",
      "2020-11-11 22:56:01,769 DEV : loss 3.1812214851379395 - score 0.8497\n",
      "Epoch    14: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2020-11-11 22:56:01,932 BAD EPOCHS (no improvement): 4\n",
      "2020-11-11 22:56:01,933 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 22:56:42,565 epoch 15 - iter 40/401 - loss 2.48221096 - samples/sec: 31.51 - lr: 0.012500\n",
      "2020-11-11 22:57:23,308 epoch 15 - iter 80/401 - loss 2.43425170 - samples/sec: 31.42 - lr: 0.012500\n",
      "2020-11-11 22:58:03,943 epoch 15 - iter 120/401 - loss 2.39102702 - samples/sec: 31.50 - lr: 0.012500\n",
      "2020-11-11 22:58:44,126 epoch 15 - iter 160/401 - loss 2.42748841 - samples/sec: 31.86 - lr: 0.012500\n",
      "2020-11-11 22:59:25,038 epoch 15 - iter 200/401 - loss 2.39410075 - samples/sec: 31.29 - lr: 0.012500\n",
      "2020-11-11 23:00:07,517 epoch 15 - iter 240/401 - loss 2.41673329 - samples/sec: 30.14 - lr: 0.012500\n",
      "2020-11-11 23:00:45,015 epoch 15 - iter 280/401 - loss 2.39435797 - samples/sec: 34.14 - lr: 0.012500\n",
      "2020-11-11 23:01:23,683 epoch 15 - iter 320/401 - loss 2.35264158 - samples/sec: 33.11 - lr: 0.012500\n",
      "2020-11-11 23:02:02,927 epoch 15 - iter 360/401 - loss 2.35978364 - samples/sec: 32.62 - lr: 0.012500\n",
      "2020-11-11 23:02:42,634 epoch 15 - iter 400/401 - loss 2.36285657 - samples/sec: 32.24 - lr: 0.012500\n",
      "2020-11-11 23:02:43,506 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:02:43,507 EPOCH 15 done: loss 2.3636 - lr 0.0125000\n",
      "2020-11-11 23:03:05,734 DEV : loss 3.0603158473968506 - score 0.8395\n",
      "2020-11-11 23:03:05,900 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 23:03:05,901 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:03:46,082 epoch 16 - iter 40/401 - loss 2.26027889 - samples/sec: 31.86 - lr: 0.012500\n",
      "2020-11-11 23:04:25,127 epoch 16 - iter 80/401 - loss 2.33736991 - samples/sec: 32.79 - lr: 0.012500\n",
      "2020-11-11 23:05:06,081 epoch 16 - iter 120/401 - loss 2.32737729 - samples/sec: 31.26 - lr: 0.012500\n",
      "2020-11-11 23:05:47,109 epoch 16 - iter 160/401 - loss 2.31262921 - samples/sec: 31.20 - lr: 0.012500\n",
      "2020-11-11 23:06:26,943 epoch 16 - iter 200/401 - loss 2.30689953 - samples/sec: 32.14 - lr: 0.012500\n",
      "2020-11-11 23:07:06,819 epoch 16 - iter 240/401 - loss 2.32514936 - samples/sec: 32.10 - lr: 0.012500\n",
      "2020-11-11 23:07:50,617 epoch 16 - iter 280/401 - loss 2.32611287 - samples/sec: 29.23 - lr: 0.012500\n",
      "2020-11-11 23:08:29,966 epoch 16 - iter 320/401 - loss 2.32655097 - samples/sec: 32.53 - lr: 0.012500\n",
      "2020-11-11 23:09:09,606 epoch 16 - iter 360/401 - loss 2.32350220 - samples/sec: 32.30 - lr: 0.012500\n",
      "2020-11-11 23:09:48,079 epoch 16 - iter 400/401 - loss 2.31754236 - samples/sec: 33.27 - lr: 0.012500\n",
      "2020-11-11 23:09:49,028 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:09:49,029 EPOCH 16 done: loss 2.3147 - lr 0.0125000\n",
      "2020-11-11 23:10:11,344 DEV : loss 3.1415491104125977 - score 0.8482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 23:10:11,510 BAD EPOCHS (no improvement): 2\n",
      "2020-11-11 23:10:11,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:10:50,863 epoch 17 - iter 40/401 - loss 2.35697298 - samples/sec: 32.53 - lr: 0.012500\n",
      "2020-11-11 23:11:30,482 epoch 17 - iter 80/401 - loss 2.42980777 - samples/sec: 32.31 - lr: 0.012500\n",
      "2020-11-11 23:12:10,841 epoch 17 - iter 120/401 - loss 2.40273140 - samples/sec: 31.72 - lr: 0.012500\n",
      "2020-11-11 23:12:49,377 epoch 17 - iter 160/401 - loss 2.39606540 - samples/sec: 33.22 - lr: 0.012500\n",
      "2020-11-11 23:13:30,890 epoch 17 - iter 200/401 - loss 2.40463871 - samples/sec: 30.84 - lr: 0.012500\n",
      "2020-11-11 23:14:10,793 epoch 17 - iter 240/401 - loss 2.37866832 - samples/sec: 32.08 - lr: 0.012500\n",
      "2020-11-11 23:14:50,091 epoch 17 - iter 280/401 - loss 2.35118823 - samples/sec: 32.58 - lr: 0.012500\n",
      "2020-11-11 23:15:31,042 epoch 17 - iter 320/401 - loss 2.32836643 - samples/sec: 31.26 - lr: 0.012500\n",
      "2020-11-11 23:16:10,329 epoch 17 - iter 360/401 - loss 2.32804176 - samples/sec: 32.58 - lr: 0.012500\n",
      "2020-11-11 23:16:50,928 epoch 17 - iter 400/401 - loss 2.31760195 - samples/sec: 31.53 - lr: 0.012500\n",
      "2020-11-11 23:16:51,934 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:16:51,935 EPOCH 17 done: loss 2.3167 - lr 0.0125000\n",
      "2020-11-11 23:17:14,161 DEV : loss 3.0831947326660156 - score 0.8423\n",
      "2020-11-11 23:17:14,324 BAD EPOCHS (no improvement): 3\n",
      "2020-11-11 23:17:14,325 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:17:53,656 epoch 18 - iter 40/401 - loss 2.30808042 - samples/sec: 32.55 - lr: 0.012500\n",
      "2020-11-11 23:18:34,245 epoch 18 - iter 80/401 - loss 2.30151611 - samples/sec: 31.54 - lr: 0.012500\n",
      "2020-11-11 23:19:13,576 epoch 18 - iter 120/401 - loss 2.25308790 - samples/sec: 32.55 - lr: 0.012500\n",
      "2020-11-11 23:19:53,902 epoch 18 - iter 160/401 - loss 2.26384601 - samples/sec: 31.75 - lr: 0.012500\n",
      "2020-11-11 23:20:34,102 epoch 18 - iter 200/401 - loss 2.31663417 - samples/sec: 31.84 - lr: 0.012500\n",
      "2020-11-11 23:21:13,229 epoch 18 - iter 240/401 - loss 2.32300808 - samples/sec: 32.72 - lr: 0.012500\n",
      "2020-11-11 23:21:52,127 epoch 18 - iter 280/401 - loss 2.29832119 - samples/sec: 32.91 - lr: 0.012500\n",
      "2020-11-11 23:22:32,625 epoch 18 - iter 320/401 - loss 2.27392280 - samples/sec: 31.61 - lr: 0.012500\n",
      "2020-11-11 23:23:14,392 epoch 18 - iter 360/401 - loss 2.27211383 - samples/sec: 30.65 - lr: 0.012500\n",
      "2020-11-11 23:23:55,080 epoch 18 - iter 400/401 - loss 2.26371545 - samples/sec: 31.46 - lr: 0.012500\n",
      "2020-11-11 23:23:56,277 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:23:56,278 EPOCH 18 done: loss 2.2674 - lr 0.0125000\n",
      "2020-11-11 23:24:18,747 DEV : loss 3.07602858543396 - score 0.8473\n",
      "Epoch    18: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2020-11-11 23:24:18,911 BAD EPOCHS (no improvement): 4\n",
      "2020-11-11 23:24:18,912 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:24:57,680 epoch 19 - iter 40/401 - loss 2.19513787 - samples/sec: 33.02 - lr: 0.006250\n",
      "2020-11-11 23:25:37,772 epoch 19 - iter 80/401 - loss 2.15954851 - samples/sec: 31.93 - lr: 0.006250\n",
      "2020-11-11 23:26:17,455 epoch 19 - iter 120/401 - loss 2.17654538 - samples/sec: 32.26 - lr: 0.006250\n",
      "2020-11-11 23:26:57,221 epoch 19 - iter 160/401 - loss 2.17417155 - samples/sec: 32.19 - lr: 0.006250\n",
      "2020-11-11 23:27:39,813 epoch 19 - iter 200/401 - loss 2.19613178 - samples/sec: 30.06 - lr: 0.006250\n",
      "2020-11-11 23:28:20,815 epoch 19 - iter 240/401 - loss 2.20288184 - samples/sec: 31.22 - lr: 0.006250\n",
      "2020-11-11 23:28:59,844 epoch 19 - iter 280/401 - loss 2.21200404 - samples/sec: 32.80 - lr: 0.006250\n",
      "2020-11-11 23:29:40,629 epoch 19 - iter 320/401 - loss 2.21066653 - samples/sec: 31.39 - lr: 0.006250\n",
      "2020-11-11 23:30:18,476 epoch 19 - iter 360/401 - loss 2.22419348 - samples/sec: 33.83 - lr: 0.006250\n",
      "2020-11-11 23:30:57,536 epoch 19 - iter 400/401 - loss 2.21097118 - samples/sec: 32.77 - lr: 0.006250\n",
      "2020-11-11 23:30:58,362 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:30:58,363 EPOCH 19 done: loss 2.2106 - lr 0.0062500\n",
      "2020-11-11 23:31:20,612 DEV : loss 3.1099624633789062 - score 0.8484\n",
      "2020-11-11 23:31:20,777 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 23:31:20,778 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:31:59,146 epoch 20 - iter 40/401 - loss 2.35323641 - samples/sec: 33.37 - lr: 0.006250\n",
      "2020-11-11 23:32:37,157 epoch 20 - iter 80/401 - loss 2.32296625 - samples/sec: 33.68 - lr: 0.006250\n",
      "2020-11-11 23:33:17,805 epoch 20 - iter 120/401 - loss 2.29620505 - samples/sec: 31.49 - lr: 0.006250\n",
      "2020-11-11 23:33:58,183 epoch 20 - iter 160/401 - loss 2.28413365 - samples/sec: 31.70 - lr: 0.006250\n",
      "2020-11-11 23:34:39,710 epoch 20 - iter 200/401 - loss 2.29459786 - samples/sec: 30.83 - lr: 0.006250\n",
      "2020-11-11 23:35:20,948 epoch 20 - iter 240/401 - loss 2.27526677 - samples/sec: 31.04 - lr: 0.006250\n",
      "2020-11-11 23:36:00,066 epoch 20 - iter 280/401 - loss 2.23357691 - samples/sec: 32.73 - lr: 0.006250\n",
      "2020-11-11 23:36:41,382 epoch 20 - iter 320/401 - loss 2.23068095 - samples/sec: 30.99 - lr: 0.006250\n",
      "2020-11-11 23:37:21,622 epoch 20 - iter 360/401 - loss 2.20960969 - samples/sec: 31.81 - lr: 0.006250\n",
      "2020-11-11 23:38:01,212 epoch 20 - iter 400/401 - loss 2.20462213 - samples/sec: 32.34 - lr: 0.006250\n",
      "2020-11-11 23:38:02,365 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:38:02,367 EPOCH 20 done: loss 2.2061 - lr 0.0062500\n",
      "2020-11-11 23:38:24,623 DEV : loss 3.0990288257598877 - score 0.8477\n",
      "2020-11-11 23:38:24,785 BAD EPOCHS (no improvement): 2\n",
      "2020-11-11 23:38:24,786 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:39:04,132 epoch 21 - iter 40/401 - loss 2.19109009 - samples/sec: 32.54 - lr: 0.006250\n",
      "2020-11-11 23:39:48,881 epoch 21 - iter 80/401 - loss 2.26674852 - samples/sec: 28.61 - lr: 0.006250\n",
      "2020-11-11 23:40:28,322 epoch 21 - iter 120/401 - loss 2.26727042 - samples/sec: 32.46 - lr: 0.006250\n",
      "2020-11-11 23:41:08,410 epoch 21 - iter 160/401 - loss 2.20950539 - samples/sec: 31.93 - lr: 0.006250\n",
      "2020-11-11 23:41:48,237 epoch 21 - iter 200/401 - loss 2.20180431 - samples/sec: 32.14 - lr: 0.006250\n",
      "2020-11-11 23:42:30,035 epoch 21 - iter 240/401 - loss 2.22137649 - samples/sec: 30.63 - lr: 0.006250\n",
      "2020-11-11 23:43:09,962 epoch 21 - iter 280/401 - loss 2.19556945 - samples/sec: 32.06 - lr: 0.006250\n",
      "2020-11-11 23:43:47,276 epoch 21 - iter 320/401 - loss 2.21399440 - samples/sec: 34.31 - lr: 0.006250\n",
      "2020-11-11 23:44:25,185 epoch 21 - iter 360/401 - loss 2.19591129 - samples/sec: 33.77 - lr: 0.006250\n",
      "2020-11-11 23:45:06,165 epoch 21 - iter 400/401 - loss 2.18232451 - samples/sec: 31.24 - lr: 0.006250\n",
      "2020-11-11 23:45:07,455 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:45:07,456 EPOCH 21 done: loss 2.1815 - lr 0.0062500\n",
      "2020-11-11 23:45:29,687 DEV : loss 3.122347354888916 - score 0.8473\n",
      "2020-11-11 23:45:29,850 BAD EPOCHS (no improvement): 3\n",
      "2020-11-11 23:45:29,851 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:46:07,560 epoch 22 - iter 40/401 - loss 2.00371697 - samples/sec: 33.95 - lr: 0.006250\n",
      "2020-11-11 23:46:46,757 epoch 22 - iter 80/401 - loss 2.00272423 - samples/sec: 32.66 - lr: 0.006250\n",
      "2020-11-11 23:47:27,533 epoch 22 - iter 120/401 - loss 2.05792109 - samples/sec: 31.40 - lr: 0.006250\n",
      "2020-11-11 23:48:07,858 epoch 22 - iter 160/401 - loss 2.06181527 - samples/sec: 31.75 - lr: 0.006250\n",
      "2020-11-11 23:48:50,775 epoch 22 - iter 200/401 - loss 2.09311021 - samples/sec: 29.83 - lr: 0.006250\n",
      "2020-11-11 23:49:31,074 epoch 22 - iter 240/401 - loss 2.11351672 - samples/sec: 31.77 - lr: 0.006250\n",
      "2020-11-11 23:50:09,889 epoch 22 - iter 280/401 - loss 2.10828885 - samples/sec: 32.98 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 23:50:49,733 epoch 22 - iter 320/401 - loss 2.14787780 - samples/sec: 32.13 - lr: 0.006250\n",
      "2020-11-11 23:51:28,015 epoch 22 - iter 360/401 - loss 2.15963760 - samples/sec: 33.44 - lr: 0.006250\n",
      "2020-11-11 23:52:08,974 epoch 22 - iter 400/401 - loss 2.16449504 - samples/sec: 31.25 - lr: 0.006250\n",
      "2020-11-11 23:52:09,892 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:52:09,894 EPOCH 22 done: loss 2.1655 - lr 0.0062500\n",
      "2020-11-11 23:52:32,520 DEV : loss 3.0588812828063965 - score 0.8411\n",
      "Epoch    22: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2020-11-11 23:52:32,683 BAD EPOCHS (no improvement): 4\n",
      "2020-11-11 23:52:32,684 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:53:11,386 epoch 23 - iter 40/401 - loss 2.07159922 - samples/sec: 33.08 - lr: 0.003125\n",
      "2020-11-11 23:53:49,732 epoch 23 - iter 80/401 - loss 1.99369564 - samples/sec: 33.39 - lr: 0.003125\n",
      "2020-11-11 23:54:30,373 epoch 23 - iter 120/401 - loss 2.04958659 - samples/sec: 31.50 - lr: 0.003125\n",
      "2020-11-11 23:55:10,893 epoch 23 - iter 160/401 - loss 2.05931786 - samples/sec: 31.59 - lr: 0.003125\n",
      "2020-11-11 23:55:52,131 epoch 23 - iter 200/401 - loss 2.08366613 - samples/sec: 31.04 - lr: 0.003125\n",
      "2020-11-11 23:56:34,771 epoch 23 - iter 240/401 - loss 2.13679771 - samples/sec: 30.02 - lr: 0.003125\n",
      "2020-11-11 23:57:15,162 epoch 23 - iter 280/401 - loss 2.13934942 - samples/sec: 31.69 - lr: 0.003125\n",
      "2020-11-11 23:57:55,043 epoch 23 - iter 320/401 - loss 2.14310239 - samples/sec: 32.10 - lr: 0.003125\n",
      "2020-11-11 23:58:35,568 epoch 23 - iter 360/401 - loss 2.14993676 - samples/sec: 31.59 - lr: 0.003125\n",
      "2020-11-11 23:59:13,712 epoch 23 - iter 400/401 - loss 2.14037827 - samples/sec: 33.56 - lr: 0.003125\n",
      "2020-11-11 23:59:14,535 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-11 23:59:14,536 EPOCH 23 done: loss 2.1404 - lr 0.0031250\n",
      "2020-11-11 23:59:36,947 DEV : loss 3.03273344039917 - score 0.8391\n",
      "2020-11-11 23:59:37,110 BAD EPOCHS (no improvement): 1\n",
      "2020-11-11 23:59:37,111 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:00:20,637 epoch 24 - iter 40/401 - loss 2.09638123 - samples/sec: 29.41 - lr: 0.003125\n",
      "2020-11-12 00:00:59,258 epoch 24 - iter 80/401 - loss 2.13238100 - samples/sec: 33.15 - lr: 0.003125\n",
      "2020-11-12 00:01:40,605 epoch 24 - iter 120/401 - loss 2.15241052 - samples/sec: 30.96 - lr: 0.003125\n",
      "2020-11-12 00:02:20,422 epoch 24 - iter 160/401 - loss 2.11035803 - samples/sec: 32.15 - lr: 0.003125\n",
      "2020-11-12 00:03:02,917 epoch 24 - iter 200/401 - loss 2.11021425 - samples/sec: 30.13 - lr: 0.003125\n",
      "2020-11-12 00:03:43,697 epoch 24 - iter 240/401 - loss 2.10320199 - samples/sec: 31.39 - lr: 0.003125\n",
      "2020-11-12 00:04:22,881 epoch 24 - iter 280/401 - loss 2.08730746 - samples/sec: 32.67 - lr: 0.003125\n",
      "2020-11-12 00:05:00,541 epoch 24 - iter 320/401 - loss 2.07562758 - samples/sec: 33.99 - lr: 0.003125\n",
      "2020-11-12 00:05:40,100 epoch 24 - iter 360/401 - loss 2.10513555 - samples/sec: 32.36 - lr: 0.003125\n",
      "2020-11-12 00:06:20,507 epoch 24 - iter 400/401 - loss 2.12297496 - samples/sec: 31.68 - lr: 0.003125\n",
      "2020-11-12 00:06:21,250 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:06:21,251 EPOCH 24 done: loss 2.1276 - lr 0.0031250\n",
      "2020-11-12 00:06:43,513 DEV : loss 3.040255069732666 - score 0.8389\n",
      "2020-11-12 00:06:43,675 BAD EPOCHS (no improvement): 2\n",
      "2020-11-12 00:06:43,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:07:24,123 epoch 25 - iter 40/401 - loss 1.87563903 - samples/sec: 31.65 - lr: 0.003125\n",
      "2020-11-12 00:08:05,312 epoch 25 - iter 80/401 - loss 1.99668349 - samples/sec: 31.08 - lr: 0.003125\n",
      "2020-11-12 00:08:45,047 epoch 25 - iter 120/401 - loss 2.06109110 - samples/sec: 32.22 - lr: 0.003125\n",
      "2020-11-12 00:09:26,116 epoch 25 - iter 160/401 - loss 2.11542527 - samples/sec: 31.17 - lr: 0.003125\n",
      "2020-11-12 00:10:05,594 epoch 25 - iter 200/401 - loss 2.12512189 - samples/sec: 32.43 - lr: 0.003125\n",
      "2020-11-12 00:10:44,985 epoch 25 - iter 240/401 - loss 2.12335676 - samples/sec: 32.50 - lr: 0.003125\n",
      "2020-11-12 00:11:23,380 epoch 25 - iter 280/401 - loss 2.10712391 - samples/sec: 33.34 - lr: 0.003125\n",
      "2020-11-12 00:12:06,337 epoch 25 - iter 320/401 - loss 2.10397274 - samples/sec: 29.80 - lr: 0.003125\n",
      "2020-11-12 00:12:45,701 epoch 25 - iter 360/401 - loss 2.10650851 - samples/sec: 32.52 - lr: 0.003125\n",
      "2020-11-12 00:13:26,438 epoch 25 - iter 400/401 - loss 2.13042375 - samples/sec: 31.43 - lr: 0.003125\n",
      "2020-11-12 00:13:27,358 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:13:27,359 EPOCH 25 done: loss 2.1324 - lr 0.0031250\n",
      "2020-11-12 00:13:49,516 DEV : loss 3.04089617729187 - score 0.8404\n",
      "2020-11-12 00:13:49,680 BAD EPOCHS (no improvement): 3\n",
      "2020-11-12 00:13:49,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:14:28,430 epoch 26 - iter 40/401 - loss 2.28721718 - samples/sec: 33.04 - lr: 0.003125\n",
      "2020-11-12 00:15:09,542 epoch 26 - iter 80/401 - loss 2.25022904 - samples/sec: 31.14 - lr: 0.003125\n",
      "2020-11-12 00:15:48,736 epoch 26 - iter 120/401 - loss 2.15222223 - samples/sec: 32.66 - lr: 0.003125\n",
      "2020-11-12 00:16:30,354 epoch 26 - iter 160/401 - loss 2.19600402 - samples/sec: 30.76 - lr: 0.003125\n",
      "2020-11-12 00:17:09,543 epoch 26 - iter 200/401 - loss 2.17753740 - samples/sec: 32.67 - lr: 0.003125\n",
      "2020-11-12 00:17:49,792 epoch 26 - iter 240/401 - loss 2.14791494 - samples/sec: 31.81 - lr: 0.003125\n",
      "2020-11-12 00:18:27,909 epoch 26 - iter 280/401 - loss 2.10427523 - samples/sec: 33.59 - lr: 0.003125\n",
      "2020-11-12 00:19:06,706 epoch 26 - iter 320/401 - loss 2.10577204 - samples/sec: 33.00 - lr: 0.003125\n",
      "2020-11-12 00:19:47,677 epoch 26 - iter 360/401 - loss 2.11822935 - samples/sec: 31.25 - lr: 0.003125\n",
      "2020-11-12 00:20:31,109 epoch 26 - iter 400/401 - loss 2.10480365 - samples/sec: 29.48 - lr: 0.003125\n",
      "2020-11-12 00:20:31,882 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:20:31,883 EPOCH 26 done: loss 2.1081 - lr 0.0031250\n",
      "2020-11-12 00:20:55,813 DEV : loss 3.0517263412475586 - score 0.8437\n",
      "Epoch    26: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2020-11-12 00:20:55,980 BAD EPOCHS (no improvement): 4\n",
      "2020-11-12 00:20:55,980 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:21:36,017 epoch 27 - iter 40/401 - loss 2.02206983 - samples/sec: 31.98 - lr: 0.001563\n",
      "2020-11-12 00:22:16,843 epoch 27 - iter 80/401 - loss 2.04617269 - samples/sec: 31.36 - lr: 0.001563\n",
      "2020-11-12 00:22:56,685 epoch 27 - iter 120/401 - loss 2.03227035 - samples/sec: 32.13 - lr: 0.001563\n",
      "2020-11-12 00:23:36,776 epoch 27 - iter 160/401 - loss 2.03601052 - samples/sec: 31.93 - lr: 0.001563\n",
      "2020-11-12 00:24:18,987 epoch 27 - iter 200/401 - loss 2.09395783 - samples/sec: 30.33 - lr: 0.001563\n",
      "2020-11-12 00:24:58,902 epoch 27 - iter 240/401 - loss 2.11950624 - samples/sec: 32.07 - lr: 0.001563\n",
      "2020-11-12 00:25:39,938 epoch 27 - iter 280/401 - loss 2.10055612 - samples/sec: 31.20 - lr: 0.001563\n",
      "2020-11-12 00:26:20,148 epoch 27 - iter 320/401 - loss 2.08091322 - samples/sec: 31.84 - lr: 0.001563\n",
      "2020-11-12 00:27:00,350 epoch 27 - iter 360/401 - loss 2.09760037 - samples/sec: 31.84 - lr: 0.001563\n",
      "2020-11-12 00:27:38,393 epoch 27 - iter 400/401 - loss 2.08992818 - samples/sec: 33.65 - lr: 0.001563\n",
      "2020-11-12 00:27:39,115 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:27:39,116 EPOCH 27 done: loss 2.0867 - lr 0.0015625\n",
      "2020-11-12 00:28:01,565 DEV : loss 3.072962760925293 - score 0.846\n",
      "2020-11-12 00:28:01,730 BAD EPOCHS (no improvement): 1\n",
      "2020-11-12 00:28:01,731 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:28:39,998 epoch 28 - iter 40/401 - loss 1.95495564 - samples/sec: 33.45 - lr: 0.001563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 00:29:23,130 epoch 28 - iter 80/401 - loss 2.09892673 - samples/sec: 29.68 - lr: 0.001563\n",
      "2020-11-12 00:30:02,919 epoch 28 - iter 120/401 - loss 2.09451132 - samples/sec: 32.17 - lr: 0.001563\n",
      "2020-11-12 00:30:44,610 epoch 28 - iter 160/401 - loss 2.12828819 - samples/sec: 30.71 - lr: 0.001563\n",
      "2020-11-12 00:31:23,736 epoch 28 - iter 200/401 - loss 2.13757448 - samples/sec: 32.72 - lr: 0.001563\n",
      "2020-11-12 00:32:02,113 epoch 28 - iter 240/401 - loss 2.10396618 - samples/sec: 33.36 - lr: 0.001563\n",
      "2020-11-12 00:32:39,499 epoch 28 - iter 280/401 - loss 2.10383987 - samples/sec: 34.24 - lr: 0.001563\n",
      "2020-11-12 00:33:21,100 epoch 28 - iter 320/401 - loss 2.09929715 - samples/sec: 30.77 - lr: 0.001563\n",
      "2020-11-12 00:34:02,506 epoch 28 - iter 360/401 - loss 2.10753193 - samples/sec: 30.92 - lr: 0.001563\n",
      "2020-11-12 00:34:42,569 epoch 28 - iter 400/401 - loss 2.09864487 - samples/sec: 31.95 - lr: 0.001563\n",
      "2020-11-12 00:34:43,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:34:43,513 EPOCH 28 done: loss 2.1017 - lr 0.0015625\n",
      "2020-11-12 00:35:05,772 DEV : loss 3.0485262870788574 - score 0.8402\n",
      "2020-11-12 00:35:05,936 BAD EPOCHS (no improvement): 2\n",
      "2020-11-12 00:35:05,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:35:44,876 epoch 29 - iter 40/401 - loss 2.06351666 - samples/sec: 32.88 - lr: 0.001563\n",
      "2020-11-12 00:36:29,291 epoch 29 - iter 80/401 - loss 2.17826782 - samples/sec: 28.82 - lr: 0.001563\n",
      "2020-11-12 00:37:09,462 epoch 29 - iter 120/401 - loss 2.18564352 - samples/sec: 31.87 - lr: 0.001563\n",
      "2020-11-12 00:37:48,506 epoch 29 - iter 160/401 - loss 2.15010123 - samples/sec: 32.79 - lr: 0.001563\n",
      "2020-11-12 00:38:29,850 epoch 29 - iter 200/401 - loss 2.16536306 - samples/sec: 30.96 - lr: 0.001563\n",
      "2020-11-12 00:39:09,619 epoch 29 - iter 240/401 - loss 2.13347457 - samples/sec: 32.19 - lr: 0.001563\n",
      "2020-11-12 00:39:49,911 epoch 29 - iter 280/401 - loss 2.12674884 - samples/sec: 31.77 - lr: 0.001563\n",
      "2020-11-12 00:40:28,801 epoch 29 - iter 320/401 - loss 2.09055976 - samples/sec: 32.92 - lr: 0.001563\n",
      "2020-11-12 00:41:10,599 epoch 29 - iter 360/401 - loss 2.09990882 - samples/sec: 30.63 - lr: 0.001563\n",
      "2020-11-12 00:41:49,584 epoch 29 - iter 400/401 - loss 2.09296846 - samples/sec: 32.84 - lr: 0.001563\n",
      "2020-11-12 00:41:50,540 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:41:50,541 EPOCH 29 done: loss 2.0929 - lr 0.0015625\n",
      "2020-11-12 00:42:12,908 DEV : loss 3.04333233833313 - score 0.8406\n",
      "2020-11-12 00:42:13,071 BAD EPOCHS (no improvement): 3\n",
      "2020-11-12 00:42:13,072 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:42:50,968 epoch 30 - iter 40/401 - loss 1.82333058 - samples/sec: 33.78 - lr: 0.001563\n",
      "2020-11-12 00:43:30,508 epoch 30 - iter 80/401 - loss 1.83686097 - samples/sec: 32.38 - lr: 0.001563\n",
      "2020-11-12 00:44:12,420 epoch 30 - iter 120/401 - loss 1.95357495 - samples/sec: 30.54 - lr: 0.001563\n",
      "2020-11-12 00:44:52,192 epoch 30 - iter 160/401 - loss 1.97410238 - samples/sec: 32.19 - lr: 0.001563\n",
      "2020-11-12 00:45:31,086 epoch 30 - iter 200/401 - loss 2.00023832 - samples/sec: 32.92 - lr: 0.001563\n",
      "2020-11-12 00:46:11,348 epoch 30 - iter 240/401 - loss 2.04245450 - samples/sec: 31.80 - lr: 0.001563\n",
      "2020-11-12 00:46:49,301 epoch 30 - iter 280/401 - loss 2.03664908 - samples/sec: 33.73 - lr: 0.001563\n",
      "2020-11-12 00:47:32,415 epoch 30 - iter 320/401 - loss 2.06143662 - samples/sec: 29.69 - lr: 0.001563\n",
      "2020-11-12 00:48:13,623 epoch 30 - iter 360/401 - loss 2.05162192 - samples/sec: 31.07 - lr: 0.001563\n",
      "2020-11-12 00:48:55,476 epoch 30 - iter 400/401 - loss 2.06741500 - samples/sec: 30.59 - lr: 0.001563\n",
      "2020-11-12 00:48:56,281 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:48:56,282 EPOCH 30 done: loss 2.0678 - lr 0.0015625\n",
      "2020-11-12 00:49:18,645 DEV : loss 3.041123151779175 - score 0.8373\n",
      "Epoch    30: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2020-11-12 00:49:18,811 BAD EPOCHS (no improvement): 4\n",
      "2020-11-12 00:49:18,812 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:49:59,291 epoch 31 - iter 40/401 - loss 1.96072824 - samples/sec: 31.63 - lr: 0.000781\n",
      "2020-11-12 00:50:36,695 epoch 31 - iter 80/401 - loss 2.03341468 - samples/sec: 34.23 - lr: 0.000781\n",
      "2020-11-12 00:51:17,865 epoch 31 - iter 120/401 - loss 2.06157354 - samples/sec: 31.09 - lr: 0.000781\n",
      "2020-11-12 00:51:58,378 epoch 31 - iter 160/401 - loss 2.06032963 - samples/sec: 31.60 - lr: 0.000781\n",
      "2020-11-12 00:52:40,694 epoch 31 - iter 200/401 - loss 2.06116014 - samples/sec: 30.25 - lr: 0.000781\n",
      "2020-11-12 00:53:20,733 epoch 31 - iter 240/401 - loss 2.07740978 - samples/sec: 31.97 - lr: 0.000781\n",
      "2020-11-12 00:54:01,127 epoch 31 - iter 280/401 - loss 2.10789596 - samples/sec: 31.69 - lr: 0.000781\n",
      "2020-11-12 00:54:41,239 epoch 31 - iter 320/401 - loss 2.09250495 - samples/sec: 31.92 - lr: 0.000781\n",
      "2020-11-12 00:55:20,371 epoch 31 - iter 360/401 - loss 2.07786689 - samples/sec: 32.71 - lr: 0.000781\n",
      "2020-11-12 00:56:02,700 epoch 31 - iter 400/401 - loss 2.08049939 - samples/sec: 30.24 - lr: 0.000781\n",
      "2020-11-12 00:56:03,691 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:56:03,692 EPOCH 31 done: loss 2.0812 - lr 0.0007813\n",
      "2020-11-12 00:56:25,946 DEV : loss 3.060328245162964 - score 0.8433\n",
      "2020-11-12 00:56:26,112 BAD EPOCHS (no improvement): 1\n",
      "2020-11-12 00:56:26,113 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 00:57:05,196 epoch 32 - iter 40/401 - loss 2.11894195 - samples/sec: 32.76 - lr: 0.000781\n",
      "2020-11-12 00:57:45,208 epoch 32 - iter 80/401 - loss 2.07391409 - samples/sec: 31.99 - lr: 0.000781\n",
      "2020-11-12 00:58:24,188 epoch 32 - iter 120/401 - loss 2.03820655 - samples/sec: 32.84 - lr: 0.000781\n",
      "2020-11-12 00:59:03,669 epoch 32 - iter 160/401 - loss 2.04702777 - samples/sec: 32.42 - lr: 0.000781\n",
      "2020-11-12 00:59:43,354 epoch 32 - iter 200/401 - loss 2.07904004 - samples/sec: 32.26 - lr: 0.000781\n",
      "2020-11-12 01:00:24,147 epoch 32 - iter 240/401 - loss 2.09023975 - samples/sec: 31.38 - lr: 0.000781\n",
      "2020-11-12 01:01:04,622 epoch 32 - iter 280/401 - loss 2.12441973 - samples/sec: 31.63 - lr: 0.000781\n",
      "2020-11-12 01:01:44,363 epoch 32 - iter 320/401 - loss 2.10543296 - samples/sec: 32.21 - lr: 0.000781\n",
      "2020-11-12 01:02:24,917 epoch 32 - iter 360/401 - loss 2.09609434 - samples/sec: 31.57 - lr: 0.000781\n",
      "2020-11-12 01:03:05,818 epoch 32 - iter 400/401 - loss 2.07875794 - samples/sec: 31.30 - lr: 0.000781\n",
      "2020-11-12 01:03:06,901 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:03:06,902 EPOCH 32 done: loss 2.0796 - lr 0.0007813\n",
      "2020-11-12 01:03:29,110 DEV : loss 3.0619049072265625 - score 0.8426\n",
      "2020-11-12 01:03:29,273 BAD EPOCHS (no improvement): 2\n",
      "2020-11-12 01:03:29,274 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:04:09,694 epoch 33 - iter 40/401 - loss 2.04961362 - samples/sec: 31.67 - lr: 0.000781\n",
      "2020-11-12 01:04:50,365 epoch 33 - iter 80/401 - loss 2.10869791 - samples/sec: 31.48 - lr: 0.000781\n",
      "2020-11-12 01:05:30,903 epoch 33 - iter 120/401 - loss 2.07998334 - samples/sec: 31.58 - lr: 0.000781\n",
      "2020-11-12 01:06:10,814 epoch 33 - iter 160/401 - loss 2.04306631 - samples/sec: 32.08 - lr: 0.000781\n",
      "2020-11-12 01:06:52,261 epoch 33 - iter 200/401 - loss 2.03415355 - samples/sec: 30.89 - lr: 0.000781\n",
      "2020-11-12 01:07:34,344 epoch 33 - iter 240/401 - loss 2.02026548 - samples/sec: 30.42 - lr: 0.000781\n",
      "2020-11-12 01:08:14,928 epoch 33 - iter 280/401 - loss 2.05357908 - samples/sec: 31.54 - lr: 0.000781\n",
      "2020-11-12 01:08:52,654 epoch 33 - iter 320/401 - loss 2.05032080 - samples/sec: 33.93 - lr: 0.000781\n",
      "2020-11-12 01:09:31,045 epoch 33 - iter 360/401 - loss 2.06614255 - samples/sec: 33.35 - lr: 0.000781\n",
      "2020-11-12 01:10:12,940 epoch 33 - iter 400/401 - loss 2.07024421 - samples/sec: 30.56 - lr: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 01:10:13,907 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:10:13,908 EPOCH 33 done: loss 2.0707 - lr 0.0007813\n",
      "2020-11-12 01:10:36,192 DEV : loss 3.0591745376586914 - score 0.8412\n",
      "2020-11-12 01:10:36,355 BAD EPOCHS (no improvement): 3\n",
      "2020-11-12 01:10:36,366 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:11:17,801 epoch 34 - iter 40/401 - loss 2.10622119 - samples/sec: 30.90 - lr: 0.000781\n",
      "2020-11-12 01:11:56,769 epoch 34 - iter 80/401 - loss 2.12725564 - samples/sec: 32.85 - lr: 0.000781\n",
      "2020-11-12 01:12:36,522 epoch 34 - iter 120/401 - loss 2.13181892 - samples/sec: 32.20 - lr: 0.000781\n",
      "2020-11-12 01:13:17,069 epoch 34 - iter 160/401 - loss 2.06728183 - samples/sec: 31.57 - lr: 0.000781\n",
      "2020-11-12 01:13:56,177 epoch 34 - iter 200/401 - loss 2.07436619 - samples/sec: 32.73 - lr: 0.000781\n",
      "2020-11-12 01:14:37,134 epoch 34 - iter 240/401 - loss 2.06977879 - samples/sec: 31.26 - lr: 0.000781\n",
      "2020-11-12 01:15:18,902 epoch 34 - iter 280/401 - loss 2.08435402 - samples/sec: 30.65 - lr: 0.000781\n",
      "2020-11-12 01:15:58,201 epoch 34 - iter 320/401 - loss 2.06555778 - samples/sec: 32.57 - lr: 0.000781\n",
      "2020-11-12 01:16:37,806 epoch 34 - iter 360/401 - loss 2.05951370 - samples/sec: 32.32 - lr: 0.000781\n",
      "2020-11-12 01:17:16,600 epoch 34 - iter 400/401 - loss 2.06303694 - samples/sec: 33.00 - lr: 0.000781\n",
      "2020-11-12 01:17:17,900 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:17:17,902 EPOCH 34 done: loss 2.0610 - lr 0.0007813\n",
      "2020-11-12 01:17:40,173 DEV : loss 3.056715250015259 - score 0.8408\n",
      "Epoch    34: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2020-11-12 01:17:40,337 BAD EPOCHS (no improvement): 4\n",
      "2020-11-12 01:17:40,338 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:18:20,781 epoch 35 - iter 40/401 - loss 2.08503322 - samples/sec: 31.65 - lr: 0.000391\n",
      "2020-11-12 01:18:58,933 epoch 35 - iter 80/401 - loss 2.07849195 - samples/sec: 33.55 - lr: 0.000391\n",
      "2020-11-12 01:19:39,213 epoch 35 - iter 120/401 - loss 2.07521549 - samples/sec: 31.78 - lr: 0.000391\n",
      "2020-11-12 01:20:18,755 epoch 35 - iter 160/401 - loss 2.09982343 - samples/sec: 32.37 - lr: 0.000391\n",
      "2020-11-12 01:20:58,551 epoch 35 - iter 200/401 - loss 2.09251072 - samples/sec: 32.17 - lr: 0.000391\n",
      "2020-11-12 01:21:36,987 epoch 35 - iter 240/401 - loss 2.06609979 - samples/sec: 33.31 - lr: 0.000391\n",
      "2020-11-12 01:22:17,786 epoch 35 - iter 280/401 - loss 2.05279568 - samples/sec: 31.38 - lr: 0.000391\n",
      "2020-11-12 01:22:57,985 epoch 35 - iter 320/401 - loss 2.05041892 - samples/sec: 31.85 - lr: 0.000391\n",
      "2020-11-12 01:23:38,832 epoch 35 - iter 360/401 - loss 2.06424101 - samples/sec: 31.34 - lr: 0.000391\n",
      "2020-11-12 01:24:20,602 epoch 35 - iter 400/401 - loss 2.07352114 - samples/sec: 30.65 - lr: 0.000391\n",
      "2020-11-12 01:24:21,455 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:24:21,457 EPOCH 35 done: loss 2.0741 - lr 0.0003906\n",
      "2020-11-12 01:24:43,777 DEV : loss 3.0526113510131836 - score 0.841\n",
      "2020-11-12 01:24:43,940 BAD EPOCHS (no improvement): 1\n",
      "2020-11-12 01:24:43,941 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:25:26,335 epoch 36 - iter 40/401 - loss 2.10212937 - samples/sec: 30.20 - lr: 0.000391\n",
      "2020-11-12 01:26:06,719 epoch 36 - iter 80/401 - loss 2.02811422 - samples/sec: 31.70 - lr: 0.000391\n",
      "2020-11-12 01:26:44,675 epoch 36 - iter 120/401 - loss 1.99349331 - samples/sec: 33.73 - lr: 0.000391\n",
      "2020-11-12 01:27:24,722 epoch 36 - iter 160/401 - loss 2.03781995 - samples/sec: 31.97 - lr: 0.000391\n",
      "2020-11-12 01:28:05,887 epoch 36 - iter 200/401 - loss 2.05185362 - samples/sec: 31.10 - lr: 0.000391\n",
      "2020-11-12 01:28:47,814 epoch 36 - iter 240/401 - loss 2.05695265 - samples/sec: 30.53 - lr: 0.000391\n",
      "2020-11-12 01:29:27,574 epoch 36 - iter 280/401 - loss 2.04444485 - samples/sec: 32.20 - lr: 0.000391\n",
      "2020-11-12 01:30:07,507 epoch 36 - iter 320/401 - loss 2.06084483 - samples/sec: 32.06 - lr: 0.000391\n",
      "2020-11-12 01:30:48,079 epoch 36 - iter 360/401 - loss 2.07371031 - samples/sec: 31.55 - lr: 0.000391\n",
      "2020-11-12 01:31:26,146 epoch 36 - iter 400/401 - loss 2.06952466 - samples/sec: 33.63 - lr: 0.000391\n",
      "2020-11-12 01:31:27,025 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:31:27,027 EPOCH 36 done: loss 2.0709 - lr 0.0003906\n",
      "2020-11-12 01:31:49,276 DEV : loss 3.060730218887329 - score 0.8419\n",
      "2020-11-12 01:31:49,443 BAD EPOCHS (no improvement): 2\n",
      "2020-11-12 01:31:49,444 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:32:33,299 epoch 37 - iter 40/401 - loss 2.23951949 - samples/sec: 29.19 - lr: 0.000391\n",
      "2020-11-12 01:33:11,351 epoch 37 - iter 80/401 - loss 2.08141715 - samples/sec: 33.64 - lr: 0.000391\n",
      "2020-11-12 01:33:51,503 epoch 37 - iter 120/401 - loss 2.05948007 - samples/sec: 31.88 - lr: 0.000391\n",
      "2020-11-12 01:34:31,375 epoch 37 - iter 160/401 - loss 2.03913432 - samples/sec: 32.11 - lr: 0.000391\n",
      "2020-11-12 01:35:09,154 epoch 37 - iter 200/401 - loss 2.03079967 - samples/sec: 33.89 - lr: 0.000391\n",
      "2020-11-12 01:35:49,169 epoch 37 - iter 240/401 - loss 2.04719813 - samples/sec: 31.99 - lr: 0.000391\n",
      "2020-11-12 01:36:27,947 epoch 37 - iter 280/401 - loss 2.03382705 - samples/sec: 33.01 - lr: 0.000391\n",
      "2020-11-12 01:37:06,813 epoch 37 - iter 320/401 - loss 2.05250299 - samples/sec: 32.94 - lr: 0.000391\n",
      "2020-11-12 01:37:47,730 epoch 37 - iter 360/401 - loss 2.06188149 - samples/sec: 31.29 - lr: 0.000391\n",
      "2020-11-12 01:38:29,037 epoch 37 - iter 400/401 - loss 2.06722030 - samples/sec: 30.99 - lr: 0.000391\n",
      "2020-11-12 01:38:30,178 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:38:30,179 EPOCH 37 done: loss 2.0679 - lr 0.0003906\n",
      "2020-11-12 01:38:52,444 DEV : loss 3.0484976768493652 - score 0.8406\n",
      "2020-11-12 01:38:52,608 BAD EPOCHS (no improvement): 3\n",
      "2020-11-12 01:38:52,609 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:39:31,878 epoch 38 - iter 40/401 - loss 2.15724656 - samples/sec: 32.60 - lr: 0.000391\n",
      "2020-11-12 01:40:13,036 epoch 38 - iter 80/401 - loss 2.01867919 - samples/sec: 31.10 - lr: 0.000391\n",
      "2020-11-12 01:40:53,467 epoch 38 - iter 120/401 - loss 2.03927975 - samples/sec: 31.66 - lr: 0.000391\n",
      "2020-11-12 01:41:35,030 epoch 38 - iter 160/401 - loss 2.01501501 - samples/sec: 30.80 - lr: 0.000391\n",
      "2020-11-12 01:42:14,838 epoch 38 - iter 200/401 - loss 2.00281202 - samples/sec: 32.16 - lr: 0.000391\n",
      "2020-11-12 01:42:52,628 epoch 38 - iter 240/401 - loss 1.98402981 - samples/sec: 33.88 - lr: 0.000391\n",
      "2020-11-12 01:43:31,171 epoch 38 - iter 280/401 - loss 2.02649463 - samples/sec: 33.21 - lr: 0.000391\n",
      "2020-11-12 01:44:12,024 epoch 38 - iter 320/401 - loss 2.05403108 - samples/sec: 31.34 - lr: 0.000391\n",
      "2020-11-12 01:44:50,044 epoch 38 - iter 360/401 - loss 2.05620180 - samples/sec: 33.67 - lr: 0.000391\n",
      "2020-11-12 01:45:32,497 epoch 38 - iter 400/401 - loss 2.07332521 - samples/sec: 30.15 - lr: 0.000391\n",
      "2020-11-12 01:45:33,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:45:33,495 EPOCH 38 done: loss 2.0720 - lr 0.0003906\n",
      "2020-11-12 01:45:55,725 DEV : loss 3.0462563037872314 - score 0.8408\n",
      "Epoch    38: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2020-11-12 01:45:55,887 BAD EPOCHS (no improvement): 4\n",
      "2020-11-12 01:45:55,888 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:46:35,724 epoch 39 - iter 40/401 - loss 2.04582524 - samples/sec: 32.14 - lr: 0.000195\n",
      "2020-11-12 01:47:13,803 epoch 39 - iter 80/401 - loss 2.04217307 - samples/sec: 33.62 - lr: 0.000195\n",
      "2020-11-12 01:47:55,777 epoch 39 - iter 120/401 - loss 2.03417704 - samples/sec: 30.50 - lr: 0.000195\n",
      "2020-11-12 01:48:35,895 epoch 39 - iter 160/401 - loss 2.05304400 - samples/sec: 31.91 - lr: 0.000195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 01:49:17,974 epoch 39 - iter 200/401 - loss 2.08526417 - samples/sec: 30.42 - lr: 0.000195\n",
      "2020-11-12 01:49:58,110 epoch 39 - iter 240/401 - loss 2.06495566 - samples/sec: 31.90 - lr: 0.000195\n",
      "2020-11-12 01:50:38,130 epoch 39 - iter 280/401 - loss 2.06642269 - samples/sec: 31.99 - lr: 0.000195\n",
      "2020-11-12 01:51:17,032 epoch 39 - iter 320/401 - loss 2.06848159 - samples/sec: 32.91 - lr: 0.000195\n",
      "2020-11-12 01:51:55,372 epoch 39 - iter 360/401 - loss 2.05339388 - samples/sec: 33.39 - lr: 0.000195\n",
      "2020-11-12 01:52:37,384 epoch 39 - iter 400/401 - loss 2.06171291 - samples/sec: 30.47 - lr: 0.000195\n",
      "2020-11-12 01:52:38,120 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:52:38,121 EPOCH 39 done: loss 2.0616 - lr 0.0001953\n",
      "2020-11-12 01:53:00,363 DEV : loss 3.0484695434570312 - score 0.8408\n",
      "2020-11-12 01:53:00,527 BAD EPOCHS (no improvement): 1\n",
      "2020-11-12 01:53:00,527 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:53:38,609 epoch 40 - iter 40/401 - loss 2.00946176 - samples/sec: 33.62 - lr: 0.000195\n",
      "2020-11-12 01:54:17,665 epoch 40 - iter 80/401 - loss 2.15227587 - samples/sec: 32.78 - lr: 0.000195\n",
      "2020-11-12 01:55:00,262 epoch 40 - iter 120/401 - loss 2.13900433 - samples/sec: 30.05 - lr: 0.000195\n",
      "2020-11-12 01:55:38,991 epoch 40 - iter 160/401 - loss 2.10980181 - samples/sec: 33.05 - lr: 0.000195\n",
      "2020-11-12 01:56:21,509 epoch 40 - iter 200/401 - loss 2.11569440 - samples/sec: 30.11 - lr: 0.000195\n",
      "2020-11-12 01:57:00,365 epoch 40 - iter 240/401 - loss 2.10843101 - samples/sec: 32.95 - lr: 0.000195\n",
      "2020-11-12 01:57:40,650 epoch 40 - iter 280/401 - loss 2.09159855 - samples/sec: 31.78 - lr: 0.000195\n",
      "2020-11-12 01:58:21,936 epoch 40 - iter 320/401 - loss 2.06754911 - samples/sec: 31.01 - lr: 0.000195\n",
      "2020-11-12 01:59:02,074 epoch 40 - iter 360/401 - loss 2.05215490 - samples/sec: 31.89 - lr: 0.000195\n",
      "2020-11-12 01:59:41,183 epoch 40 - iter 400/401 - loss 2.04626778 - samples/sec: 32.73 - lr: 0.000195\n",
      "2020-11-12 01:59:42,118 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 01:59:42,119 EPOCH 40 done: loss 2.0489 - lr 0.0001953\n",
      "2020-11-12 02:00:04,466 DEV : loss 3.0487558841705322 - score 0.8407\n",
      "2020-11-12 02:00:04,630 BAD EPOCHS (no improvement): 2\n",
      "2020-11-12 02:00:04,631 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:00:46,347 epoch 41 - iter 40/401 - loss 2.38544873 - samples/sec: 30.69 - lr: 0.000195\n",
      "2020-11-12 02:01:28,343 epoch 41 - iter 80/401 - loss 2.28574773 - samples/sec: 30.48 - lr: 0.000195\n",
      "2020-11-12 02:02:06,923 epoch 41 - iter 120/401 - loss 2.18804599 - samples/sec: 33.18 - lr: 0.000195\n",
      "2020-11-12 02:02:47,348 epoch 41 - iter 160/401 - loss 2.17339973 - samples/sec: 31.67 - lr: 0.000195\n",
      "2020-11-12 02:03:26,354 epoch 41 - iter 200/401 - loss 2.17457067 - samples/sec: 32.82 - lr: 0.000195\n",
      "2020-11-12 02:04:04,308 epoch 41 - iter 240/401 - loss 2.13745678 - samples/sec: 33.73 - lr: 0.000195\n",
      "2020-11-12 02:04:44,493 epoch 41 - iter 280/401 - loss 2.10641276 - samples/sec: 31.86 - lr: 0.000195\n",
      "2020-11-12 02:05:24,583 epoch 41 - iter 320/401 - loss 2.07539957 - samples/sec: 31.93 - lr: 0.000195\n",
      "2020-11-12 02:06:04,800 epoch 41 - iter 360/401 - loss 2.07230704 - samples/sec: 31.83 - lr: 0.000195\n",
      "2020-11-12 02:06:44,440 epoch 41 - iter 400/401 - loss 2.06526350 - samples/sec: 32.30 - lr: 0.000195\n",
      "2020-11-12 02:06:45,283 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:06:45,284 EPOCH 41 done: loss 2.0630 - lr 0.0001953\n",
      "2020-11-12 02:07:09,152 DEV : loss 3.0507256984710693 - score 0.8415\n",
      "2020-11-12 02:07:09,316 BAD EPOCHS (no improvement): 3\n",
      "2020-11-12 02:07:09,317 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:07:47,848 epoch 42 - iter 40/401 - loss 1.79270783 - samples/sec: 33.23 - lr: 0.000195\n",
      "2020-11-12 02:08:25,775 epoch 42 - iter 80/401 - loss 1.88538214 - samples/sec: 33.75 - lr: 0.000195\n",
      "2020-11-12 02:09:06,941 epoch 42 - iter 120/401 - loss 1.92621700 - samples/sec: 31.10 - lr: 0.000195\n",
      "2020-11-12 02:09:48,607 epoch 42 - iter 160/401 - loss 1.99113554 - samples/sec: 30.72 - lr: 0.000195\n",
      "2020-11-12 02:10:29,362 epoch 42 - iter 200/401 - loss 1.99937448 - samples/sec: 31.41 - lr: 0.000195\n",
      "2020-11-12 02:11:09,790 epoch 42 - iter 240/401 - loss 2.00147857 - samples/sec: 31.67 - lr: 0.000195\n",
      "2020-11-12 02:11:51,068 epoch 42 - iter 280/401 - loss 2.04141567 - samples/sec: 31.01 - lr: 0.000195\n",
      "2020-11-12 02:12:30,634 epoch 42 - iter 320/401 - loss 2.04561238 - samples/sec: 32.36 - lr: 0.000195\n",
      "2020-11-12 02:13:12,346 epoch 42 - iter 360/401 - loss 2.06015018 - samples/sec: 30.69 - lr: 0.000195\n",
      "2020-11-12 02:13:50,174 epoch 42 - iter 400/401 - loss 2.05630421 - samples/sec: 33.84 - lr: 0.000195\n",
      "2020-11-12 02:13:51,060 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:13:51,061 EPOCH 42 done: loss 2.0542 - lr 0.0001953\n",
      "2020-11-12 02:14:13,448 DEV : loss 3.0507020950317383 - score 0.841\n",
      "Epoch    42: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2020-11-12 02:14:13,611 BAD EPOCHS (no improvement): 4\n",
      "2020-11-12 02:14:13,612 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:14:13,613 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:14:13,613 learning rate too small - quitting training!\n",
      "2020-11-12 02:14:13,614 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:14:14,160 ----------------------------------------------------------------------------------------------------\n",
      "2020-11-12 02:14:14,167 Testing using best model ...\n",
      "2020-11-12 02:14:14,168 loading file resources/taggers/example-ner/best-model.pt\n",
      "2020-11-12 02:16:03,000 \t0.8929\n",
      "2020-11-12 02:16:03,001 \n",
      "Results:\n",
      "- F-score (micro): 0.8929\n",
      "- F-score (macro): 0.073\n",
      "- Accuracy (incl. no class): 0.8929\n",
      "\n",
      "By class:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                          O     0.8941    0.9989    0.9436     29497\n",
      "            Loaded_Language     0.5417    0.0399    0.0743       652\n",
      "                 Repetition     1.0000    0.0000    0.0000       134\n",
      "      Name_Calling,Labeling     0.4211    0.0263    0.0495       304\n",
      "        Appeal_to_Authority     1.0000    0.0000    0.0000       218\n",
      "Thought-terminating_Cliches     1.0000    0.0000    0.0000        37\n",
      "  Causal_Oversimplification     1.0000    0.0000    0.0000       537\n",
      "  Exaggeration,Minimisation     0.0000    0.0000    0.0000       182\n",
      "                      Doubt     1.0000    0.0143    0.0282       840\n",
      "                    Slogans     1.0000    0.0000    0.0000        48\n",
      "   Appeal_to_fear-prejudice     0.0000    0.0000    0.0000       274\n",
      "               Whataboutism     1.0000    0.0000    0.0000        69\n",
      "    Black-and-White_Fallacy     1.0000    0.0000    0.0000       102\n",
      "                Red_Herring     1.0000    0.0000    0.0000        30\n",
      "                Flag-Waving     1.0000    0.0000    0.0000       126\n",
      "\n",
      "                   accuracy                         0.8929     33050\n",
      "                  macro avg     0.7905    0.0720    0.0730     33050\n",
      "               weighted avg     0.8773    0.8929    0.8448     33050\n",
      "\n",
      "2020-11-12 02:16:03,002 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8929,\n",
       " 'dev_score_history': [0.8526,\n",
       "  0.8522,\n",
       "  0.8426,\n",
       "  0.7658,\n",
       "  0.3687,\n",
       "  0.8528,\n",
       "  0.8528,\n",
       "  0.847,\n",
       "  0.8297,\n",
       "  0.851,\n",
       "  0.8487,\n",
       "  0.847,\n",
       "  0.8443,\n",
       "  0.8497,\n",
       "  0.8395,\n",
       "  0.8482,\n",
       "  0.8423,\n",
       "  0.8473,\n",
       "  0.8484,\n",
       "  0.8477,\n",
       "  0.8473,\n",
       "  0.8411,\n",
       "  0.8391,\n",
       "  0.8389,\n",
       "  0.8404,\n",
       "  0.8437,\n",
       "  0.846,\n",
       "  0.8402,\n",
       "  0.8406,\n",
       "  0.8373,\n",
       "  0.8433,\n",
       "  0.8426,\n",
       "  0.8412,\n",
       "  0.8408,\n",
       "  0.841,\n",
       "  0.8419,\n",
       "  0.8406,\n",
       "  0.8408,\n",
       "  0.8408,\n",
       "  0.8407,\n",
       "  0.8415,\n",
       "  0.841],\n",
       " 'train_loss_history': [11.253379627356209,\n",
       "  5.916571028809297,\n",
       "  4.83766245871708,\n",
       "  4.4146733468310195,\n",
       "  4.086303799526947,\n",
       "  3.271066280225863,\n",
       "  3.1399421614601724,\n",
       "  3.036928580883435,\n",
       "  2.922407278990805,\n",
       "  2.8361931168230394,\n",
       "  2.605942691650771,\n",
       "  2.5539224242926237,\n",
       "  2.4986031158012048,\n",
       "  2.459933787658625,\n",
       "  2.3635609848540917,\n",
       "  2.3147391123961927,\n",
       "  2.316668475060689,\n",
       "  2.2674471104977436,\n",
       "  2.2106180141988836,\n",
       "  2.2060668597792152,\n",
       "  2.181502441812929,\n",
       "  2.1655034605701666,\n",
       "  2.1403885898447395,\n",
       "  2.12758843968634,\n",
       "  2.13240472663965,\n",
       "  2.1081416213007045,\n",
       "  2.0866637301266637,\n",
       "  2.101711927655332,\n",
       "  2.092896929405574,\n",
       "  2.0677979212449378,\n",
       "  2.081247541746891,\n",
       "  2.0795560492541725,\n",
       "  2.070666244499701,\n",
       "  2.060955678286992,\n",
       "  2.0741417825667936,\n",
       "  2.070866509565986,\n",
       "  2.067939817162226,\n",
       "  2.0720226370782924,\n",
       "  2.061589239690072,\n",
       "  2.0489182131100176,\n",
       "  2.063015726587719,\n",
       "  2.054205443199139],\n",
       " 'dev_loss_history': [8.192145347595215,\n",
       "  4.875819683074951,\n",
       "  4.275538921356201,\n",
       "  4.098170280456543,\n",
       "  6.209514617919922,\n",
       "  3.70194935798645,\n",
       "  3.7865734100341797,\n",
       "  3.3864734172821045,\n",
       "  3.336512327194214,\n",
       "  3.291630506515503,\n",
       "  3.172679901123047,\n",
       "  3.165822982788086,\n",
       "  3.1069228649139404,\n",
       "  3.1812214851379395,\n",
       "  3.0603158473968506,\n",
       "  3.1415491104125977,\n",
       "  3.0831947326660156,\n",
       "  3.07602858543396,\n",
       "  3.1099624633789062,\n",
       "  3.0990288257598877,\n",
       "  3.122347354888916,\n",
       "  3.0588812828063965,\n",
       "  3.03273344039917,\n",
       "  3.040255069732666,\n",
       "  3.04089617729187,\n",
       "  3.0517263412475586,\n",
       "  3.072962760925293,\n",
       "  3.0485262870788574,\n",
       "  3.04333233833313,\n",
       "  3.041123151779175,\n",
       "  3.060328245162964,\n",
       "  3.0619049072265625,\n",
       "  3.0591745376586914,\n",
       "  3.056715250015259,\n",
       "  3.0526113510131836,\n",
       "  3.060730218887329,\n",
       "  3.0484976768493652,\n",
       "  3.0462563037872314,\n",
       "  3.0484695434570312,\n",
       "  3.0487558841705322,\n",
       "  3.0507256984710693,\n",
       "  3.0507020950317383]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train('resources/taggers/example-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-25 13:44:31,933 loading file ./resources/taggers/example-ner/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "model = SequenceTagger.load('./resources/taggers/example-ner/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sentence('Hitler is a horribe man')\n",
    "model.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hitler is a horribe man'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
